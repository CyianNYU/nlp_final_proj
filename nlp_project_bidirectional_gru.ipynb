{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re  \n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import collections\n",
    "from itertools import dropwhile\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install sacrebleu\n",
    "from sacrebleu import corpus_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in chinese-english pairs\n",
    "#read in chinese-english pairs\n",
    "lines_zh = open('iwslt-zh-en/train.tok.zh',encoding = 'utf-8').read().strip().split('\\n')\n",
    "lines_en = open('iwslt-zh-en/train.tok.en',encoding = 'utf-8').read().strip().split('\\n')\n",
    "lines_zh_test = open('iwslt-zh-en/test.tok.zh',encoding = 'utf-8').read().strip().split('\\n')\n",
    "lines_en_test = open('iwslt-zh-en/test.tok.en',encoding = 'utf-8').read().strip().split('\\n')\n",
    "lines_zh_val = open('iwslt-zh-en/dev.tok.zh',encoding = 'utf-8').read().strip().split('\\n')\n",
    "lines_en_val = open('iwslt-zh-en/dev.tok.en',encoding = 'utf-8').read().strip().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delect_least_common_words(list_sent, threshold = 5):\n",
    "    ret_list =[]\n",
    "    for x in list_sent:\n",
    "        ret_list += x.split()\n",
    "    ret_dic = collections.Counter(ret_list)\n",
    "    for key, count in dropwhile(lambda key_count: key_count[1] >= threshold, ret_dic.most_common()):\n",
    "        del ret_dic[key]\n",
    "    return list(ret_dic.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "zh_words = delect_least_common_words(lines_zh)\n",
    "en_words = delect_least_common_words(lines_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_to_load = 100000\n",
    "PAD_IDX = 0\n",
    "UNK_IDX = 1\n",
    "SOS_IDX = 2\n",
    "EOS_IDX = 3\n",
    "\n",
    "with open('cc.zh.300.vec') as f:\n",
    "    loaded_embeddings_ft = np.zeros((words_to_load+3, 300))\n",
    "    words_ft = {}\n",
    "    idx2words_ft = {}\n",
    "    ordered_words_ft = []\n",
    "    ordered_words_ft.extend(['<pad>', '<unk>', '<s>'])\n",
    "    loaded_embeddings_ft[0,:] = np.zeros(300)\n",
    "    loaded_embeddings_ft[1,:] = np.random.normal(size = 300)\n",
    "    loaded_embeddings_ft[2,:] = np.random.normal(size = 300)\n",
    "    for i, line in enumerate(f):\n",
    "        if i >= words_to_load: \n",
    "            break\n",
    "        s = line.split()\n",
    "        loaded_embeddings_ft[i+3, :] = np.asarray(s[1:])\n",
    "        words_ft[s[0]] = i+3\n",
    "        idx2words_ft[i+3] = s[0]\n",
    "        ordered_words_ft.append(s[0])\n",
    "    length = len(np.setdiff1d(zh_words, ordered_words_ft))\n",
    "    tmp_embeddings = np.zeros((length, 300))\n",
    "    for idx, word in enumerate(np.setdiff1d(zh_words, ordered_words_ft)):\n",
    "        words_ft[word] = idx+words_to_load+3\n",
    "        idx2words_ft[idx+words_to_load+3] = word\n",
    "        tmp_embeddings[idx, :] = np.random.normal(size = 300)\n",
    "    loaded_embeddings_ft = np.concatenate((loaded_embeddings_ft, tmp_embeddings), axis = 0)\n",
    "    words_ft['<pad>'] = PAD_IDX\n",
    "    words_ft['<unk>'] = UNK_IDX\n",
    "    words_ft['<s>'] = SOS_IDX\n",
    "    idx2words_ft[PAD_IDX] = '<pad>'\n",
    "    idx2words_ft[UNK_IDX] = '<unk>'\n",
    "    idx2words_ft[SOS_IDX] = '<s>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#English embedding\n",
    "with open('wiki-news-300d-1M.vec') as f:\n",
    "    loaded_embeddings_ft_en = np.zeros((words_to_load+4, 300))\n",
    "    words_ft_en = {}\n",
    "    idx2words_ft_en = {}\n",
    "    ordered_words_ft_en = []\n",
    "    ordered_words_ft_en.extend(['<pad>', '<unk>', '<s>', '</s>'])\n",
    "    loaded_embeddings_ft_en[0,:] = np.zeros(300)\n",
    "    loaded_embeddings_ft_en[1,:] = np.random.normal(size = 300)\n",
    "    loaded_embeddings_ft_en[2,:] = np.random.normal(size = 300)\n",
    "    loaded_embeddings_ft_en[3,:] = np.random.normal(size = 300)\n",
    "    for i, line in enumerate(f):\n",
    "        if i >= words_to_load: \n",
    "            break\n",
    "        s = line.split()\n",
    "        loaded_embeddings_ft_en[i+4, :] = np.asarray(s[1:])\n",
    "        words_ft_en[s[0]] = i+4\n",
    "        idx2words_ft_en[i+4] = s[0]\n",
    "        ordered_words_ft_en.append(s[0])\n",
    "    length = len(np.setdiff1d(en_words, ordered_words_ft_en))\n",
    "    tmp_embeddings = np.zeros((length, 300))\n",
    "    for idx, word in enumerate(np.setdiff1d(en_words, ordered_words_ft_en)):\n",
    "        words_ft_en[word] = idx+words_to_load+4\n",
    "        idx2words_ft_en[idx+words_to_load+4] = word\n",
    "        tmp_embeddings[idx, :] = np.random.normal(size = 300)\n",
    "    loaded_embeddings_ft_en = np.concatenate((loaded_embeddings_ft_en, tmp_embeddings), axis = 0)\n",
    "    words_ft_en['<pad>'] = PAD_IDX\n",
    "    words_ft_en['<unk>'] = UNK_IDX\n",
    "    words_ft_en['<s>'] = SOS_IDX\n",
    "    words_ft_en['</s>'] = EOS_IDX\n",
    "    idx2words_ft_en[PAD_IDX] = '<pad>'\n",
    "    idx2words_ft_en[UNK_IDX] = '<unk>'\n",
    "    idx2words_ft_en[SOS_IDX] = '<s>'\n",
    "    idx2words_ft_en[EOS_IDX] = '</s>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add sos and eos in each sentence\n",
    "def add_sos_eos(lines):\n",
    "    \n",
    "    train = []\n",
    "    for l in lines:\n",
    "        l = '<s> ' + l + '</s>'\n",
    "        train.append(l)\n",
    "    return train\n",
    "zh_train = add_sos_eos(lines_zh)    \n",
    "en_train = add_sos_eos(lines_en)\n",
    "zh_test = add_sos_eos(lines_zh_test)\n",
    "en_test = add_sos_eos(lines_en_test)\n",
    "zh_val = add_sos_eos(lines_zh_val)\n",
    "en_val = add_sos_eos(lines_en_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert token to id in the dataset\n",
    "def token2index_dataset(tokens_data,eng = False):\n",
    "    indices_data = []\n",
    "    for tokens in tokens_data:\n",
    "        index_list = []\n",
    "        for token in tokens.split():\n",
    "            if eng == False:\n",
    "                try:\n",
    "                    index_list.append(words_ft[token])\n",
    "                except KeyError:\n",
    "                    index_list.append(UNK_IDX)\n",
    "            else:\n",
    "                try:\n",
    "                    index_list.append(words_ft_en[token])\n",
    "                except KeyError:\n",
    "                    index_list.append(UNK_IDX)\n",
    "        indices_data.append(index_list)\n",
    "    return indices_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "zh_train_indices = token2index_dataset(zh_train)\n",
    "en_train_indices = token2index_dataset(en_train,eng = True)\n",
    "zh_test_indices = token2index_dataset(zh_test)\n",
    "en_test_indices = token2index_dataset(en_test,eng = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#max_sentence_length\n",
    "length_of_en = [len(x.split()) for x in en_train]\n",
    "max_sentence_length_en = sorted(length_of_en)[-int(len(length_of_en)*0.01)]\n",
    "length_of_zh = [len(x.split()) for x in zh_train]\n",
    "max_sentence_length_zh = sorted(length_of_zh)[-int(len(length_of_zh)*0.01)]\n",
    "max_sentence_length_en = 50\n",
    "max_sentence_length_zh = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_sentence_length_zh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Data Loader\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class load_dataset(Dataset):\n",
    "    \"\"\"\n",
    "    Class that represents a train/validation/test dataset that's readable for PyTorch\n",
    "    Note that this class inherits torch.utils.data.Dataset\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data_list_s1,data_list_s2):\n",
    "        \"\"\"\n",
    "        @param data_list_zh: list of Chinese tokens \n",
    "        @param data_list_en: list of English tokens as TARGETS\n",
    "        \"\"\"\n",
    "        self.data_list_s1 = data_list_s1\n",
    "        self.data_list_s2 = data_list_s2\n",
    "        \n",
    "        assert (len(self.data_list_s1) == len(self.data_list_s2))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_list_s1)\n",
    "        \n",
    "    def __getitem__(self, key):\n",
    "        \"\"\"\n",
    "        Triggered when you call dataset[i]\n",
    "        \"\"\"\n",
    "        \n",
    "        token_idx_s1 = self.data_list_s1[key][:max_sentence_length_zh]\n",
    "        token_idx_s2 = self.data_list_s2[key][:max_sentence_length_en]\n",
    "        return [token_idx_s1, token_idx_s2, len(token_idx_s1), len(token_idx_s2)]\n",
    "\n",
    "def collate_func(batch):\n",
    "    \"\"\"\n",
    "    Customized function for DataLoader that dynamically pads the batch so that all \n",
    "    data have the same length\n",
    "    \"\"\"\n",
    "    data_list_s1 = []\n",
    "    data_list_s2 = []\n",
    "    length_list_s1 = []\n",
    "    length_list_s2 = []\n",
    "    for datum in batch:\n",
    "        length_list_s1.append(datum[2])\n",
    "        length_list_s2.append(datum[3])\n",
    "        padded_vec_zh = np.pad(np.array(datum[0]), \n",
    "                                pad_width=((0,max_sentence_length_zh-datum[2])), \n",
    "                                mode=\"constant\", constant_values=0)\n",
    "        padded_vec_en = np.pad(np.array(datum[1]), \n",
    "                                pad_width=((0,max_sentence_length_en-datum[3])), \n",
    "                                mode=\"constant\", constant_values=0)\n",
    "        data_list_s1.append(padded_vec_zh[:max_sentence_length_zh])\n",
    "        data_list_s2.append(padded_vec_en[:max_sentence_length_en])\n",
    "    #print(type(data_list_s1[0]))\n",
    "    if torch.cuda.is_available and torch.has_cudnn:\n",
    "        return [torch.from_numpy(np.array(data_list_s1)).cuda(), torch.from_numpy(np.array(data_list_s2)).cuda(),\n",
    "                torch.LongTensor(length_list_s1).cuda(), torch.LongTensor(length_list_s2).cuda()]\n",
    "    else:    \n",
    "        return [torch.from_numpy(np.array(data_list_s1)), torch.from_numpy(np.array(data_list_s2)),\n",
    "                torch.LongTensor(length_list_s1), torch.LongTensor(length_list_s2)]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 100\n",
    "EMBEDDING_SIZE = 300 # fixed as from the input embedding data\n",
    "\n",
    "train_dataset = load_dataset(zh_train_indices, en_train_indices)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=collate_func,\n",
    "                                           shuffle=True)\n",
    "\n",
    "val_dataset = load_dataset(zh_test_indices, en_test_indices)\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_dataset,\n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=collate_func,\n",
    "                                           shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, emb_dim, hidden_size, embed= torch.from_numpy(loaded_embeddings_ft).float(),num_layers=1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.emb_dim = emb_dim\n",
    "        self.num_layers = num_layers \n",
    "        \n",
    "        # freeze needs to set to be false as we need the random embeddings to train with the pretrained embeddings\n",
    "        self.embedding = nn.Embedding.from_pretrained(embed, freeze=False)\n",
    "        self.gru = nn.GRU(emb_dim, hidden_size,num_layers=num_layers,batch_first=True,bidirectional = True)\n",
    "\n",
    "    def forward(self, data, hidden):\n",
    "        \n",
    "        batch_size, seq_len = data.size()\n",
    "        \n",
    "        embed = self.embedding(data)\n",
    "        output, hidden = self.gru(embed,hidden)\n",
    "        hidden = torch.cat((hidden[0:1,:,:], hidden[1:2,:,:]), 2)\n",
    "\n",
    "        #hidden = [n layers * n directions =1 , batch_size, hidden_size ]\n",
    "        \n",
    "        return output, hidden\n",
    "\n",
    "    # initialize the hidden with random numbers\n",
    "    def initHidden(self,batch_size):\n",
    "        return torch.randn(2*self.num_layers, batch_size, self.hidden_size,device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self,emb_dim,hidden_size, output_size, embed= torch.from_numpy(loaded_embeddings_ft_en).float(),num_layers=1,\n",
    "                 dropout_p=0.1, max_length=max_sentence_length_zh):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size*2\n",
    "        self.num_layers = num_layers \n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding.from_pretrained(embed, freeze=False)\n",
    "        self.attn = nn.Linear(self.hidden_size + emb_dim, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size + emb_dim, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, data, hidden,encoder_outputs):\n",
    "        \n",
    "        ### embed: [1 * batch size * emb_dim = 300 ] ###\n",
    "        ### hidden: [1 * batch size * hidden_size = 300 ] ###\n",
    "        ### encoder_outputs: [batch size * max_sentence_length_zh * hidden_size = 300 ] ###\n",
    "        ### 因为这里concat之后，attn layer 他给的是 hidden size *2 \n",
    "        ### 所以我这儿的hidden size就只能写300了 \n",
    "        \n",
    "        embed = self.embedding(data)\n",
    "        embed = self.dropout(embed)   \n",
    " \n",
    "        ### torch.cat((embed, hidden), 2)  \n",
    "        ### [1 * batch size * (emb_dim + hidden_size) ]\n",
    "        \n",
    "        ### attn_weights: [1 * batch size * max_sentence_length_zh ]###\n",
    "        ### attn_weights[0].unsqueeze(1): [batch size * 1 * max_sentence_length_zh ]###\n",
    "        \n",
    "        ### softmax dim=2 因为最后一个dimension是 词组什么的，不能是1，1的话就是\n",
    "        ### 不同batch间这样比较了？\n",
    "        #hidden = [1 * batch_size * emb_dim]\n",
    "        \n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embed[0], hidden[0]), 1)), dim=1).unsqueeze(1)\n",
    "\n",
    "        ### torch.bmm(attn_weights[0].unsqueeze(1),encoder_outputs).squeeze(1) :\n",
    "        ### [batch size * 1 * hidden_size ]###\n",
    "        ### attn_applied: [batch size * hidden_size (= 300) ] ###\n",
    "        attn_applied = torch.bmm(attn_weights,\n",
    "                                 encoder_outputs).squeeze(1)\n",
    "        ### output: [batch size * hidden_size (= 300) ] ###\n",
    "        ### embed[0]: [batch size * hidden_size (= 300) ] ###\n",
    "        output = torch.cat((embed[0], attn_applied), 1)\n",
    "        ### output: [1 * batch size * hidden_size (= 300) ] ###\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "        \n",
    "        ### output: [1 * batch size * hidden_size (= 300) ] ###\n",
    "        output = F.relu(output)\n",
    "        \n",
    "        #print(hidden.size())\n",
    "        #print(output.size())\n",
    "\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        \n",
    "        \n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        \n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self,batch_size):\n",
    "        return torch.randn(self.num_layers, batch_size, self.hidden_size,device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 1\n",
    "#input_tensor: list of sentence tensor\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer,\n",
    "          criterion,eee):\n",
    "    \n",
    "    ### target_tensor [batch size, max_sentence_length_en = 73] ###\n",
    "    ### target_tensor [batch size, max_sentence_length_zh = 62] ###\n",
    "    batch_size_1, input_length = input_tensor.size()\n",
    "    batch_size_2, target_length = target_tensor.size()\n",
    "    \n",
    "    \n",
    "    encoder_hidden = encoder.initHidden(batch_size_1)\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    ### encoder_hidden: 1 * batch * hidden size ### \n",
    "    ### encoder_output: batch size * max_sentence_length_zh * hidden size ### \n",
    "    encoder_output, encoder_hidden = encoder(input_tensor, encoder_hidden)\n",
    "\n",
    "    decoder_input = torch.tensor(np.array([[SOS_IDX]]*batch_size_1).reshape(1,batch_size_1),device=device)\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "    #print(use_teacher_forcing)\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            \n",
    "            ### decoder_output: [batchsize,5000] ###\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden,encoder_output)\n",
    "        \n",
    "            \n",
    "            loss += criterion(decoder_output, target_tensor[:,di])\n",
    "            decoder_input = target_tensor[:,di].unsqueeze(0)  # Teacher forcing\n",
    "            \n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden,encoder_output)\n",
    "                        \n",
    "            ### decoder_output [batch size, 50003]  ###\n",
    "            \n",
    "            ### topi is a [batch size, 1] tensor first we remove the size 1\n",
    "            ### demension then we add it at the beginning using squeeze\n",
    "            ### 有点脑残诶，做个转置不就好了？\n",
    "            \n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "            \n",
    "            ### decoder_input [1, batch size]  ###\n",
    "            decoder_input = decoder_input.unsqueeze(0)\n",
    " \n",
    "            loss += criterion(decoder_output, target_tensor[:,di])\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, n_iters, folder, print_every=1, plot_every=100, learning_rate=0.001):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "    \n",
    "    #--------------------------------------------\t\n",
    "    #\t\n",
    "    #    LOAD MODELS\t\n",
    "    #\t\n",
    "    #--------------------------------------------\t\n",
    "    \t\n",
    "    if not os.path.exists(folder):\t\n",
    "        os.makedirs(folder)\t\n",
    "\n",
    "    if os.path.exists('./attentation_model/encoder_b'):\t\n",
    "        print('---------------------------------------------------------------------')\t\n",
    "        print('----------------Readind trained model---------------------------------')\t\n",
    "        print('---------------------------------------------------------------------')\t\n",
    "        \t\n",
    "        #read trained models\t\n",
    "        encoder.load_state_dict(torch.load(folder+\"/encoder_b\"))\n",
    "        decoder.load_state_dict(torch.load(folder+\"/decoder_b\"))\t\n",
    "    \n",
    "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        for i, (data_s1, data_s2, lengths_s1, lengths_s2) in enumerate(train_loader):\n",
    "            input_tensor = data_s1\n",
    "            target_tensor = data_s2\n",
    "            #print(\"train\",target_tensor.size())\n",
    "            loss = train(input_tensor, target_tensor, encoder,\n",
    "                         decoder, encoder_optimizer, decoder_optimizer, criterion,i)\n",
    "            print_loss_total += loss\n",
    "            plot_loss_total += loss\n",
    "\n",
    "            if i % print_every == 0:\n",
    "                print_loss_avg = print_loss_total / print_every\n",
    "                print_loss_total = 0\n",
    "                print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                             iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "            if i % plot_every == 0:\n",
    "                plot_loss_avg = plot_loss_total / plot_every\n",
    "                plot_losses.append(plot_loss_avg)\n",
    "                plot_loss_total = 0\n",
    "                \n",
    "        # Save the model for every epoch\n",
    "        print('---------------------------------------------------------------------')\t\n",
    "        print('----------------Saving trained model---------------------------------')\t\n",
    "        print('---------------------------------------------------------------------')\t\n",
    "      \n",
    "        torch.save(encoder.state_dict(),folder +\"/encoder_b\")\n",
    "        torch.save(decoder.state_dict(),folder +\"/decoder_b\")\n",
    "\n",
    "    \n",
    "    return plot_losses\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)\n",
    "    \n",
    "import time\n",
    "import math\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 0s (- 0m 10s) (1 5%) 0.2166\n",
      "0m 27s (- 8m 35s) (1 5%) 3.4213\n",
      "0m 53s (- 16m 59s) (1 5%) 2.6148\n",
      "1m 20s (- 25m 24s) (1 5%) 2.5240\n",
      "1m 46s (- 33m 48s) (1 5%) 2.4414\n",
      "2m 13s (- 42m 13s) (1 5%) 2.4618\n",
      "2m 39s (- 50m 38s) (1 5%) 2.3513\n",
      "3m 6s (- 59m 2s) (1 5%) 2.3600\n",
      "3m 33s (- 67m 27s) (1 5%) 2.3488\n",
      "3m 59s (- 75m 51s) (1 5%) 2.2940\n",
      "4m 26s (- 84m 16s) (1 5%) 2.2474\n",
      "4m 52s (- 92m 40s) (1 5%) 2.1991\n",
      "5m 19s (- 101m 5s) (1 5%) 2.1781\n",
      "5m 45s (- 109m 30s) (1 5%) 2.1724\n",
      "6m 12s (- 117m 54s) (1 5%) 2.0973\n",
      "6m 38s (- 126m 19s) (1 5%) 2.0806\n",
      "7m 5s (- 134m 44s) (1 5%) 2.0396\n",
      "7m 32s (- 143m 9s) (1 5%) 2.0493\n",
      "7m 58s (- 151m 33s) (1 5%) 2.0511\n",
      "8m 25s (- 159m 58s) (1 5%) 2.0343\n",
      "8m 51s (- 168m 23s) (1 5%) 1.9840\n",
      "9m 18s (- 176m 47s) (1 5%) 2.0068\n",
      "9m 44s (- 185m 12s) (1 5%) 1.9850\n",
      "10m 11s (- 193m 37s) (1 5%) 1.9651\n",
      "10m 37s (- 202m 1s) (1 5%) 1.9547\n",
      "11m 4s (- 210m 26s) (1 5%) 1.9098\n",
      "11m 31s (- 218m 51s) (1 5%) 1.9362\n",
      "11m 57s (- 227m 15s) (1 5%) 1.9437\n",
      "12m 24s (- 235m 40s) (1 5%) 1.9062\n",
      "12m 50s (- 244m 5s) (1 5%) 1.9334\n",
      "13m 17s (- 252m 30s) (1 5%) 1.8730\n",
      "13m 43s (- 260m 54s) (1 5%) 1.8932\n",
      "14m 10s (- 269m 19s) (1 5%) 1.8477\n",
      "14m 37s (- 277m 44s) (1 5%) 1.8218\n",
      "15m 3s (- 286m 8s) (1 5%) 1.8317\n",
      "15m 30s (- 294m 33s) (1 5%) 1.8439\n",
      "15m 56s (- 302m 58s) (1 5%) 1.8130\n",
      "16m 23s (- 311m 22s) (1 5%) 1.7800\n",
      "16m 49s (- 319m 47s) (1 5%) 1.7746\n",
      "17m 16s (- 328m 12s) (1 5%) 1.7693\n",
      "17m 43s (- 336m 37s) (1 5%) 1.7935\n",
      "18m 9s (- 345m 1s) (1 5%) 1.7704\n",
      "18m 36s (- 353m 26s) (1 5%) 1.7529\n",
      "---------------------------------------------------------------------\n",
      "----------------Saving trained model---------------------------------\n",
      "---------------------------------------------------------------------\n",
      "18m 55s (- 170m 19s) (2 10%) 1.1775\n",
      "19m 22s (- 174m 18s) (2 10%) 1.7063\n",
      "19m 48s (- 178m 18s) (2 10%) 1.6989\n",
      "20m 15s (- 182m 17s) (2 10%) 1.6952\n",
      "20m 41s (- 186m 16s) (2 10%) 1.7110\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 300\n",
    "encoder1 = EncoderRNN(EMBEDDING_SIZE,hidden_size).to(device)\n",
    "decoder1 = AttnDecoderRNN(EMBEDDING_SIZE,hidden_size, len(ordered_words_ft)).to(device)\n",
    "epoch_size = 20\n",
    "# ##UNCOMMENT TO TRAIN THE MODEL\n",
    "# trainIters(encoder1, decoder1, epoch_size, './attention_model/GRU_TF1_H300_ES20',print_every=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load the best models\n",
    "hidden_size=300\n",
    "\n",
    "folder = './attentation_model'\t\n",
    "\n",
    "encoder2 = EncoderRNN(EMBEDDING_SIZE,hidden_size).to(device)\n",
    "decoder2 = AttnDecoderRNN(EMBEDDING_SIZE,hidden_size, len(ordered_words_ft)).to(device)\n",
    "\n",
    "encoder2.load_state_dict(torch.load(folder+\"/Encoder_b\"))\n",
    "decoder2.load_state_dict(torch.load(folder+\"/Decoder_b\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loader can be test_loader or val_loader\n",
    "def evaluate(loader, encoder, decoder, beam = False, beam_k = 1):\n",
    "    out_predictions = ''\n",
    "    out_references = ''\n",
    "    with torch.no_grad():\n",
    "        for i, (data_s1, data_s2, lengths_s1, lengths_s2) in enumerate(loader):\n",
    "            input_tensor = data_s1\n",
    "            input_length = input_tensor.size()[0]\n",
    "            #sentence_length to the output length\n",
    "            sentence_length = data_s2.size()[1]\n",
    "            encoder_hidden = encoder.initHidden(input_length)\n",
    "\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor, encoder_hidden)\n",
    "            \n",
    "            #decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "            decoder_input = torch.tensor(np.array([[SOS_IDX]]*input_length).reshape(1,input_length),device=device)\n",
    "\n",
    "            decoder_hidden = encoder_hidden\n",
    "\n",
    "            decoder_attentions = torch.zeros(sentence_length, sentence_length)\n",
    "            decoded_words_eval = []\n",
    "            sequences = [[list(), 1.0]]*input_length\n",
    "            for di in range(sentence_length):\n",
    "                decoded_words_sub = []\n",
    "                decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                    decoder_input, decoder_hidden, encoder_output)\n",
    "                # decoder_attentions[di] = decoder_attention.data\n",
    "                # topk(1) - softmax probability maximum\n",
    "                if beam == True:\n",
    "                    pass\n",
    "#                     topv, topi = decoder_output.data.topk(beam_k)\n",
    "#                     #batch loop\n",
    "#                     C = []\n",
    "#                     for idx, ind in enumerate(topi):\n",
    "#                         H, _ = sequences[idx]\n",
    "#                         for ele in ind:\n",
    "#                             if ele.item() == EOS_IDX:\n",
    "#                                 H.append('<EOS>')\n",
    "#                             else:\n",
    "#                                 H.append(idx2words_ft_en[ele.item()])\n",
    "                         \n",
    "                else:\n",
    "                    topv, topi = decoder_output.data.topk(1) \n",
    "                #batch loop\n",
    "                \n",
    "                eos_flag = False\n",
    "                for ind in topi:\n",
    "                    if eos_flag == False:\n",
    "                        if ind.item() == EOS_IDX:\n",
    "                            decoded_words_sub.append('</s>')\n",
    "                            eos_flag = True\n",
    "                            #break\n",
    "                        else:\n",
    "                            decoded_words_sub.append(idx2words_ft_en[ind.item()])\n",
    "                    else:\n",
    "                        decoded_words_sub.append(\"<pad>\")\n",
    "                        \n",
    "                \n",
    "                decoded_words_eval.append(decoded_words_sub)\n",
    "                \n",
    "                #swap dimensions of decoded_words to [batch_size * 377]\n",
    "                \n",
    "                #decoded_words_new = [[i for i in ele] for ele in list(zip(*decoded_words_eval))]\n",
    "\n",
    "                #change the dimension\n",
    "                decoder_input = topi.squeeze().detach()\n",
    "                decoder_input = decoder_input.unsqueeze(0)\n",
    "            \n",
    "            \n",
    "\n",
    "            listed_predictions = ''\n",
    "            \n",
    "            \n",
    "            decoded_words_new = [[i for i in ele] for ele in list(zip(*decoded_words_eval))]\n",
    "            for token_list in decoded_words_new:\n",
    "                sent = ' '.join(str(token) for token in token_list if token!=\"<pad>\")\n",
    "                #print (sent)\n",
    "                listed_predictions= list_predictions + ' '+ sent\n",
    "                \n",
    "            listed_reference = ' '\n",
    "            for ele in data_s2:\n",
    "                sent = index2token_sentence(ele)\n",
    "                #print (tokens)\n",
    "                #sent = ' '.join(tokens)\n",
    "                #print (sent)\n",
    "                listed_reference = listed_reference + ' ' + sent\n",
    "            \n",
    "        out_predictions = out_predictions + ' ' + listed_predictions\n",
    "        out_references = out_references + ' ' + listed_reference\n",
    "        bleu_score = corpus_bleu(out_predictions, out_references)\n",
    "            \n",
    "            #uncommon to print prediction and reference\n",
    "            #print (listed_predictions)\n",
    "            #print (listed_reference)\n",
    "            \n",
    "            \n",
    "        print('BLEU Score is %s' % (str(bleu_score.score)))\n",
    "           \n",
    "        return bleu_score, decoded_words_new, decoder_attentions[:di + 1]\n",
    "    \n",
    "def index2token_batch(list_of_list):\n",
    "    return ' '.join(idx2words_ft_en[r.item()] for v in list_of_list for r in v if r.item()!=PAD_IDX)\n",
    "def index2token_sentence(sentence_batch):\n",
    "    return ' '.join(idx2words_ft_en[sent.item()] for sent in sentence_batch if sent.item()!=PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score is 20.099632842263766\n",
      "BLEU Score is 17.2331000405467\n",
      "BLEU Score is 18.263529593949873\n",
      "BLEU Score is 18.156729843585964\n",
      "BLEU Score is 16.248083583710795\n",
      "BLEU Score is 16.6067262093732\n",
      "BLEU Score is 23.67949056871905\n",
      "BLEU Score is 17.897392446235028\n",
      "BLEU Score is 20.546576246012076\n",
      "BLEU Score is 20.05563999110098\n",
      "BLEU Score is 16.732889645990205\n",
      "BLEU Score is 16.704218238382563\n",
      "BLEU Score is 18.362462385489334\n",
      "BLEU Score is 20.55813622830437\n"
     ]
    }
   ],
   "source": [
    "blue, output_words, attentions = evaluate(val_loader,\n",
    "    encoder1, decoder1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
