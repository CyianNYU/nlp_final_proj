{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sacrebleu\n",
      "  Downloading https://files.pythonhosted.org/packages/37/51/bffea2b666d59d77be0413d35220022040a1f308c39009e5b023bc4eb8ab/sacrebleu-1.2.12.tar.gz\n",
      "Collecting typing (from sacrebleu)\n",
      "  Downloading https://files.pythonhosted.org/packages/4a/bd/eee1157fc2d8514970b345d69cb9975dcd1e42cd7e61146ed841f6e68309/typing-3.6.6-py3-none-any.whl\n",
      "Building wheels for collected packages: sacrebleu\n",
      "  Running setup.py bdist_wheel for sacrebleu ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/yc2462/.cache/pip/wheels/ea/0a/7d/ddcbdcd15a04b72de1b3f78e7e754aab415aff81c423376385\n",
      "Successfully built sacrebleu\n",
      "Installing collected packages: typing, sacrebleu\n",
      "Successfully installed sacrebleu-1.2.12 typing-3.6.6\n"
     ]
    }
   ],
   "source": [
    "# !pip3 install sacrebleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from sacrebleu import corpus_bleu\n",
    "import os\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_to_load = 50000\n",
    "PAD_IDX = 0\n",
    "UNK_IDX = 1\n",
    "SOS_IDX = 2\n",
    "EOS_IDX = 3\n",
    "\n",
    "with open('../cc.zh.300.vec') as f:\n",
    "    loaded_embeddings_ft = np.zeros((words_to_load+3, 300))\n",
    "    words_ft = {}\n",
    "    idx2words_ft = {}\n",
    "    ordered_words_ft = []\n",
    "    ordered_words_ft.extend(['<pad>', '<unk>', '<s>'])\n",
    "    loaded_embeddings_ft[0,:] = np.zeros(300)\n",
    "    loaded_embeddings_ft[1,:] = np.random.normal(size = 300)\n",
    "    loaded_embeddings_ft[2,:] = np.random.normal(size = 300)\n",
    "    for i, line in enumerate(f):\n",
    "        if i >= words_to_load: \n",
    "            break\n",
    "        s = line.split()\n",
    "        loaded_embeddings_ft[i+3, :] = np.asarray(s[1:])\n",
    "        words_ft[s[0]] = i+3\n",
    "        idx2words_ft[i+3] = s[0]\n",
    "        ordered_words_ft.append(s[0])\n",
    "    words_ft['<pad>'] = PAD_IDX\n",
    "    words_ft['<unk>'] = UNK_IDX\n",
    "    words_ft['<s>'] = SOS_IDX\n",
    "    idx2words_ft[PAD_IDX] = '<pad>'\n",
    "    idx2words_ft[UNK_IDX] = '<unk>'\n",
    "    idx2words_ft[SOS_IDX] = '<s>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#English embedding\n",
    "with open('wiki-news-300d-1M.vec') as f:\n",
    "    loaded_embeddings_ft_en = np.zeros((words_to_load+4, 300))\n",
    "    words_ft_en = {}\n",
    "    idx2words_ft_en = {}\n",
    "    ordered_words_ft_en = []\n",
    "    ordered_words_ft_en.extend(['<pad>', '<unk>', '<s>', '</s>'])\n",
    "    loaded_embeddings_ft_en[0,:] = np.zeros(300)\n",
    "    loaded_embeddings_ft_en[1,:] = np.random.normal(size = 300)\n",
    "    loaded_embeddings_ft_en[2,:] = np.random.normal(size = 300)\n",
    "    loaded_embeddings_ft_en[3,:] = np.random.normal(size = 300)\n",
    "    for i, line in enumerate(f):\n",
    "        if i >= words_to_load: \n",
    "            break\n",
    "        s = line.split()\n",
    "        loaded_embeddings_ft_en[i+4, :] = np.asarray(s[1:])\n",
    "        words_ft_en[s[0]] = i+4\n",
    "        idx2words_ft_en[i+4] = s[0]\n",
    "        ordered_words_ft_en.append(s[0])\n",
    "    words_ft_en['<pad>'] = PAD_IDX\n",
    "    words_ft_en['<unk>'] = UNK_IDX\n",
    "    words_ft_en['<s>'] = SOS_IDX\n",
    "    words_ft_en['</s>'] = EOS_IDX\n",
    "    idx2words_ft_en[PAD_IDX] = '<pad>'\n",
    "    idx2words_ft_en[UNK_IDX] = '<unk>'\n",
    "    idx2words_ft_en[SOS_IDX] = '<s>'\n",
    "    idx2words_ft_en[EOS_IDX] = '</s>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in chinese-english pairs\n",
    "lines_zh = open('iwslt-zh-en/train.tok.zh',encoding = 'utf-8').read().strip().split('\\n')\n",
    "lines_en = open('iwslt-zh-en/train.tok.en',encoding = 'utf-8').read().strip().split('\\n')\n",
    "lines_zh_test = open('iwslt-zh-en/test.tok.zh',encoding = 'utf-8').read().strip().split('\\n')\n",
    "lines_en_test = open('iwslt-zh-en/test.tok.en',encoding = 'utf-8').read().strip().split('\\n')\n",
    "lines_zh_val = open('iwslt-zh-en/dev.tok.zh',encoding = 'utf-8').read().strip().split('\\n')\n",
    "lines_en_val = open('iwslt-zh-en/dev.tok.en',encoding = 'utf-8').read().strip().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add sos and eos in each sentence\n",
    "def add_sos_eos(lines):  \n",
    "    train = []\n",
    "    for l in lines:\n",
    "        l = '<s> ' + l + '</s>'\n",
    "        train.append(l)\n",
    "    return train\n",
    "zh_train = add_sos_eos(lines_zh)    \n",
    "en_train = add_sos_eos(lines_en)\n",
    "zh_test = add_sos_eos(lines_zh_test)\n",
    "en_test = add_sos_eos(lines_en_test)\n",
    "zh_val = add_sos_eos(lines_zh_val)\n",
    "en_val = add_sos_eos(lines_en_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert token to id in the dataset\n",
    "def token2index_dataset(tokens_data,eng = False):\n",
    "    indices_data = []\n",
    "    for tokens in tokens_data:\n",
    "        index_list = []\n",
    "        for token in tokens.split():\n",
    "            if eng == False:\n",
    "                try:\n",
    "                    index_list.append(words_ft[token])\n",
    "                except KeyError:\n",
    "                    index_list.append(UNK_IDX)\n",
    "            else:\n",
    "                try:\n",
    "                    index_list.append(words_ft_en[token])\n",
    "                except KeyError:\n",
    "                    index_list.append(UNK_IDX)\n",
    "        indices_data.append(index_list)\n",
    "    return indices_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "zh_train_indices = token2index_dataset(zh_train)\n",
    "en_train_indices = token2index_dataset(en_train,eng = True)\n",
    "zh_test_indices = token2index_dataset(zh_test)\n",
    "en_test_indices = token2index_dataset(en_test,eng = True)\n",
    "zh_val_indices = token2index_dataset(zh_val)\n",
    "en_val_indices = token2index_dataset(en_val,eng = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#max_sentence_length\n",
    "length_of_en = [len(x.split()) for x in en_train]\n",
    "max_sentence_length_en = sorted(length_of_en)[-int(len(length_of_en)*0.01)]\n",
    "length_of_zh = [len(x.split()) for x in zh_train]\n",
    "max_sentence_length_zh = sorted(length_of_zh)[-int(len(length_of_zh)*0.01)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(length_of_zh)[-int(len(length_of_zh)*0.1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Data Loader\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class load_dataset(Dataset):\n",
    "    \"\"\"\n",
    "    Class that represents a train/validation/test dataset that's readable for PyTorch\n",
    "    Note that this class inherits torch.utils.data.Dataset\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data_list_s1,data_list_s2):\n",
    "        \"\"\"\n",
    "        @param data_list_zh: list of Chinese tokens \n",
    "        @param data_list_en: list of English tokens as TARGETS\n",
    "        \"\"\"\n",
    "        self.data_list_s1 = data_list_s1\n",
    "        self.data_list_s2 = data_list_s2\n",
    "        \n",
    "        assert (len(self.data_list_s1) == len(self.data_list_s2))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_list_s1)\n",
    "        \n",
    "    def __getitem__(self, key):\n",
    "        \"\"\"\n",
    "        Triggered when you call dataset[i]\n",
    "        \"\"\"\n",
    "        \n",
    "        token_idx_s1 = self.data_list_s1[key][:max_sentence_length_zh]\n",
    "        token_idx_s2 = self.data_list_s2[key][:max_sentence_length_en]\n",
    "        return [token_idx_s1, token_idx_s2, len(token_idx_s1), len(token_idx_s2)]\n",
    "\n",
    "def collate_func(batch):\n",
    "    \"\"\"\n",
    "    Customized function for DataLoader that dynamically pads the batch so that all \n",
    "    data have the same length\n",
    "    \"\"\"\n",
    "    data_list_s1 = []\n",
    "    data_list_s2 = []\n",
    "    length_list_s1 = []\n",
    "    length_list_s2 = []\n",
    "    for datum in batch:\n",
    "        length_list_s1.append(datum[2])\n",
    "        length_list_s2.append(datum[3])\n",
    "        padded_vec_zh = np.pad(np.array(datum[0]), \n",
    "                                pad_width=((0,max_sentence_length_zh-datum[2])), \n",
    "                                mode=\"constant\", constant_values=0)\n",
    "        padded_vec_en = np.pad(np.array(datum[1]), \n",
    "                                pad_width=((0,max_sentence_length_en-datum[3])), \n",
    "                                mode=\"constant\", constant_values=0)\n",
    "        data_list_s1.append(padded_vec_zh[:max_sentence_length_zh])\n",
    "        data_list_s2.append(padded_vec_en[:max_sentence_length_en])\n",
    "    #print(type(data_list_s1[0]))\n",
    "    if torch.cuda.is_available and torch.has_cudnn:\n",
    "        return [torch.from_numpy(np.array(data_list_s1)).cuda(), torch.from_numpy(np.array(data_list_s2)).cuda(),\n",
    "                torch.LongTensor(length_list_s1).cuda(), torch.LongTensor(length_list_s2).cuda()]\n",
    "    else:    \n",
    "        return [torch.from_numpy(np.array(data_list_s1)), torch.from_numpy(np.array(data_list_s2)),\n",
    "                torch.LongTensor(length_list_s1), torch.LongTensor(length_list_s2)]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "EMBEDDING_SIZE = 300 # fixed as from the input embedding data\n",
    "\n",
    "\n",
    "train_dataset = load_dataset(zh_train_indices, en_train_indices)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=collate_func,\n",
    "                                           shuffle=True)\n",
    "\n",
    "val_dataset = load_dataset(zh_val_indices, en_val_indices)\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_dataset,\n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=collate_func,\n",
    "                                           shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, emb_dim, hidden_size, embed= torch.from_numpy(loaded_embeddings_ft).float(),num_layers=1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.emb_dim = emb_dim\n",
    "        self.num_layers = num_layers \n",
    "\n",
    "        self.embedding = nn.Embedding.from_pretrained(embed, freeze=True)\n",
    "        self.gru = nn.GRU(emb_dim, hidden_size,num_layers=num_layers,batch_first=True)\n",
    "\n",
    "    def forward(self, data, hidden):\n",
    "        \n",
    "        batch_size, seq_len = data.size()\n",
    "        \n",
    "        embed = self.embedding(data)\n",
    "        \n",
    "        output, hidden = self.gru(embed,hidden)\n",
    "        #hidden = [n layers * n directions =1 , batch_size, hidden_size ]\n",
    "        \n",
    "        return output, hidden\n",
    "\n",
    "    # initialize the hidden with random numbers\n",
    "    def initHidden(self,batch_size):\n",
    "        return torch.randn(self.num_layers, batch_size, self.hidden_size,device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self,emb_dim,hidden_size, output_size, embed= torch.from_numpy(loaded_embeddings_ft_en).float(),num_layers=1,\n",
    "                 dropout_p=0.1, max_length=max_sentence_length_zh):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers \n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding.from_pretrained(embed, freeze=True)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "\n",
    "        self.gru = nn.GRU(emb_dim, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, data, hidden,encoder_outputs):\n",
    "        \n",
    "        ### embed: [1 * batch size * emb_dim = 300 ] ###\n",
    "        ### hidden: [1 * batch size * hidden_size = 300 ] ###\n",
    "        ### encoder_outputs: [batch size * max_sentence_length_zh * hidden_size = 300 ] ###\n",
    "        ### 因为这里concat之后，attn layer 他给的是 hidden size *2 \n",
    "        ### 所以我这儿的hidden size就只能写300了 \n",
    "        \n",
    "        embed = self.embedding(data)\n",
    "        embed = self.dropout(embed)    \n",
    "        ### torch.cat((embed, hidden), 2)  \n",
    "        ### [1 * batch size * (emb_dim + hidden_size) ]\n",
    "        \n",
    "        ### attn_weights: [1 * batch size * max_sentence_length_zh ]###\n",
    "        ### attn_weights[0].unsqueeze(1): [batch size * 1 * max_sentence_length_zh ]###\n",
    "        \n",
    "        ### softmax dim=2 因为最后一个dimension是 词组什么的，不能是1，1的话就是\n",
    "        ### 不同batch间这样比较了？\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embed, hidden), 2)), dim=2)\n",
    "        \n",
    "\n",
    "        ### torch.bmm(attn_weights[0].unsqueeze(1),encoder_outputs).squeeze(1) :\n",
    "        ### [batch size * 1 * hidden_size ]###\n",
    "\n",
    "        ### attn_applied: [batch size * hidden_size (= 300) ] ###\n",
    "        attn_applied = torch.bmm(attn_weights[0].unsqueeze(1), encoder_outputs).squeeze(1)\n",
    "        \n",
    "        ### output: [batch size * hidden_size (= 300) ] ###\n",
    "        ### embed[0]: [batch size * hidden_size (= 300) ] ###\n",
    "\n",
    "        output = torch.cat((embed[0], attn_applied), 1)\n",
    " \n",
    "        ### output: [1 * batch size * hidden_size (= 300) ] ###\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "        \n",
    "        ### output: [1 * batch size * hidden_size (= 300) ] ###\n",
    "        output = F.relu(output)\n",
    "        \n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        \n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self,batch_size):\n",
    "        return torch.randn(self.num_layers, batch_size, self.hidden_size,device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "#input_tensor: list of sentence tensor\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer,\n",
    "          criterion, eee):\n",
    "    \n",
    "    ### target_tensor [batch size, max_sentence_length_en = 377] ###\n",
    "    ### target_tensor [batch size, max_sentence_length_zh = 220] ###\n",
    "    batch_size_1, input_length = input_tensor.size()\n",
    "    batch_size_2, target_length = target_tensor.size()\n",
    "    \n",
    "    \n",
    "    encoder_hidden = encoder.initHidden(batch_size_1)\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    loss = 0\n",
    "    ### encoder_hidden: 1 * batch * hidden size ### \n",
    "    ### encoder_output: batch size * max_sentence_length_zh * hidden size ### \n",
    "    encoder_output, encoder_hidden = encoder(input_tensor, encoder_hidden)\n",
    "\n",
    "    decoder_input = torch.tensor(np.array([[SOS_IDX]]*batch_size_1).reshape(1,batch_size_1),device=device)\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "    #print(use_teacher_forcing)\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            \n",
    "            ### decoder_output: [batchsize,5000] ###\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden,encoder_output)\n",
    "            \n",
    "            loss += criterion(decoder_output, target_tensor[:,di])\n",
    "            decoder_input = target_tensor[:,di].unsqueeze(0)  # Teacher forcing\n",
    "            \n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden,encoder_output)\n",
    "                        \n",
    "            ### decoder_output [batch size, 50003]  ###\n",
    "            \n",
    "            ### topi is a [batch size, 1] tensor first we remove the size 1\n",
    "            ### demension then we add it at the beginning using squeeze\n",
    "            ### 有点脑残诶，做个转置不就好了？\n",
    "            \n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "            \n",
    "            ### decoder_input [1, batch size]  ###\n",
    "            decoder_input = decoder_input.unsqueeze(0)\n",
    " \n",
    "            loss += criterion(decoder_output, target_tensor[:,di])\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, n_iters, print_every=1, plot_every=100, learning_rate=0.001):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "    \n",
    "    #--------------------------------------------\t\n",
    "    #\t\n",
    "    #    LOAD MODELS\t\n",
    "    #\t\n",
    "    #--------------------------------------------\t\n",
    "    folder = '.'\t\n",
    "    if not os.path.exists(folder):\t\n",
    "        os.makedirs(folder)\t\n",
    "\n",
    "    if os.path.exists('./attentation_model/Encoder_b'):\t\n",
    "        print('---------------------------------------------------------------------')\t\n",
    "        print('----------------Readind trained model---------------------------------')\t\n",
    "        print('---------------------------------------------------------------------')\t\n",
    "        \t\n",
    "        #read trained models\t\n",
    "        encoder.load_state_dict(torch.load(folder+\"/Encoder_b\"))\n",
    "        decoder.load_state_dict(torch.load(folder+\"/Decoder_b\"))\t\n",
    "    \n",
    "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        for i, (data_s1, data_s2, lengths_s1, lengths_s2) in enumerate(train_loader):\n",
    "            input_tensor = data_s1\n",
    "            target_tensor = data_s2\n",
    "            #print(\"train\",target_tensor.size())\n",
    "            loss = train(input_tensor, target_tensor, encoder,\n",
    "                         decoder, encoder_optimizer, decoder_optimizer, criterion,i)\n",
    "            print_loss_total += loss\n",
    "            plot_loss_total += loss\n",
    "\n",
    "            if i % print_every == 0:\n",
    "                print_loss_avg = print_loss_total / print_every\n",
    "                print_loss_total = 0\n",
    "                print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                             iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "            if i % plot_every == 0:\n",
    "                plot_loss_avg = plot_loss_total / plot_every\n",
    "                plot_losses.append(plot_loss_avg)\n",
    "                plot_loss_total = 0\n",
    "                \n",
    "        # Save the model for every epoch\n",
    "        print('---------------------------------------------------------------------')\t\n",
    "        print('----------------Saving trained model---------------------------------')\t\n",
    "        print('---------------------------------------------------------------------')\t\n",
    "      \n",
    "        torch.save(encoder.state_dict(),folder +\"/Encoder_b\")\n",
    "        torch.save(decoder.state_dict(),folder +\"/Decoder_b\")\n",
    "\n",
    "    \n",
    "    return plot_losses\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)\n",
    "    \n",
    "import time\n",
    "import math\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# beam search + bleu score\n",
    "def beam_search_decoder(data, k):\n",
    "    sequences = [[list(), 1.0]]\n",
    "    # walk over each step in sequence\n",
    "    for row in data:\n",
    "        all_candidates = list()\n",
    "        # expand each current candidate\n",
    "        for i in range(len(sequences)):\n",
    "            seq, score = sequences[i]\n",
    "            for j in range(len(row)):\n",
    "                candidate = [seq + [j], score * -log(row[j])]\n",
    "                all_candidates.append(candidate)\n",
    "        # order all candidates by score\n",
    "        ordered = sorted(all_candidates, key=lambda tup:tup[1])\n",
    "        # select top best\n",
    "        sequences = ordered[:1]\n",
    "    return sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index2token_sentence(sentence_batch):\n",
    "    return ' '.join(idx2words_ft_en[sent.item()] for sent in sentence_batch if sent.item()!=PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class decoder_output_node:\n",
    "    def __init__(self,parent, word_idx, prob_sum, isroot=False):\n",
    "        self.parent = parent\n",
    "        self.isroot = isroot\n",
    "        self.children = []\n",
    "        self.word_idx = word_idx\n",
    "        self.prob_sum = prob_sum\n",
    "    \n",
    "    def get_children(self):\n",
    "        '''\n",
    "        return children\n",
    "        '''\n",
    "        return self.children\n",
    "    \n",
    "    def add_children(self, child):\n",
    "        '''\n",
    "        child: node\n",
    "        '''\n",
    "        self.children.append(child)\n",
    "        return\n",
    "    \n",
    "    def get_parent(self):\n",
    "        '''\n",
    "        get parent of children\n",
    "        '''\n",
    "        return self.parent\n",
    "    \n",
    "    def get_word_idx(self):\n",
    "        \n",
    "        return self.word_idx\n",
    "    \n",
    "    def get_prob_sum(self):\n",
    "        \n",
    "        return self.prob_sum\n",
    "    \n",
    "    def is_root(self):\n",
    "        return self.isroot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_sentence_sequence(child_node):\n",
    "    if child_node.is_root():\n",
    "        return [child_node.get_word_idx()]\n",
    "    \n",
    "    return return_sentence_sequence(child_node.get_parent())+[child_node.get_word_idx()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beam_search(beam_k, decoder_output, prob_sum = None, parent_node_list=None, vocab_size = len(idx2words_ft_en)-1):\n",
    "    '''\n",
    "    params:\n",
    "    beam_k\n",
    "    decoder_output: previous round decoder output\n",
    "    parent_node_list: previous candidate word list (for only one candidate)\n",
    "    \n",
    "    return:\n",
    "    list_of_best_k_nodes: best k nodes found in this iteration, list of list, first dim batch, second dim best k\n",
    "    prob_with_sum: probabilistic matrix after sum+sortee \n",
    "    '''\n",
    "    # if first word\n",
    "    if parent_node_list is None:\n",
    "        # initialize result\n",
    "        prob_with_sum_sorted, word_idx_sorted = decoder_output.data.topk(beam_k)\n",
    "        \n",
    "        # add initialize tree list\n",
    "        list_of_best_k_nodes = []\n",
    "        batchsize = prob_with_sum_sorted.shape[0]\n",
    "        for batch_i in range(batchsize):\n",
    "            batch_i_tree_list = []\n",
    "            for beam_i in range(beam_k):\n",
    "                # add tree root node to list\n",
    "                batch_i_tree_list.append(decoder_output_node(parent=None, word_idx=word_idx_sorted[batch_i, beam_i].item(), \n",
    "                                                            prob_sum= prob_with_sum_sorted[batch_i, beam_i].item(), isroot=True))\n",
    "                \n",
    "            list_of_best_k_nodes.append(batch_i_tree_list)\n",
    "   \n",
    "    # if not first word\n",
    "    else:\n",
    "        # get sorted results for all outputs\n",
    "        prob, word_idx = decoder_output.data.topk(vocab_size)\n",
    "        #print(decoder_output.data.data.topk(vocab_size))\n",
    "        #print(word_idx)\n",
    "        \n",
    "        \n",
    "        # find top beam k words options\n",
    "        prob_with_sum = prob+prob_sum\n",
    "        prob_with_sum_sorted, word_idx_sorted = torch.sort(prob_with_sum, dim=1, descending=True)\n",
    "        \n",
    "        # add top beam k words options into tree\n",
    "        batchsize = prob_with_sum_sorted.shape[0]\n",
    "        \n",
    "        list_of_best_k_nodes = []\n",
    "        for batch_i in range(batchsize):\n",
    "            batch_i_tree_list = []\n",
    "            for beam_i in range(beam_k):\n",
    "                #print(word_idx_sorted[batch_i, beam_i])\n",
    "                #print(parent_node_list[batch_i].get_word_idx())\n",
    "                child_node = decoder_output_node(parent=parent_node_list[batch_i], word_idx= word_idx[batch_i,word_idx_sorted[batch_i,beam_i]].item(), prob_sum=prob_with_sum_sorted[batch_i,beam_i].item())\n",
    "                # update parent node's child\n",
    "                parent_node_list[batch_i].add_children(child_node)\n",
    "                #save child to new list\n",
    "                batch_i_tree_list.append(child_node)\n",
    "            # add batch tree list to best k\n",
    "            list_of_best_k_nodes.append(batch_i_tree_list)\n",
    "                \n",
    "    return list_of_best_k_nodes, prob_with_sum_sorted[:,:beam_k], word_idx_sorted[:,:beam_k]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "['<s> And <unk> <unk>', '<s> And <unk>', '<s> And , <unk> <unk>', '<s> <s> <unk>', '<s> And <unk> <unk>', '<s> And <unk> <unk>', '<s> And <unk> <unk>', '<s> And <unk> <unk>', '<s> And <unk> <unk>', '<s> <s> , <unk> <unk>', '<s> And <unk> <unk>', '<s> And <unk> <unk>', '<s> And , <unk> <unk>', '<s> And <unk> <unk>', '<s> And <unk>', '<s> And <unk> <unk>', '<s> And <unk> <unk>', '<s> And <unk> <unk>', '<s> <s> <unk> <unk>', '<s> And <unk>', '<s> And <unk>', '<s> And <unk> <unk>', '<s> And <unk> <unk>', '<s> And , <unk> <unk>', '<s> And <unk> <unk>', '<s> <s> <unk>', '<s> <s> , , <unk>', '<s> And , , <unk>', '<s> And , , <unk> <unk>', '<s> And <unk> <unk>', '<s> And , , <unk> <unk>', '<s> And <unk> <unk> <unk>']\n",
      "BLEU Score is 6.370453494395023\n",
      "1\n",
      "['<s> And <unk> <unk>', '<s> <s> , , <unk>', '<s> <s> <unk>', '<s> And <unk>', '<s> And <unk> <unk>', '<s> And , , <unk>', '<s> And <unk> <unk>', '<s> And , , <unk>', '<s> And , , <unk> <unk>', '<s> And <unk>', '<s> And <unk> <unk>', '<s> And , , <unk>', '<s> And , <unk> <unk>', '<s> <s> , <unk>', '<s> And <unk> <unk> <unk>', '<s> And , <unk> <unk>', '<s> And , <unk> <unk>', '<s> And , <unk> <unk>', '<s> And , <unk> <unk>', '<s> And , <unk> <unk>', '<s> And <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> <s> , , <unk> <unk>', '<s> And <unk>', '<s> And <unk> <unk>', '<s> And <unk>', '<s> And <unk>', '<s> And <unk> <unk> <unk>', '<s> <s> , , <unk>', '<s> And <unk>', '<s> And <unk>', '<s> And <unk> <unk> <unk>']\n",
      "BLEU Score is 3.8648881919424753\n",
      "2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-89-d6bb696ec3f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m                     \u001b[0;31m# get beam search output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m                     \u001b[0mbest_k_curr_node\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob_sum_curr_node\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbeam_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeam_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob_sum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprob_sum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent_node_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbeam_i\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mls\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist_of_best_k_nodes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m                     \u001b[0;31m#print(word_idx_curr_node)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-83-f0183505d9d2>\u001b[0m in \u001b[0;36mbeam_search\u001b[0;34m(beam_k, decoder_output, prob_sum, parent_node_list, vocab_size)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;31m# find top beam k words options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mprob_with_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprob\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mprob_sum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mprob_with_sum_sorted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_idx_sorted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprob_with_sum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;31m# add top beam k words options into tree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# beam search temp eval\n",
    "beam_k = 3\n",
    "with torch.no_grad():\n",
    "    for i, (data_s1, data_s2, lengths_s1, lengths_s2) in enumerate(val_loader):\n",
    "        print(i)\n",
    "        input_tensor = data_s1\n",
    "        input_length = input_tensor.size()[0]\n",
    "        #sentence_length to the output length\n",
    "        sentence_length = data_s2.size()[1]\n",
    "        encoder_hidden = encoder1.initHidden(input_length)\n",
    "\n",
    "        encoder_output, encoder_hidden = encoder1(input_tensor, encoder_hidden)\n",
    "\n",
    "        #decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "        decoder_input = torch.tensor(np.array([[SOS_IDX]]*input_length).reshape(1,input_length),device=device)\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoder_attentions = torch.zeros(sentence_length, sentence_length)\n",
    "        decoded_words_eval = []\n",
    "        list_of_best_k_nodes = []\n",
    "        \n",
    "        for di in range(sentence_length):\n",
    "            \n",
    "            ############################################beam search###################################################\n",
    "            if di == 0:\n",
    "                decoded_words_sub = []\n",
    "                \n",
    "                \n",
    "                decoder_output, decoder_hidden, decoder_attention = decoder1(\n",
    "                                decoder_input, decoder_hidden, encoder_output)\n",
    "                \n",
    "                # find top k candidates\n",
    "                list_of_best_k_nodes,prob_with_sum_sorted ,word_idx_sorted = beam_search(beam_k, decoder_output, parent_node_list=None)\n",
    "                #print(word_idx_sorted)\n",
    "                #print(list_of_best_k_nodes[0][0].get_word_idx())\n",
    "                #print(list_of_best_k_nodes[0][1].get_word_idx())\n",
    "                \n",
    "            else:\n",
    "                # keep track of all new nodes\n",
    "                new_nodes = []\n",
    "                nodes_prob = None\n",
    "                #nodes_word_idx = None\n",
    "                \n",
    "                # store index in previous candidate to locate position in new nodes, repeats=beam_size*beam_size\n",
    "                prev_candidate_idx = np.repeat(range(beam_k), repeats=beam_k*beam_k)\n",
    "                #print(prev_candidate_idx)\n",
    "                \n",
    "                # iterate through each node candidate from last iterations to find new candidates\n",
    "                for beam_i in range(beam_k):\n",
    "                    #print(word_idx_sorted.shape)\n",
    "                    topi = word_idx_sorted[:,beam_i]\n",
    "                    #print(topi)\n",
    "                    prob_sum = prob_with_sum_sorted[:,beam_i].view((input_length,1))\n",
    "                    \n",
    "                    #change the dimension\n",
    "                    decoder_input = topi.squeeze().detach()\n",
    "                    decoder_input = decoder_input.unsqueeze(0)\n",
    "                \n",
    "                    # get decoder output\n",
    "                    decoder_output, decoder_hidden, decoder_attention = decoder1(\n",
    "                                decoder_input, decoder_hidden, encoder_output)\n",
    "                    \n",
    "                    # get beam search output\n",
    "                    best_k_curr_node, prob_sum_curr_node, _ = beam_search(beam_k, decoder_output, prob_sum=prob_sum, parent_node_list=[ls[beam_i] for ls in list_of_best_k_nodes])\n",
    "                    #print(word_idx_curr_node)\n",
    "                    \n",
    "                    # keep track of beam search output\n",
    "                    new_nodes.append(best_k_curr_node)\n",
    "                    \n",
    "                    if beam_i == 0:\n",
    "                        nodes_prob = prob_sum_curr_node\n",
    "                        \n",
    "                        #nodes_word_idx = word_idx_curr_node\n",
    "                    else:\n",
    "                        nodes_prob = torch.cat((nodes_prob, prob_sum_curr_node),dim=1)\n",
    "                        #nodes_word_idx = torch.cat((nodes_word_idx, word_idx_curr_node),dim=1)\n",
    "                \n",
    "                _, sorted_idx = torch.sort(nodes_prob, dim=1, descending=True)\n",
    "                #print(\"length\",nodes_prob.shape)\n",
    "                \n",
    "                # update \n",
    "                #print(sorted_idx.shape)\n",
    "                for batch_i in range(input_length):\n",
    "                    for beam_i in range(beam_k):\n",
    "                        # find the index of which candidate it descended from\n",
    "                        st_idx = sorted_idx[batch_i][beam_i].item()\n",
    "                        # find the corresponding node, st_idx gives parent node id, batch_i gives which example, st_idx%beam_k gives which node in the existing node list\n",
    "                        #print(st_idx)\n",
    "                        update_node = new_nodes[prev_candidate_idx[st_idx]][batch_i][st_idx%beam_k]\n",
    "                        \n",
    "                        list_of_best_k_nodes[batch_i][beam_i] = update_node\n",
    "                        #print(batch_i)\n",
    "                        #print(beam_i)\n",
    "                        #print(list_of_best_k_nodes[0][0].parent.get_word_idx())\n",
    "                        \n",
    "                        # update word idex, prob sum correspondingly for next iteration\n",
    "                        #word_idx_sorted[batch_i][beam_i] = nodes_word_idx[batch_i][st_idx] \n",
    "                        word_idx_sorted[batch_i][beam_i] = update_node.get_word_idx()\n",
    "                        prob_with_sum_sorted[batch_i][beam_i] = update_node.get_prob_sum()\n",
    "            \n",
    "        # find the best and get index\n",
    "        listed_predictions = []\n",
    "        for batch_i in range(input_length):\n",
    "            best_sequence_last_node = list_of_best_k_nodes[batch_i][0]\n",
    "            batch_i_word_idx = return_sentence_sequence(best_sequence_last_node)\n",
    "            \n",
    "            listed_predictions.append(' '.join(idx2words_ft_en[token_idx] for token_idx in batch_i_word_idx if token_idx!=PAD_IDX))\n",
    "            #print(batch_i_word_idx)\n",
    "        listed_reference = []\n",
    "        for ele in data_s2:\n",
    "            sent = index2token_sentence(ele)\n",
    "            \n",
    "            listed_reference.append(sent)\n",
    "            \n",
    "        print(listed_predictions)\n",
    "        bleu_score = corpus_bleu(listed_predictions,[listed_reference])\n",
    "        print('BLEU Score is %s' % (str(bleu_score.score)))\n",
    "\n",
    "        ############################################beam search###################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(171, device='cuda:0')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_best_k_nodes[0][0].parent.get_word_idx()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "#loader can be test_loader or val_loader\n",
    "def evaluate(loader, encoder, decoder, beam = False, beam_k = 1, threshold = 0.5):\n",
    "    bleu_score_list = []\n",
    "    with torch.no_grad():\n",
    "        for i, (data_s1, data_s2, lengths_s1, lengths_s2) in enumerate(loader):\n",
    "            print(i)\n",
    "            input_tensor = data_s1\n",
    "            input_length = input_tensor.size()[0]\n",
    "            #sentence_length to the output length\n",
    "            sentence_length = data_s2.size()[1]\n",
    "            encoder_hidden = encoder.initHidden(input_length)\n",
    "\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor, encoder_hidden)\n",
    "            \n",
    "            #decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "            decoder_input = torch.tensor(np.array([[SOS_IDX]]*input_length).reshape(1,input_length),device=device)\n",
    "\n",
    "            decoder_hidden = encoder_hidden\n",
    "\n",
    "            decoder_attentions = torch.zeros(sentence_length, sentence_length)\n",
    "            decoded_words_eval = []\n",
    "            # EOS_IDX tensor matrix\n",
    "            test_matrix = torch.ones(input_length, beam_k)*EOS_IDX\n",
    "            out_sequences = []\n",
    "            for di in range(sentence_length):\n",
    "                decoded_words_sub = []\n",
    "                if beam == True:\n",
    "#                     pass\n",
    "                    #input length is the batch_size \n",
    "                    last_word_matrix = torch.zeros([input_length, beam_k])\n",
    "                    # if all last word are the EOS_IDX then break\n",
    "                    if torch.nonzero(last_word_matrix==test_matrix).size(0) >= threshold*input_length*beam_k:\n",
    "                        break\n",
    "                    # initiate\n",
    "                    if di == 0:\n",
    "                        decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                            decoder_input, decoder_hidden, encoder_output)\n",
    "                        prob, elements = decoder_output.data.topk(beam_k)\n",
    "                        #batch loop\n",
    "                        for idx, ind in enumerate(elements):\n",
    "                            sequences = []\n",
    "                            for idx2 in range(beam_k):\n",
    "                                # ind[idx2] is the index of vocab\n",
    "                                sequences.append(([ind[idx2].item()], prob[idx][idx2].item()))\n",
    "                                last_word_matrix[idx, idx2] = ind[idx2]\n",
    "                            out_sequences.append(sequences)\n",
    "                    else:\n",
    "                        # shape of decoder output is 1 less than english vocab size, why?\n",
    "                        prob, elements = decoder_output.data.topk(len(idx2words_ft_en)-1)\n",
    "                        #batch loop\n",
    "                        for idx, ind in enumerate(elements):\n",
    "                            #score_list : (1*vocab_size)\n",
    "                            '''\n",
    "                            ? whether score_list make sense\n",
    "                            last_word_matrix every element needs to be tensor\n",
    "                            '''\n",
    "                            score_list = list(prob[idx].cpu())\n",
    "                            updated_dic = {}\n",
    "                            for idx2 in range(beam_k):\n",
    "                                # vocab size list (log)prob + the (log)prob \n",
    "                                updated_score_list = np.array(score_list) + np.array([out_sequences[idx][idx2][1]]*len(score_list))\n",
    "                                #length of vocab_size\n",
    "                                for idx3, ele in enumerate(updated_score_list):\n",
    "                                    # key is the tuple of two indices of vocab # out_sequences[idx][idx2][0]\n",
    "                                    updated_dic[(idx2, idx3)] = ele\n",
    "                            # sort all the dict values and output the keys (tuple of two indices)\n",
    "                            optimal = dict(sorted(updated_dic.items(), key=operator.itemgetter(1), reverse=True)[:beam_k])\n",
    "                            \n",
    "                            #change a dictionary to list of tuples and override it to the out_sequences\n",
    "                            for index, (k, v) in enumerate(optimal.items()):\n",
    "                                (k1, k2) = k\n",
    "                                out_sequences[idx] = [(out_sequences[idx][k1][0].append(k2), v)]\n",
    "                                last_word_matrix[idx][index] = k2\n",
    "                    \n",
    "                    #######################temp##############\n",
    "                    #need to iterate through topi for all choi\n",
    "                    topi = last_word_matrix[:,0]\n",
    "                    #######################temp##############\n",
    "                    # select the first column of out_sequence (which has the hightest softmax value) to do the corpus_blue\n",
    "                    '''\n",
    "                    TO DO\n",
    "                    '''\n",
    "                else:\n",
    "                    decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                        decoder_input, decoder_hidden, encoder_output)\n",
    "                    # topk(1) - softmax probability maximum\n",
    "                    topv, topi = decoder_output.data.topk(1) \n",
    "                    #print(topi)\n",
    "                    #batch loop\n",
    "                \n",
    "                for ind in topi:\n",
    "                    if ind.item() == EOS_IDX:\n",
    "                        decoded_words_sub.append('</s>')\n",
    "                        break\n",
    "                    else:\n",
    "                        decoded_words_sub.append(idx2words_ft_en[ind.item()])\n",
    "                decoded_words_eval.append(decoded_words_sub)\n",
    "\n",
    "                #change the dimension\n",
    "                decoder_input = topi.squeeze().detach()\n",
    "                decoder_input = decoder_input.unsqueeze(0)\n",
    "\n",
    "            pred_num = 0\n",
    "            listed_predictions = []\n",
    "            #swap dimensions of decoded_words to [batch_size * 377]\n",
    "            decoded_words_new = [[i for i in ele] for ele in list(zip(*decoded_words_eval))]\n",
    "           # print(decoded_words_new)\n",
    "            for token_list in decoded_words_new:\n",
    "                sent = ' '.join(token for token in token_list if token!=\"<pad>\")\n",
    "                #print(len(token_list))\n",
    "                #print (sent)\n",
    "                listed_predictions.append(sent)\n",
    "                pred_num += 1\n",
    "                \n",
    "            ref_num = 0\n",
    "            listed_reference = []\n",
    "            for ele in data_s2:\n",
    "                sent = index2token_sentence(ele)\n",
    "                #print (tokens)\n",
    "                #sent = ' '.join(tokens)\n",
    "                #print (sent)\n",
    "                listed_reference.append(sent)\n",
    "                ref_num += 1\n",
    "            print(listed_predictions)\n",
    "            bleu_score = corpus_bleu(listed_predictions,[listed_reference])\n",
    "            print('BLEU Score is %s' % (str(bleu_score.score)))\n",
    "        bleu_score_list.append(bleu_score)\n",
    "        return bleu_score_list, decoded_words_new, decoder_attentions[:di + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 0s (- 0m 0s) (1 100%) 0.2166\n",
      "0m 11s (- 0m 0s) (1 100%) 3.2614\n",
      "0m 21s (- 0m 0s) (1 100%) 2.2029\n",
      "0m 32s (- 0m 0s) (1 100%) 2.0147\n",
      "0m 43s (- 0m 0s) (1 100%) 1.9650\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-76aa6300f398>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# ##UNCOMMENT TO TRAIN THE MODEL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtrainIters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;31m#encoder1.load_state_dict(torch.load(\"encoder.pt\"))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#decoder1.load_state_dict(torch.load(\"decoder.pt\"))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-a0a1db10d32b>\u001b[0m in \u001b[0;36mtrainIters\u001b[0;34m(encoder, decoder, n_iters, print_every, plot_every, learning_rate)\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;31m#print(\"train\",target_tensor.size())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             loss = train(input_tensor, target_tensor, encoder,\n\u001b[0;32m---> 36\u001b[0;31m                          decoder, encoder_optimizer, decoder_optimizer, criterion,i)\n\u001b[0m\u001b[1;32m     37\u001b[0m             \u001b[0mprint_loss_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mplot_loss_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-83ca6d4eab32>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, eee)\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_tensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pytorch-gpu/py3.6.3/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pytorch-gpu/py3.6.3/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hidden_size = 300\n",
    "encoder1 = EncoderRNN(EMBEDDING_SIZE,hidden_size).to(device)\n",
    "decoder1 = AttnDecoderRNN(EMBEDDING_SIZE,hidden_size, len(ordered_words_ft)).to(device)\n",
    "\n",
    "# ##UNCOMMENT TO TRAIN THE MODEL\n",
    "trainIters(encoder1, decoder1, 1, print_every=50)\n",
    "#encoder1.load_state_dict(torch.load(\"encoder.pt\"))\n",
    "#decoder1.load_state_dict(torch.load(\"decoder.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "['<s> And , , <unk> <unk>', '<s> And <unk> <unk>', '<s> And , , , , , , <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> And , <unk> <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And , <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> And , , , , , , <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk> <unk>', '<s> And , , <unk> <unk> <unk> <unk>', '<s> And , , <unk> <unk> <unk>', '<s> And , <unk> <unk>', '<s> And <unk> <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> And , , <unk> <unk> <unk>', '<s> And , <unk> <unk> <unk>', '<s> And , , , , , , , <unk> <unk> <unk> <unk>', '<s> And , <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk> <unk> <unk> <unk>', '<s> And , , , <unk> <unk> <unk> <unk> <unk> <unk>', '<s> And , , , <unk> <unk> <unk> <unk> <unk> <unk> <unk>', '<s> <s> And , <unk> <unk> <unk>', '<s> And , , , <unk> <unk> <unk> <unk> <unk>', '<s> And , , <unk> <unk> <unk> <unk> <unk>']\n",
      "BLEU Score is 8.518313347932908\n",
      "1\n",
      "['<s> And <unk> <unk> <unk> <unk>', '<s> And , , , , , <unk> <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> <s> And , <unk> <unk> <unk>', '<s> And , , , , <unk> <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> And , , , , , , <unk> <unk> <unk>', '<s> <s> <s> <s> <s> I , , , , , , <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> <s> And <unk> <unk> <unk>', '<s> And , , , <unk> <unk> <unk> <unk>', '<s> <s> And , , , , , <unk> <unk> <unk> <unk>', '<s> <s> <s> <s> I , , <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk> <unk> <unk> <unk>', '<s> <s> And , , , , , , , , , , , <unk> <unk> <unk>', '<s> And , , , , , , , , , , <unk> <unk> <unk>', '<s> <s> And , <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>', '<s> And , , <unk> <unk> <unk> <unk> <unk>', '<s> And , , , , , , <unk> <unk> <unk> <unk>', '<s> And , <unk> <unk> <unk>', '<s> And , , <unk> <unk> <unk> <unk> <unk>', '<s> And , , <unk> <unk> <unk> <unk> <unk> <unk>', '<s> And , <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> <s> And , , <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And , , , , <unk> <unk> <unk> <unk> <unk> <unk>', '<s> And , , , , , <unk> <unk> <unk> <unk>', '<s> <s> And <unk> <unk> <unk>', '<s> <s> And <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk> <unk> <unk>']\n",
      "BLEU Score is 7.957585783687668\n",
      "2\n",
      "['<s> And , , , <unk> <unk> <unk> <unk> <unk> <unk>', '<s> <s> And , , , , <unk> <unk> <unk> <unk> <unk>', '<s> And <unk> <unk>', '<s> And , , , , , , , <unk> <unk> <unk>', '<s> And , <unk> <unk> <unk>', '<s> And , , , , , , , <unk> <unk> <unk>', '<s> And , , <unk> <unk> <unk> <unk> <unk>', '<s> And , , , , , , , , , <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> <s> And <unk> <unk> <unk> <unk>', '<s> <s> And , , , , <unk> <unk> <unk>', '<s> And , , <unk> <unk>', '<s> And , , , , , , <unk> <unk> <unk> <unk>', '<s> And , <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And , <unk> <unk>', '<s> And <unk> <unk> <unk> <unk> <unk> <unk> <unk>', '<s> <s> And , <unk> <unk>', '<s> And , , <unk> <unk> <unk> <unk> <unk> <unk>', '<s> And , , <unk> <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And , , , <unk> <unk> <unk> <unk> <unk>', '<s> And , <unk> <unk> <unk>', '<s> And , <unk> <unk>', '<s> And , <unk> <unk> <unk> <unk>', '<s> <s> And , , , , <unk> <unk> <unk> <unk>', '<s> And , <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> <s> And , , , , , , <unk> <unk> <unk>', '<s> And , , , , <unk> <unk> <unk> <unk>']\n",
      "BLEU Score is 13.928126810633128\n",
      "3\n",
      "['<s> And <unk> <unk> <unk> <unk>', '<s> And , , , , <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And , , , , , , , <unk> <unk> <unk> <unk>', '<s> And , , , , , , , , <unk> <unk> <unk>', '<s> And <unk> <unk>', '<s> And , , , , , , , , , <unk> <unk> <unk>', '<s> <s> And <unk> <unk> <unk>', '<s> <s> And <unk> <unk> <unk>', '<s> And , <unk> <unk> <unk>', '<s> And , <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> <s> And , , , , , <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> <s> And , , , , , , , , <unk> <unk> <unk>', '<s> <s> And <unk> <unk> <unk>', '<s> And <unk> <unk>', '<s> <s> And , , , , , , , , , <unk> <unk> <unk>', '<s> And , <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>', '<s> And , , , , , , <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And , , , , <unk> <unk> <unk> <unk> <unk>', '<s> And , , <unk> <unk> <unk>', '<s> <s> And , , , , <unk> <unk> <unk> <unk> <unk>', '<s> And , , , , , , , , , , , <unk> <unk>', '<s> <s> And , , , , , <unk> <unk> <unk>']\n",
      "BLEU Score is 8.362111830746622\n",
      "4\n",
      "['<s> <s> And , , , , , , <unk> <unk> <unk> <unk>', '<s> <s> And , <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> <s> And <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And , , <unk> <unk> <unk>', '<s> And , , <unk> <unk> <unk> <unk> <unk> <unk> <unk>', '<s> And , , , , , , <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And , , , , , , <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And , , , , , <unk> <unk> <unk> <unk>', '<s> And , <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> <s> And , <unk> <unk> <unk> <unk>', '<s> And , , <unk> <unk> <unk> <unk> <unk> <unk>', '<s> And , <unk> <unk> <unk>', '<s> <s> And <unk> <unk> <unk> <unk>', '<s> <s> And , , , <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> <s> And , <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> <s> And <unk> <unk> <unk>', '<s> <s> And , , , <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk> <unk>', '<s> And , , , , , <unk> <unk> <unk> <unk>', '<s> And , , , , , , , <unk> <unk> <unk> <unk>', '<s> And , <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>']\n",
      "BLEU Score is 8.72904107469353\n",
      "5\n",
      "['<s> And , , , <unk> <unk> <unk>', '<s> And , , , , , <unk> <unk> <unk> <unk>', '<s> And , <unk> <unk> <unk>', '<s> And , <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> And , <unk> <unk> <unk>', '<s> <s> And , , , , , , , <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And , , , <unk> <unk> <unk>', '<s> <s> <s> I <unk> <unk> <unk>', '<s> <s> And <unk> <unk> <unk> <unk>', '<s> And , , , , , <unk> <unk> <unk>', '<s> And , , , <unk> <unk> <unk> <unk> <unk>', '<s> And , , , , , , , , , , , , , , <unk>', '<s> And <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> And , , , , , <unk> <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> <s> And <unk> <unk> <unk>', '<s> <s> <s> And , , <unk> <unk>', '<s> <s> And <unk> <unk> <unk>', '<s> And , , , , <unk> <unk> <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> <s> And , , , , , , , <unk>', '<s> And , <unk> <unk>', '<s> And , , , , , , <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk> <unk> <unk>', '<s> <s> And , , , <unk> <unk> <unk> <unk> <unk>']\n",
      "BLEU Score is 9.34971914004537\n",
      "6\n",
      "['<s> And , , <unk> <unk> <unk>', '<s> And , , , , <unk> <unk> <unk> <unk>', '<s> <s> And , , , , , <unk> <unk> <unk> <unk>', '<s> <s> And , , , , , <unk> <unk> <unk> <unk>', '<s> <s> And , , <unk> <unk> <unk>', '<s> <s> And , , , , , , <unk> <unk> <unk> <unk>', '<s> And , <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And , , , , <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> And , , , , , <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> And , , <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk> <unk> <unk>', '<s> <s> <s> <s> I , , , , , <unk> <unk> <unk> <unk>', '<s> And , , <unk> <unk> <unk> <unk>', '<s> And , <unk> <unk>', '<s> And , <unk> <unk> <unk> <unk>', '<s> And , , , <unk> <unk> <unk> <unk> <unk> <unk>', '<s> And , , , , <unk> <unk> <unk> <unk> <unk>', '<s> And , <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk> <unk>', '<s> And , , , , , <unk> <unk> <unk> <unk>', '<s> And , , <unk> <unk> <unk> <unk> <unk> <unk> <unk>', '<s> And , , , , , , , <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> <s> And , , <unk> <unk>', '<s> <s> And <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And , , , , , , , , , <unk> <unk> <unk>', '<s> And , <unk> <unk>']\n",
      "BLEU Score is 11.204554838694165\n",
      "7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<s> <s> And , <unk> <unk>', '<s> And , , , , <unk> <unk> <unk> <unk> <unk>', '<s> And , , , , <unk> <unk> <unk> <unk> <unk>', '<s> And , , , <unk> <unk> <unk>', '<s> And , , , , , , , , <unk> <unk> <unk>', '<s> And , , , , <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> <s> And , <unk> <unk>', '<s> And , , , , , , , <unk> <unk> <unk> <unk>', '<s> And , <unk> <unk> <unk> <unk>', '<s> <s> And <unk> <unk>', '<s> <s> And <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And , , , , <unk> <unk> <unk> <unk> <unk>', '<s> <s> And , <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> <s> <s> <s> I , , , , , <unk> <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And , , <unk> <unk> <unk> <unk> <unk> <unk> <unk>', '<s> <s> And , , , , , <unk> <unk> <unk> <unk> <unk>', '<s> And , <unk> <unk> <unk> <unk>', '<s> And , <unk> <unk> <unk>', '<s> And , , , <unk> <unk> <unk> <unk> <unk>', '<s> And , , , , <unk> <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And , , <unk> <unk> <unk> <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> And , , , , , <unk> <unk> <unk> <unk>', '<s> <s> And <unk> <unk> <unk> <unk>']\n",
      "BLEU Score is 12.423867130674825\n",
      "8\n",
      "['<s> <s> And <unk> <unk>', '<s> <s> And , <unk> <unk> <unk>', '<s> And , , , , , , <unk> <unk> <unk> <unk>', '<s> And , <unk> <unk> <unk>', '<s> And , , , , , , <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> And , , , , , , , <unk> <unk> <unk>', '<s> And , , , , <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk> <unk> <unk> <unk>', '<s> And , , , , , , , , , , , , <unk> <unk>', '<s> And , , , , , , , , <unk> <unk> <unk>', '<s> <s> And <unk> <unk> <unk>', '<s> And , <unk> <unk>', '<s> <s> And <unk> <unk> <unk>', '<s> And , , <unk> <unk> <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And , , , , , , <unk> <unk> <unk> <unk>', '<s> And , , , , <unk> <unk> <unk> <unk> <unk> <unk>', '<s> And , , , <unk> <unk> <unk> <unk> <unk>', '<s> And , , <unk> <unk> <unk> <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> And , , , , , <unk> <unk> <unk> <unk> <unk>', '<s> And , , <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And , , , , , , <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And , , , , , , , , <unk> <unk> <unk>', '<s> And , , , , , <unk> <unk> <unk> <unk> <unk> <unk>', '<s> <s> And , , , , , , , , , <unk> <unk>', '<s> <s> And , , , <unk> <unk> <unk> <unk> <unk>', '<s> And , <unk> <unk> <unk> <unk>']\n",
      "BLEU Score is 8.616050212072572\n",
      "9\n",
      "['<s> And , , , , , , , , , <unk> <unk>', '<s> And <unk> <unk> <unk> <unk> <unk>', '<s> And , , , , , , , , , <unk> <unk> <unk> <unk>', '<s> And , , , , , <unk> <unk> <unk>', '<s> And , <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And , , , <unk> <unk>', '<s> <s> And <unk> <unk> <unk>', '<s> And , , , , , <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And , , , , , , , , , , <unk> <unk>', '<s> <s> And , , , , , , , , <unk> <unk> <unk> <unk>', '<s> And , , , <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And , , <unk> <unk> <unk>', '<s> And , , , , , , , , , , <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> <s> And <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk> <unk>', '<s> And , <unk> <unk> <unk> <unk> <unk> <unk>', '<s> And , , , , , <unk> <unk> <unk>', '<s> <s> And , <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And , , , , , , <unk> <unk> <unk> <unk> <unk>', '<s> And , , <unk> <unk> <unk>', '<s> And , <unk> <unk> <unk>']\n",
      "BLEU Score is 8.231790843467147\n",
      "10\n",
      "['<s> <s> And <unk> <unk> <unk> <unk>', '<s> And , , <unk> <unk> <unk> <unk> <unk> <unk>', '<s> And , , , <unk> <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And , , , , <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And , , , , , , , , <unk> <unk> <unk>', '<s> And , , , <unk> <unk> <unk> <unk>', '<s> <s> And , , , , , <unk> <unk> <unk> <unk> <unk>', '<s> And , , , , , , , , <unk> <unk>', '<s> <s> And <unk> <unk> <unk>', '<s> And , , , <unk> <unk> <unk> <unk> <unk>', '<s> <s> And , , , , , , , <unk> <unk> <unk> <unk> <unk>', '<s> <s> And , , <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk> <unk> <unk>', '<s> And , , , , <unk> <unk> <unk> <unk>', '<s> And , , , , , , , <unk> <unk> <unk>', '<s> And , , , , , , , , <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> And , , , , , , , <unk> <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And , , <unk> <unk> <unk> <unk>', '<s> And , , , <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> <s> And , , <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> <s> And <unk> <unk>', '<s> <s> And , , , <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>']\n",
      "BLEU Score is 9.904196167742278\n",
      "11\n",
      "['<s> <s> And <unk> <unk> <unk>', '<s> And , , , , , <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And , , , , , , , <unk> <unk> <unk>', '<s> <s> <s> <s> I , , , , , , , <unk> <unk> <unk>', '<s> And , , , , <unk> <unk> <unk> <unk> <unk>', '<s> <s> And , , <unk> <unk> <unk> <unk> <unk> <unk> <unk>', '<s> And , , , , , <unk> <unk> <unk> <unk>', '<s> And , , , <unk> <unk> <unk> <unk>', '<s> And , <unk> <unk> <unk>', '<s> And , , , , , , <unk> <unk> <unk> <unk>', '<s> <s> <s> I , <unk> <unk>', '<s> And <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>', '<s> And , <unk> <unk> <unk>', '<s> And , , , , , <unk> <unk> <unk> <unk>', '<s> And , , , <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk> <unk> <unk>', '<s> And , , , , , , , <unk> <unk> <unk>', '<s> <s> <s> And , , , , , , , , , , , , <unk> <unk>', '<s> And , , , , , <unk> <unk> <unk>', '<s> And , , , , , , , , <unk> <unk> <unk> <unk>', '<s> And , , , , <unk> <unk> <unk> <unk> <unk>', '<s> And <unk> <unk>', '<s> <s> And <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> <s> And , <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> And , , , , <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> <s> <s> I <unk> <unk> <unk>']\n",
      "BLEU Score is 8.898372121716715\n",
      "12\n",
      "['<s> And , <unk> <unk> <unk> <unk>', '<s> And , , , , , , , <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> <s> And <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And , , , , <unk> <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And , , , , , , , <unk> <unk> <unk>', '<s> And , , , , , , <unk> <unk> <unk> <unk>', '<s> And , , , , , , , <unk> <unk> <unk>', '<s> And , , <unk> <unk> <unk> <unk> <unk>', '<s> And , , , , , , , <unk> <unk> <unk> <unk>', '<s> And , , , , , , <unk> <unk> <unk> <unk>', '<s> <s> And , <unk> <unk> <unk> <unk> <unk>', '<s> And , <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk> <unk> <unk>', '<s> And , , , , <unk> <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And , , , , , , , <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk> <unk> <unk> <unk>', '<s> <s> And , , , , , <unk> <unk> <unk> <unk>', '<s> And , , <unk> <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> <s> <s> And , , <unk> <unk> <unk> <unk> <unk> <unk> <unk>', '<s> And , <unk> <unk>', '<s> And , , , <unk> <unk> <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>']\n",
      "BLEU Score is 9.406402186342017\n",
      "13\n",
      "['<s> And , , , , <unk> <unk> <unk> <unk> <unk> <unk>', '<s> <s> And , , , , , , , <unk> <unk> <unk> <unk>', '<s> And , , , , <unk> <unk> <unk> <unk> <unk>', '<s> <s> And , , , , , , , , , , <unk> <unk>', '<s> And , , , , , , , <unk> <unk> <unk>', '<s> And , <unk> <unk> <unk> <unk> <unk>', '<s> And , <unk> <unk>', '<s> And , <unk> <unk>', '<s> And , , , , <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And , , <unk> <unk>', '<s> And <unk> <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> And , , <unk> <unk> <unk> <unk>', '<s> And , , , <unk> <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> And , <unk> <unk> <unk>', '<s> <s> And , , , , , , , <unk> <unk> <unk>', '<s> And , , , , <unk> <unk> <unk> <unk> <unk>', '<s> And , , , <unk> <unk> <unk> <unk> <unk>', '<s> And , , , , , <unk> <unk> <unk> <unk>', '<s> <s> And , , , , , , , , <unk> <unk> <unk>', '<s> And , , , <unk> <unk> <unk> <unk> <unk> <unk>', '<s> And , , , , , , <unk> <unk> <unk> <unk> <unk>', '<s> And , , , , , , <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And , , , , , <unk> <unk> <unk> <unk>']\n",
      "BLEU Score is 5.81012219317842\n",
      "14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<s> And <unk> <unk> <unk>', '<s> And , , , , , <unk> <unk> <unk> <unk> <unk>', '<s> And , <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> <s> And , <unk> <unk> <unk>', '<s> And , , , <unk> <unk> <unk> <unk>', '<s> And , , , , , , , , , , , , <unk>', '<s> And , , <unk> <unk> <unk> <unk> <unk> <unk>', '<s> <s> And <unk> <unk> <unk> <unk>', '<s> <s> And <unk> <unk> <unk> <unk> <unk> <unk>', '<s> And , , , , , , , <unk> <unk> <unk> <unk>', '<s> And , <unk> <unk>', '<s> And <unk> <unk>', '<s> And , , , , , , , , <unk> <unk> <unk>', '<s> <s> And , , , , <unk> <unk> <unk> <unk> <unk>', '<s> And , , , , , , , , , , <unk>', '<s> <s> And , <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> <s> And <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> <s> And , , , , , <unk> <unk> <unk> <unk>', '<s> And , , <unk> <unk> <unk> <unk>', '<s> And , , , , , <unk> <unk> <unk>', '<s> And , <unk> <unk>', '<s> And , , <unk> <unk> <unk>', '<s> And , , <unk> <unk> <unk>', '<s> And , , , , , , <unk> <unk> <unk> <unk>', '<s> <s> And , , , , , <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And , , , , , , <unk> <unk> <unk> <unk>', '<s> And , , , , , , , <unk> <unk> <unk>', '<s> <s> And , <unk> <unk>']\n",
      "BLEU Score is 5.4629631471202265\n",
      "15\n",
      "['<s> And , , , , <unk> <unk> <unk> <unk> <unk>', '<s> <s> And <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> <s> And <unk> <unk> <unk>', '<s> And , , , , <unk> <unk> <unk> <unk> <unk>', '<s> <s> <s> I , <unk> <unk>', '<s> And , , , , <unk> <unk> <unk> <unk>', '<s> And , , , , , <unk> <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> And , <unk> <unk> <unk>', '<s> And , <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>', '<s> <s> <s> I , <unk> <unk> <unk>', '<s> And , , , , , , , <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And , , , , , <unk> <unk> <unk> <unk> <unk>', '<s> And , , , , <unk> <unk> <unk> <unk>', '<s> <s> <s> I <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> <s> And <unk> <unk> <unk>', '<s> And , , , <unk> <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> And , <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And , , , , , , <unk> <unk> <unk> <unk> <unk>', '<s> <s> And <unk> <unk> <unk>', '<s> <s> And , , , , , <unk> <unk> <unk> <unk> <unk> <unk>', '<s> <s> And , <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> And , , , , , , , <unk> <unk> <unk>']\n",
      "BLEU Score is 13.933853156301762\n",
      "16\n",
      "['<s> <s> And <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And , , , <unk> <unk> <unk> <unk> <unk>', '<s> And , , , , , , , <unk> <unk> <unk> <unk>', '<s> And , , , , , <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk> <unk> <unk> <unk>', '<s> And , , , , , , , , <unk> <unk> <unk>', '<s> <s> And <unk> <unk> <unk>', '<s> <s> <s> I , , , <unk> <unk>', '<s> And , , , , , <unk> <unk> <unk>', '<s> And , , , , , , <unk> <unk> <unk>', '<s> And , , , , , , , , , <unk> <unk> <unk>', '<s> And , <unk> <unk> <unk>', '<s> And , <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> <s> And , <unk> <unk> <unk>', '<s> And , , , <unk> <unk>', '<s> And , , , <unk> <unk> <unk> <unk>', '<s> And , , , , , <unk> <unk> <unk> <unk>', '<s> <s> And , , <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> And <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> And , , <unk> <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And , <unk> <unk> <unk>', '<s> And , , , , , , , , <unk> <unk> <unk>', '<s> And , <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And , , , , <unk> <unk> <unk> <unk>']\n",
      "BLEU Score is 11.48143741425371\n",
      "17\n",
      "['<s> And <unk> <unk> <unk>', '<s> And , , <unk> <unk> <unk> <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> <s> And <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And , <unk> <unk> <unk> <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> <s> And <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And , , <unk> <unk> <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And , , , , , <unk> <unk> <unk>', '<s> And , , , , <unk> <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And , <unk> <unk> <unk> <unk> <unk>', '<s> And <unk> <unk>', '<s> And , <unk> <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> <s> And <unk> <unk> <unk>', '<s> And , , , , <unk> <unk> <unk> <unk> <unk> <unk>', '<s> And , <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And , <unk> <unk>', '<s> And , <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And , , <unk> <unk> <unk>']\n",
      "BLEU Score is 13.265534580099647\n",
      "18\n",
      "['<s> And <unk> <unk> <unk>', '<s> <s> And , , <unk> <unk>', '<s> <s> And , <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And , , <unk> <unk> <unk> <unk> <unk> <unk>', '<s> <s> And <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And , <unk> <unk> <unk> <unk>', '<s> And , , , <unk> <unk> <unk> <unk> <unk>', '<s> And , <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> And , <unk> <unk>', '<s> <s> And , , <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> <s> And , , , , <unk> <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And , , , <unk> <unk> <unk> <unk> <unk> <unk>', '<s> <s> And <unk> <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> And , , <unk> <unk> <unk> <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And <unk> <unk>', '<s> And , , <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>', '<s> And , <unk> <unk> <unk>', '<s> And , , , , , <unk> <unk> <unk> <unk>']\n",
      "BLEU Score is 10.103605857162494\n",
      "19\n",
      "['<s> And <unk> <unk> <unk>', '<s> <s> And , , , , , , <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> <s> And <unk> <unk> <unk>', '<s> <s> And , , , <unk> <unk> <unk> <unk>', '<s> And , , , , , , , , <unk> <unk> <unk>', '<s> And , , , , , , , , <unk> <unk> <unk> <unk>', '<s> <s> And <unk> <unk>', '<s> And , <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And , , <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> <s> And , , <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> And , <unk> <unk>', '<s> And , , <unk> <unk> <unk> <unk> <unk> <unk> <unk>', '<s> And , <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> <s> And , <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> And , , , <unk> <unk> <unk> <unk> <unk> <unk>', '<s> And , , , , <unk> <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> <s> And , <unk> <unk> <unk>', '<s> And , , , , <unk> <unk> <unk> <unk>', '<s> And , , , , , , , , <unk> <unk> <unk>', '<s> And , <unk> <unk> <unk> <unk> <unk>']\n",
      "BLEU Score is 11.259943267064843\n",
      "20\n",
      "['<s> And , , , , , , <unk> <unk> <unk> <unk>', '<s> And , , , , , <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And , , , , <unk> <unk> <unk> <unk> <unk>', '<s> And , , <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> <s> And , <unk> <unk> <unk>', '<s> And , , , <unk> <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> And , , , , <unk> <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> And , <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk> <unk> <unk>', '<s> And , , , , , , , <unk> <unk> <unk> <unk>', '<s> <s> And , , , , <unk> <unk> <unk> <unk> <unk> <unk>', '<s> And , <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And , , , , , , , <unk> <unk> <unk> <unk>', '<s> And , , <unk> <unk> <unk> <unk> <unk> <unk>', '<s> And , , , , , , <unk> <unk> <unk> <unk> <unk>', '<s> <s> And , , , , , , , , <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> And , , , , <unk> <unk> <unk> <unk>', '<s> And , , , , , , , <unk> <unk> <unk>', '<s> And , , , , , , , , <unk> <unk> <unk> <unk>', '<s> And , , , , , <unk> <unk> <unk> <unk> <unk>', '<s> And , , , , <unk> <unk> <unk> <unk> <unk>', '<s> And , , , , <unk> <unk> <unk> <unk> <unk>', '<s> And , , , , , , , , , , , , , , <unk>']\n",
      "BLEU Score is 8.628791762086731\n",
      "21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<s> And , , , , , , <unk> <unk> <unk>', '<s> And , <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> <s> And , , , , , , , <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And , , , , , , , , <unk> <unk> <unk>', '<s> And , , <unk> <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And , <unk> <unk> <unk>', '<s> <s> <s> I <unk> <unk>', '<s> And <unk> <unk> <unk> <unk> <unk>', '<s> And , <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And , <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>', '<s> <s> <s> <s> I , , , , , , , <unk> <unk> <unk>', '<s> And , , <unk> <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And , , , <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And , <unk> <unk> <unk> <unk> <unk>', '<s> And , , <unk> <unk> <unk> <unk> <unk>', '<s> And , , , <unk> <unk> <unk> <unk> <unk> <unk>', '<s> <s> And , , , , , <unk> <unk> <unk>', '<s> <s> And , <unk> <unk> <unk>', '<s> <s> And , , , , , <unk> <unk> <unk> <unk> <unk>', '<s> And , , <unk> <unk> <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> <s> And , , , , , <unk> <unk> <unk> <unk>', '<s> And , , , , , <unk> <unk> <unk> <unk> <unk>']\n",
      "BLEU Score is 9.920102024965255\n",
      "22\n",
      "['<s> <s> And , , , , <unk> <unk> <unk> <unk> <unk>', '<s> And , <unk> <unk> <unk> <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And , <unk> <unk> <unk> <unk> <unk>', '<s> And , , , , , , , , , <unk> <unk>', '<s> And <unk> <unk> <unk> <unk> <unk>', '<s> And , , , , , , <unk> <unk> <unk>', '<s> And , , <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> And , , , <unk> <unk> <unk> <unk>', '<s> And , , , , , , <unk> <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> And , , , , <unk> <unk> <unk> <unk> <unk>', '<s> <s> <s> I , <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And , , , <unk> <unk> <unk> <unk> <unk>', '<s> And , , , , <unk> <unk> <unk>', '<s> And , , , , , , <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>', '<s> And , , <unk> <unk> <unk> <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And , <unk> <unk> <unk>', '<s> And , , , , , , , <unk> <unk>', '<s> And , , , , <unk> <unk> <unk> <unk> <unk>', '<s> And , , , <unk> <unk> <unk> <unk> <unk>', '<s> And , , <unk> <unk> <unk> <unk> <unk> <unk>', '<s> And , , , <unk> <unk> <unk> <unk> <unk>', '<s> <s> <s> I <unk> <unk> <unk>', '<s> <s> And , , , , , , <unk> <unk> <unk> <unk>', '<s> <s> And <unk> <unk>', '<s> And , , , , , , <unk> <unk> <unk> <unk>', '<s> And , , , , , , <unk> <unk> <unk>']\n",
      "BLEU Score is 8.119229519776036\n",
      "23\n",
      "['<s> And , , , <unk> <unk> <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> And , , , , , <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>', '<s> And , , , , , <unk> <unk> <unk>', '<s> <s> And , , , , , , <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> And , , , , , <unk> <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> <s> And , , , , , <unk> <unk> <unk>', '<s> And , , , , , , , , , , <unk> <unk>', '<s> And , , , , , , , <unk> <unk> <unk>', '<s> And , , , , , , , , , <unk> <unk>', '<s> And , , , , <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> And , , , , , , , , , <unk> <unk> <unk>', '<s> And , , , , , , , <unk> <unk> <unk>', '<s> And , , , , , , , <unk> <unk> <unk>', '<s> <s> And , , , , <unk> <unk> <unk> <unk>', '<s> And , , , <unk> <unk> <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk> <unk>', '<s> <s> And , , <unk> <unk>', '<s> <s> And , <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And , , , , , , <unk> <unk> <unk> <unk> <unk>', '<s> And , <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>']\n",
      "BLEU Score is 6.0527635421628965\n",
      "24\n",
      "['<s> And , , , , , , <unk> <unk> <unk>', '<s> And , , , , , <unk> <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> And , , , , <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> <s> And <unk> <unk> <unk>', '<s> And , , , , , , , <unk> <unk> <unk>', '<s> And , , , , , , <unk> <unk> <unk>', '<s> And , , , , , , , <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And , , , , , <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And , <unk> <unk>', '<s> And , , , , , , , <unk> <unk> <unk> <unk>', '<s> <s> And , , , , , , <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk> <unk>', '<s> And <unk> <unk>', '<s> And , , , <unk> <unk> <unk> <unk> <unk>', '<s> And , <unk> <unk> <unk>', '<s> And , , , , <unk> <unk> <unk> <unk> <unk>', '<s> And , , , , , , , <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And , <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> And <unk> <unk>', '<s> And , , , , , <unk> <unk> <unk> <unk>', '<s> And , , , , <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk> <unk> <unk>']\n",
      "BLEU Score is 5.9599516529029986\n",
      "25\n",
      "['<s> And , , , , , , <unk> <unk> <unk> <unk>', '<s> <s> And , , , , , , , <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>', '<s> <s> And , , , , , <unk> <unk> <unk> <unk>', '<s> And , , , <unk> <unk> <unk>', '<s> And , , , , , , , <unk> <unk> <unk>', '<s> And , , , <unk> <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> <s> And <unk> <unk>', '<s> And , , <unk> <unk> <unk> <unk>', '<s> And <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> And , <unk> <unk>', '<s> And , <unk> <unk> <unk>', '<s> And , , <unk> <unk> <unk> <unk> <unk>', '<s> <s> And <unk> <unk> <unk> <unk>', '<s> And , , , , <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>', '<s> <s> <s> I <unk> <unk> <unk>', '<s> And , , , , , , <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And , , , , , , <unk> <unk> <unk> <unk>', '<s> <s> <s> <s> <s> I , , , , , , , <unk> <unk> <unk>', '<s> <s> And , , , , , , , <unk> <unk> <unk> <unk>', '<s> And , , <unk> <unk> <unk> <unk> <unk> <unk> <unk>', '<s> And , , <unk> <unk> <unk> <unk> <unk> <unk>', '<s> And , , , , , , , <unk> <unk> <unk>', '<s> <s> And <unk> <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk> <unk> <unk> <unk>']\n",
      "BLEU Score is 10.692723641302045\n",
      "26\n",
      "['<s> And , , , , , <unk> <unk> <unk> <unk> <unk>', '<s> And , , , , , , , <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And , , , , <unk> <unk> <unk> <unk>', '<s> And , , , , , <unk> <unk> <unk> <unk>', '<s> <s> <s> I <unk> <unk> <unk>', '<s> And , , <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And , , , , <unk> <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> And , , , , , , , , <unk> <unk> <unk>', '<s> And , , , <unk> <unk>', '<s> And , <unk> <unk> <unk>', '<s> <s> And , , <unk> <unk>', '<s> And , , , , <unk> <unk> <unk> <unk> <unk>', '<s> And , , <unk> <unk> <unk> <unk> <unk> <unk>', '<s> And , , <unk> <unk> <unk> <unk> <unk>', '<s> And , <unk> <unk> <unk> <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> <s> And <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And , , , <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And , , , , , <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And , , , , , <unk> <unk> <unk> <unk>', '<s> <s> And , , , , , <unk> <unk> <unk> <unk>']\n",
      "BLEU Score is 8.147408093166865\n",
      "27\n",
      "['<s> And , , , , , <unk> <unk> <unk> <unk> <unk>', '<s> And , , , , , , , , <unk> <unk>', '<s> And , , , <unk> <unk> <unk> <unk> <unk> <unk>', '<s> And , <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> <s> And , , , , <unk> <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> <s> And <unk> <unk> <unk>', '<s> And , , <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> <s> And , , , , , <unk> <unk> <unk>', '<s> And , , , , , <unk> <unk> <unk> <unk> <unk>', '<s> And , <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And , , , , <unk> <unk> <unk> <unk> <unk>', '<s> <s> And , , <unk> <unk> <unk> <unk>', '<s> And , <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> <s> And , , , , , , , , <unk> <unk> <unk>', '<s> And , <unk> <unk> <unk>', '<s> And , <unk> <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> <s> And , , , <unk> <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> <s> And , , , , , <unk> <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>', '<s> <s> And , <unk> <unk>']\n",
      "BLEU Score is 8.646288166253177\n",
      "28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<s> And <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk> <unk>', '<s> And , , , , , , , , , <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> <s> And <unk> <unk> <unk>', '<s> And , , , <unk> <unk> <unk>', '<s> And , , , , <unk> <unk> <unk> <unk> <unk>', '<s> And , , <unk> <unk> <unk> <unk>', '<s> And , , <unk> <unk> <unk> <unk> <unk> <unk> <unk>', '<s> And , , , <unk> <unk> <unk>', '<s> <s> And I , , , <unk> <unk> <unk> <unk>', '<s> <s> And , , , , , , , , <unk> <unk> <unk> <unk>', '<s> And , , , <unk> <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And , <unk> <unk> <unk>', '<s> And , <unk> <unk> <unk> <unk> <unk>', '<s> And , <unk> <unk>', '<s> And , , , , , , <unk> <unk> <unk>', '<s> <s> And <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And , , , , , , <unk> <unk> <unk> <unk>', '<s> <s> And <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> And , <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> And , , <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> And <unk> <unk>']\n",
      "BLEU Score is 7.731312150956634\n",
      "29\n",
      "['<s> And <unk> <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> <s> And , <unk> <unk> <unk> <unk> <unk>', '<s> And , , , , , , , , <unk> <unk> <unk>', '<s> And , , <unk> <unk> <unk>', '<s> And <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> And , , , , , , , , , <unk> <unk> <unk>', '<s> And , <unk> <unk>', '<s> <s> And , , <unk> <unk> <unk> <unk>', '<s> <s> And <unk> <unk> <unk> <unk>', '<s> And , , , <unk> <unk> <unk> <unk> <unk>', '<s> <s> And , , , , , , <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> <s> And , , , <unk> <unk> <unk> <unk> <unk> <unk> <unk>', '<s> And , <unk> <unk> <unk> <unk> <unk>', '<s> And , , , , <unk> <unk> <unk> <unk> <unk>', '<s> <s> <s> <s> I <unk> <unk> <unk> <unk> <unk>', '<s> And , , , <unk> <unk> <unk> <unk> <unk>', '<s> And , <unk> <unk> <unk>', '<s> And , , , , <unk> <unk> <unk> <unk> <unk> <unk>', '<s> And , , , , , <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And <unk> <unk>', '<s> <s> And <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>']\n",
      "BLEU Score is 6.319480446061583\n",
      "30\n",
      "['<s> And , <unk> <unk> <unk>', '<s> And , <unk> <unk> <unk>', '<s> <s> And , , , , , , , , , <unk> <unk> <unk>', '<s> And , , <unk> <unk> <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> <s> And <unk> <unk> <unk>', '<s> <s> And , , , , , , , <unk> <unk> <unk>', '<s> And , , , , , <unk> <unk> <unk> <unk>', '<s> And , , , , , , , , , , , , <unk> <unk>', '<s> And , , , , , , , , , <unk> <unk> <unk>', '<s> And , , , , , <unk> <unk> <unk> <unk>', '<s> And , <unk> <unk> <unk>', '<s> And , <unk> <unk> <unk>', '<s> <s> And <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> And , <unk> <unk> <unk>', '<s> <s> And , <unk> <unk> <unk>', '<s> And , , , , , , <unk> <unk> <unk>', '<s> And , , , , , , <unk> <unk> <unk> <unk>', '<s> And , <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> And , , , , , <unk> <unk> <unk>', '<s> And , , , , , , <unk> <unk> <unk>', '<s> <s> And , <unk> <unk>', '<s> And , <unk> <unk> <unk>', '<s> And , , , <unk> <unk> <unk> <unk> <unk> <unk>', '<s> <s> And , , , , , , <unk> <unk> <unk> <unk>', '<s> And , , , , , , , <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> And , <unk> <unk> <unk>', '<s> And , , , , , , <unk> <unk> <unk> <unk>']\n",
      "BLEU Score is 11.448184146745481\n",
      "31\n",
      "['<s> And , , , , , , , , , , <unk> <unk> <unk>', '<s> And , , , , , , <unk> <unk> <unk> <unk>', '<s> And , , , , , <unk> <unk> <unk> <unk>', '<s> And , , <unk> <unk> <unk> <unk>', '<s> And , , , , , , , , <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And , , , , , <unk> <unk> <unk>', '<s> <s> And , , <unk> <unk> <unk> <unk>', '<s> And , , , , , <unk> <unk> <unk> <unk>', '<s> And , , <unk> <unk> <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And , , , <unk> <unk> <unk> <unk> <unk>', '<s> And , , , , , , , , <unk> <unk> <unk> <unk>', '<s> And , , , , , , , <unk> <unk> <unk> <unk>', '<s> And , , , , , <unk> <unk> <unk> <unk> <unk>', '<s> And , , <unk> <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> <s> And , , <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk> <unk> <unk>', '<s> And , , <unk> <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk> <unk> <unk>', '<s> <s> And , , , , <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk> <unk> <unk> <unk>', '<s> And , , , <unk> <unk> <unk> <unk> <unk> <unk>', '<s> And , , <unk> <unk>', '<s> And , , , , <unk> <unk> <unk> <unk> <unk> <unk>', '<s> <s> And , , <unk> <unk>', '<s> <s> And , , , , <unk> <unk> <unk> <unk> <unk>', '<s> <s> And , , , , , , , , <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> And , , , , <unk> <unk> <unk> <unk>']\n",
      "BLEU Score is 8.360819522885699\n",
      "32\n",
      "['<s> And , , , , , , , , , <unk> <unk> <unk>', '<s> And , <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk> <unk> <unk> <unk>', '<s> And , , , , , , , , , , <unk> <unk>', '<s> And , , , , , , <unk> <unk> <unk> <unk>', '<s> <s> And <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> <s> And , <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> <s> And <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And , <unk> <unk> <unk>', '<s> <s> And , , , , , <unk> <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And , , , , , , <unk> <unk> <unk> <unk>', '<s> And , , , , , , , , , , <unk> <unk> <unk>', '<s> And , , , , <unk> <unk> <unk> <unk>', '<s> <s> And , , , , , <unk> <unk> <unk> <unk> <unk>', '<s> And , , , , , , , <unk> <unk> <unk>', '<s> And , , , , , , , , , <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And , , , , <unk> <unk> <unk> <unk> <unk> <unk>', '<s> And , , , , , <unk> <unk> <unk>', '<s> <s> <s> <s> I , , , , , , , , <unk> <unk>']\n",
      "BLEU Score is 9.376221093276444\n",
      "33\n",
      "['<s> And , , , , <unk> <unk> <unk> <unk>', '<s> <s> And , , , , , , , <unk> <unk> <unk>', '<s> And , , , , , <unk> <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk> <unk> <unk>', '<s> And , , <unk> <unk> <unk> <unk>', '<s> And , , , , , <unk> <unk> <unk> <unk> <unk>', '<s> And , <unk> <unk> <unk> <unk> <unk> <unk> <unk>', '<s> And , , <unk> <unk> <unk> <unk>', '<s> <s> And <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And , , , <unk> <unk> <unk> <unk> <unk> <unk>', '<s> And , , , , , <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And , , , <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk> <unk> <unk> <unk>', '<s> And , , , , , , , , <unk> <unk>', '<s> And , , <unk> <unk> <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> <s> <s> <s> I , <unk> <unk> <unk>', '<s> And , , , , <unk> <unk> <unk> <unk> <unk>', '<s> <s> And , , , , , , , , , , , <unk>', '<s> And , , <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk> <unk>', '<s> And , , , , , , , , <unk> <unk> <unk>', '<s> <s> And , , , , , , , <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>']\n",
      "BLEU Score is 7.68084958714059\n",
      "34\n",
      "['<s> And <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And , , , , , <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> And , , <unk> <unk> <unk> <unk> <unk>', '<s> And , , , , , , <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And , <unk> <unk> <unk>', '<s> And , , , <unk> <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk> <unk>', '<s> And , , , , , , , <unk> <unk> <unk>', '<s> And , , , , , , , <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> And , , , <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> And , , , , , , , <unk> <unk> <unk>', '<s> And , <unk> <unk> <unk> <unk>', '<s> <s> And , , , <unk> <unk>', '<s> And , , <unk> <unk> <unk> <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And , , , , , , <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> And , <unk> <unk> <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And , <unk> <unk> <unk>', '<s> And , , , <unk> <unk>', '<s> And , , <unk> <unk>']\n",
      "BLEU Score is 4.960729910310716\n",
      "35\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<s> And , , , <unk> <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> <s> And <unk> <unk> <unk> <unk> <unk> <unk> <unk>', '<s> And , , , , , <unk> <unk> <unk> <unk>', '<s> <s> And <unk> <unk> <unk>', '<s> And , , , <unk> <unk> <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And , , , <unk> <unk> <unk> <unk> <unk> <unk>', '<s> <s> <s> I <unk> <unk> <unk>', '<s> And , , , , , , <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And , , , , , , , , <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And , <unk> <unk>', '<s> <s> And , , <unk> <unk> <unk> <unk> <unk>', '<s> And , , , , <unk> <unk> <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> <s> And , <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And , , <unk> <unk> <unk> <unk> <unk>', '<s> <s> And , , , , , , , <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> <s> And , , <unk> <unk> <unk> <unk> <unk>', '<s> And , , , <unk> <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And , , , <unk> <unk> <unk> <unk> <unk>', '<s> And , , , <unk> <unk> <unk> <unk> <unk> <unk>', '<s> <s> And , , , , , , , , , , <unk> <unk>']\n",
      "BLEU Score is 9.129157871213225\n",
      "36\n",
      "['<s> And , , , , <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> <s> <s> <s> <s> I , , , , , , , , <unk> <unk>', '<s> And , , , , , <unk> <unk> <unk> <unk> <unk>', '<s> And , , , , , , , <unk> <unk> <unk> <unk>', '<s> And <unk> <unk>', '<s> <s> And , , , , , , , , , , , , , <unk> <unk>', '<s> And , , , , <unk> <unk> <unk> <unk>', '<s> And , , <unk> <unk> <unk> <unk> <unk> <unk> <unk>', '<s> <s> And , , , , , , , , , <unk> <unk>', '<s> And <unk> <unk> <unk> <unk> <unk> <unk> <unk>', '<s> And , , , , , , , , , <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> <s> And , , , <unk> <unk> <unk> <unk> <unk>', '<s> <s> <s> <s> <s> I , , , , , , , <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk> <unk> <unk>', '<s> And , , , , , , , <unk> <unk> <unk>', '<s> <s> And , , , <unk> <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And , <unk> <unk> <unk> <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And , <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> <s> And , , , , , , , , <unk> <unk> <unk>', '<s> And , , , , , <unk> <unk> <unk> <unk>', '<s> And , , , , , , , <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And , <unk> <unk> <unk> <unk> <unk> <unk> <unk>']\n",
      "BLEU Score is 5.733780794695615\n",
      "37\n",
      "['<s> And , , , , <unk> <unk> <unk> <unk>', '<s> And , , <unk> <unk> <unk> <unk> <unk> <unk>', '<s> <s> And , , , , <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> <s> And , , , , <unk> <unk> <unk> <unk>', '<s> <s> <s> I , <unk> <unk>', '<s> And , <unk> <unk> <unk>', '<s> And , , , , , , , , <unk> <unk> <unk> <unk>', '<s> <s> And , <unk> <unk> <unk>', '<s> <s> And , , , , , , , , <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And , <unk> <unk> <unk>', '<s> And , , , , , , , , , <unk> <unk> <unk>', '<s> And , , <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> <s> <s> I <unk> <unk> <unk>', '<s> And , <unk> <unk> <unk> <unk>', '<s> And , , , , , , , , , , <unk> <unk>', '<s> And , , , , <unk> <unk> <unk> <unk>', '<s> And , <unk> <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> And , , , , , <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> <s> And <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk> <unk>', '<s> <s> And <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> <s> <s> <s> I , , , , , <unk> <unk> <unk> <unk>', '<s> And , , <unk> <unk> <unk> <unk> <unk> <unk>']\n",
      "BLEU Score is 11.695535847470593\n",
      "38\n",
      "['<s> <s> <s> <s> I , <unk> <unk> <unk> <unk>', '<s> <s> And , , , , , , , <unk> <unk> <unk> <unk>', '<s> And , <unk> <unk>', '<s> And , , , , , , , , , , <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And , , , , <unk> <unk> <unk> <unk> <unk>', '<s> And , <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And , , , , , <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And , , , , , <unk> <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> <s> And , <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> <s> And , , , , , , , <unk> <unk> <unk>', '<s> And , , , , <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>', '<s> And , , , <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And , , , , , , <unk> <unk> <unk>', '<s> <s> And , <unk> <unk> <unk>', '<s> <s> And , , , , , , , , <unk> <unk>', '<s> <s> And <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> <s> And , , , , , <unk> <unk> <unk> <unk>', '<s> And , <unk> <unk> <unk> <unk> <unk>']\n",
      "BLEU Score is 6.586050492952208\n",
      "39\n",
      "['<s> And , , , , , , <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk> <unk> <unk>', '<s> And , <unk> <unk> <unk> <unk> <unk>', '<s> And , , <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk> <unk>', '<s> And I , , <unk> <unk> <unk> <unk>', '<s> <s> And , , , <unk> <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk> <unk>', '<s> And , <unk> <unk> <unk>', '<s> And , , , <unk> <unk> <unk> <unk> <unk> <unk>', '<s> And <unk> <unk> <unk>', '<s> And , , , <unk> <unk> <unk> <unk>', '<s> <s> And <unk> <unk> <unk>']\n",
      "BLEU Score is 8.416574971813056\n"
     ]
    }
   ],
   "source": [
    "score_list, output_words, attentions = evaluate(val_loader, encoder1, decoder1, beam=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
