{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re  \n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import collections\n",
    "from itertools import dropwhile\n",
    "import copy\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install sacrebleu\n",
    "from sacrebleu import corpus_bleu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in chinese-english pairs\n",
    "#read in chinese-english pairs\n",
    "lines_zh = open(PATH+'iwslt-zh-en/train.tok.zh',encoding = 'utf-8').read().strip().split('\\n')\n",
    "lines_en = open(PATH+'iwslt-zh-en/train.tok.en',encoding = 'utf-8').read().strip().split('\\n')\n",
    "lines_zh_test = open(PATH+'iwslt-zh-en/test.tok.zh',encoding = 'utf-8').read().strip().split('\\n')\n",
    "lines_en_test = open(PATH+'iwslt-zh-en/test.tok.en',encoding = 'utf-8').read().strip().split('\\n')\n",
    "lines_zh_val = open(PATH+'iwslt-zh-en/dev.tok.zh',encoding = 'utf-8').read().strip().split('\\n')\n",
    "lines_en_val = open(PATH+'iwslt-zh-en/dev.tok.en',encoding = 'utf-8').read().strip().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delect_least_common_words(list_sent, threshold = 5):\n",
    "    ret_list =[]\n",
    "    for x in list_sent:\n",
    "        ret_list += x.split()\n",
    "    ret_dic = collections.Counter(ret_list)\n",
    "\n",
    "    for key, count in dropwhile(lambda key_count: key_count[1] >= threshold, ret_dic.most_common()):\n",
    "        \n",
    "        del ret_dic[key]\n",
    "        \n",
    "        \n",
    "    return list(ret_dic.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "zh_words = delect_least_common_words(lines_zh)\n",
    "en_words = delect_least_common_words(lines_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_to_load = 100000\n",
    "PAD_IDX = 0\n",
    "UNK_IDX = 1\n",
    "SOS_IDX = 2\n",
    "EOS_IDX = 3\n",
    "\n",
    "with open(PATH+'cc.zh.300.vec') as f:\n",
    "    loaded_embeddings_ft = np.zeros((words_to_load+3, 300))\n",
    "    words_ft = {}\n",
    "    idx2words_ft = {}\n",
    "    ordered_words_ft = []\n",
    "    ordered_words_ft.extend(['<pad>', '<unk>', '<s>'])\n",
    "    loaded_embeddings_ft[0,:] = np.zeros(300)\n",
    "    loaded_embeddings_ft[1,:] = np.random.normal(size = 300)\n",
    "    loaded_embeddings_ft[2,:] = np.random.normal(size = 300)\n",
    "    for i, line in enumerate(f):\n",
    "        if i >= words_to_load: \n",
    "            break\n",
    "        s = line.split()\n",
    "        loaded_embeddings_ft[i+3, :] = np.asarray(s[1:])\n",
    "        words_ft[s[0]] = i+3\n",
    "        idx2words_ft[i+3] = s[0]\n",
    "        ordered_words_ft.append(s[0])\n",
    "    length = len(np.setdiff1d(zh_words, ordered_words_ft))\n",
    "    tmp_embeddings = np.zeros((length, 300))\n",
    "    for idx, word in enumerate(np.setdiff1d(zh_words, ordered_words_ft)):\n",
    "        words_ft[word] = idx+words_to_load+3\n",
    "        idx2words_ft[idx+words_to_load+3] = word\n",
    "        tmp_embeddings[idx, :] = np.random.normal(size = 300)\n",
    "    loaded_embeddings_ft = np.concatenate((loaded_embeddings_ft, tmp_embeddings), axis = 0)\n",
    "    words_ft['<pad>'] = PAD_IDX\n",
    "    words_ft['<unk>'] = UNK_IDX\n",
    "    words_ft['<s>'] = SOS_IDX\n",
    "    idx2words_ft[PAD_IDX] = '<pad>'\n",
    "    idx2words_ft[UNK_IDX] = '<unk>'\n",
    "    idx2words_ft[SOS_IDX] = '<s>'\n",
    "    \n",
    "ordered_words_ft = list(words_ft.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#English embedding\n",
    "with open(PATH+'wiki-news-300d-1M.vec') as f:\n",
    "    loaded_embeddings_ft_en = np.zeros((words_to_load+4, 300))\n",
    "    words_ft_en = {}\n",
    "    idx2words_ft_en = {}\n",
    "    ordered_words_ft_en = []\n",
    "    ordered_words_ft_en.extend(['<pad>', '<unk>', '<s>', '</s>'])\n",
    "    loaded_embeddings_ft_en[0,:] = np.zeros(300)\n",
    "    loaded_embeddings_ft_en[1,:] = np.random.normal(size = 300)\n",
    "    loaded_embeddings_ft_en[2,:] = np.random.normal(size = 300)\n",
    "    loaded_embeddings_ft_en[3,:] = np.random.normal(size = 300)\n",
    "    for i, line in enumerate(f):\n",
    "        if i >= words_to_load: \n",
    "            break\n",
    "        s = line.split()\n",
    "        loaded_embeddings_ft_en[i+4, :] = np.asarray(s[1:])\n",
    "        words_ft_en[s[0]] = i+4\n",
    "        idx2words_ft_en[i+4] = s[0]\n",
    "        ordered_words_ft_en.append(s[0])\n",
    "    length = len(np.setdiff1d(en_words, ordered_words_ft_en))\n",
    "    tmp_embeddings = np.zeros((length, 300))\n",
    "    for idx, word in enumerate(np.setdiff1d(en_words, ordered_words_ft_en)):\n",
    "        words_ft_en[word] = idx+words_to_load+4\n",
    "        idx2words_ft_en[idx+words_to_load+4] = word\n",
    "        tmp_embeddings[idx, :] = np.random.normal(size = 300)\n",
    "    loaded_embeddings_ft_en = np.concatenate((loaded_embeddings_ft_en, tmp_embeddings), axis = 0)\n",
    "    words_ft_en['<pad>'] = PAD_IDX\n",
    "    words_ft_en['<unk>'] = UNK_IDX\n",
    "    words_ft_en['<s>'] = SOS_IDX\n",
    "    words_ft_en['</s>'] = EOS_IDX\n",
    "    idx2words_ft_en[PAD_IDX] = '<pad>'\n",
    "    idx2words_ft_en[UNK_IDX] = '<unk>'\n",
    "    idx2words_ft_en[SOS_IDX] = '<s>'\n",
    "    idx2words_ft_en[EOS_IDX] = '</s>'\n",
    "    \n",
    "ordered_words_ft_en = list(words_ft_en.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(idx2words_ft) == len(words_ft)\n",
    "assert len(loaded_embeddings_ft) == len(words_ft)\n",
    "assert len(idx2words_ft_en) == len(words_ft_en)\n",
    "assert len(loaded_embeddings_ft_en) == len(words_ft_en)\n",
    "assert len(ordered_words_ft_en) == len(loaded_embeddings_ft_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add sos and eos in each sentence\n",
    "def add_sos_eos(lines):\n",
    "    \n",
    "    train = []\n",
    "    for l in lines:\n",
    "        l = '<s> ' + l + '</s>'\n",
    "        train.append(l)\n",
    "    return train\n",
    "zh_train = add_sos_eos(lines_zh)    \n",
    "en_train = add_sos_eos(lines_en)\n",
    "zh_test = add_sos_eos(lines_zh_test)\n",
    "en_test = add_sos_eos(lines_en_test)\n",
    "zh_val = add_sos_eos(lines_zh_val)\n",
    "en_val = add_sos_eos(lines_en_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert token to id in the dataset\n",
    "def token2index_dataset(tokens_data,eng = False):\n",
    "    indices_data = []\n",
    "    for tokens in tokens_data:\n",
    "        index_list = []\n",
    "        for token in tokens.split():\n",
    "            if eng == False:\n",
    "                try:\n",
    "                    index_list.append(words_ft[token])\n",
    "                except KeyError:\n",
    "                    index_list.append(UNK_IDX)\n",
    "            else:\n",
    "                try:\n",
    "                    index_list.append(words_ft_en[token])\n",
    "                except KeyError:\n",
    "                    index_list.append(UNK_IDX)\n",
    "        indices_data.append(index_list)\n",
    "    return indices_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "zh_train_indices = token2index_dataset(zh_train)\n",
    "en_train_indices = token2index_dataset(en_train,eng = True)\n",
    "zh_test_indices = token2index_dataset(zh_test)\n",
    "en_test_indices = token2index_dataset(en_test,eng = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#max_sentence_length\n",
    "length_of_en = [len(x.split()) for x in en_train]\n",
    "max_sentence_length_en = sorted(length_of_en)[-int(len(length_of_en)*0.01)]\n",
    "length_of_zh = [len(x.split()) for x in zh_train]\n",
    "max_sentence_length_zh = sorted(length_of_zh)[-int(len(length_of_zh)*0.01)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sentence_length_en =69"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Data Loader\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class load_dataset(Dataset):\n",
    "    \"\"\"\n",
    "    Class that represents a train/validation/test dataset that's readable for PyTorch\n",
    "    Note that this class inherits torch.utils.data.Dataset\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data_list_s1,data_list_s2):\n",
    "        \"\"\"\n",
    "        @param data_list_zh: list of Chinese tokens \n",
    "        @param data_list_en: list of English tokens as TARGETS\n",
    "        \"\"\"\n",
    "        self.data_list_s1 = data_list_s1\n",
    "        self.data_list_s2 = data_list_s2\n",
    "        \n",
    "        assert (len(self.data_list_s1) == len(self.data_list_s2))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_list_s1)\n",
    "        \n",
    "    def __getitem__(self, key):\n",
    "        \"\"\"\n",
    "        Triggered when you call dataset[i]\n",
    "        \"\"\"\n",
    "        \n",
    "        token_idx_s1 = self.data_list_s1[key][:max_sentence_length_zh]\n",
    "        token_idx_s2 = self.data_list_s2[key][:max_sentence_length_en]\n",
    "        return [token_idx_s1, token_idx_s2, len(token_idx_s1), len(token_idx_s2)]\n",
    "\n",
    "def collate_func(batch):\n",
    "    \"\"\"\n",
    "    Customized function for DataLoader that dynamically pads the batch so that all \n",
    "    data have the same length\n",
    "    \"\"\"\n",
    "    data_list_s1 = []\n",
    "    data_list_s2 = []\n",
    "    length_list_s1 = []\n",
    "    length_list_s2 = []\n",
    "    for datum in batch:\n",
    "        length_list_s1.append(datum[2])\n",
    "        length_list_s2.append(datum[3])\n",
    "        padded_vec_zh = np.pad(np.array(datum[0]), \n",
    "                                pad_width=((0,max_sentence_length_zh-datum[2])), \n",
    "                                mode=\"constant\", constant_values=0)\n",
    "        padded_vec_en = np.pad(np.array(datum[1]), \n",
    "                                pad_width=((0,max_sentence_length_en-datum[3])), \n",
    "                                mode=\"constant\", constant_values=0)\n",
    "        data_list_s1.append(padded_vec_zh[:max_sentence_length_zh])\n",
    "        data_list_s2.append(padded_vec_en[:max_sentence_length_en])\n",
    "    #print(type(data_list_s1[0]))\n",
    "    if torch.cuda.is_available and torch.has_cudnn:\n",
    "        return [torch.from_numpy(np.array(data_list_s1)).cuda(), torch.from_numpy(np.array(data_list_s2)).cuda(),\n",
    "                torch.LongTensor(length_list_s1).cuda(), torch.LongTensor(length_list_s2).cuda()]\n",
    "    else:    \n",
    "        return [torch.from_numpy(np.array(data_list_s1)), torch.from_numpy(np.array(data_list_s2)),\n",
    "                torch.LongTensor(length_list_s1), torch.LongTensor(length_list_s2)]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 30\n",
    "EMBEDDING_SIZE = 300 # fixed as from the input embedding data\n",
    "\n",
    "train_dataset = load_dataset(zh_train_indices, en_train_indices)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=collate_func,\n",
    "                                           shuffle=True)\n",
    "\n",
    "val_dataset = load_dataset(zh_test_indices, en_test_indices)\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_dataset,\n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=collate_func,\n",
    "                                           shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Self - Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define helper classes\n",
    "class LayerNorm(nn.Module):\n",
    "    \"Construct a layernorm module (See citation for details).\"\n",
    "    def __init__(self, features, eps=1e-6):\n",
    "        super(LayerNorm, self).__init__()\n",
    "        self.a_2 = nn.Parameter(torch.ones(features))\n",
    "        self.b_2 = nn.Parameter(torch.zeros(features))\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(-1, keepdim=True)\n",
    "        std = x.std(-1, keepdim=True)\n",
    "        return self.a_2 * (x - mean) / (std + self.eps) + self.b_2\n",
    "class SublayerConnection(nn.Module):\n",
    "    \"\"\"\n",
    "    A residual connection followed by a layer norm.\n",
    "    Note for code simplicity the norm is first as opposed to last.\n",
    "    \"\"\"\n",
    "    def __init__(self, size, dropout):\n",
    "        super(SublayerConnection, self).__init__()\n",
    "        self.norm = LayerNorm(size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, sublayer):\n",
    "        \"Apply residual connection to any sublayer with the same size.\"\n",
    "        return x + self.dropout(sublayer(self.norm(x)))\n",
    "\n",
    "class MultiHeadedAttention(nn.Module):\n",
    "    def __init__(self, h, d_model, dropout=0.1):\n",
    "        \"Take in model size and number of heads.\"\n",
    "        super(MultiHeadedAttention, self).__init__()\n",
    "        assert d_model % h == 0\n",
    "        # We assume d_v always equals d_k\n",
    "        self.d_k = d_model // h\n",
    "        self.h = h\n",
    "        self.linears = clones(nn.Linear(d_model, d_model), 4)\n",
    "        self.attn = None\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        \"Implements Figure 2\"\n",
    "        if mask is not None:\n",
    "            # Same mask applied to all h heads.\n",
    "            mask = mask.unsqueeze(1)\n",
    "        nbatches = query.size(0)\n",
    "        \n",
    "        # 1) Do all the linear projections in batch from d_model => h x d_k \n",
    "        query, key, value = \\\n",
    "            [l(x).view(nbatches, -1, self.h, self.d_k).transpose(1, 2)\n",
    "             for l, x in zip(self.linears, (query, key, value))]\n",
    "        \n",
    "        # 2) Apply attention on all the projected vectors in batch. \n",
    "        x, self.attn = attention(query, key, value, mask=mask, \n",
    "                                 dropout=self.dropout)\n",
    "        \n",
    "        # 3) \"Concat\" using a view and apply a final linear. \n",
    "        x = x.transpose(1, 2).contiguous() \\\n",
    "             .view(nbatches, -1, self.h * self.d_k)\n",
    "        return self.linears[-1](x)\n",
    "\n",
    "class PositionwiseFeedForward(nn.Module):\n",
    "    \"Implements FFN equation.\"\n",
    "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
    "        super(PositionwiseFeedForward, self).__init__()\n",
    "        self.w_1 = nn.Linear(d_model, d_ff)\n",
    "        self.w_2 = nn.Linear(d_ff, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.w_2(self.dropout(F.relu(self.w_1(x))))\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    \"Implement the PE function.\"\n",
    "    def __init__(self, d_model, dropout, max_len=max_sentence_length_en):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "        # Compute the positional encodings once in log space.\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0., max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0., d_model, 2) *\n",
    "                             -(math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x + Variable(self.pe[:, :x.size(1)], \n",
    "                         requires_grad=False)\n",
    "        return self.dropout(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define helper functions\n",
    "def attention(query, key, value, mask=None, dropout=None):\n",
    "    \"Compute 'Scaled Dot Product Attention'\"\n",
    "    d_k = query.size(-1)\n",
    "    scores = torch.matmul(query, key.transpose(-2, -1)) \\\n",
    "             / math.sqrt(d_k)\n",
    "    if mask is not None:\n",
    "        scores = scores.masked_fill(mask == 0, -1e9)\n",
    "    p_attn = F.softmax(scores, dim = -1)\n",
    "    if dropout is not None:\n",
    "        p_attn = dropout(p_attn)\n",
    "    return torch.matmul(p_attn, value), p_attn\n",
    "\n",
    "def clones(module, N):\n",
    "    \"Produce N identical layers.\"\n",
    "    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])\n",
    "\n",
    "def get_subsequent_mask(seq):\n",
    "    ''' For masking out the subsequent info. '''\n",
    "    sz_b, len_s = seq.size()\n",
    "    subsequent_mask = torch.triu(\n",
    "        torch.ones((len_s, len_s), device=seq.device, dtype=torch.uint8), diagonal=1)\n",
    "    subsequent_mask = subsequent_mask.unsqueeze(0).expand(sz_b, -1, -1)  # b x ls x ls\n",
    "\n",
    "    return Variable(subsequent_mask == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderDecoder(nn.Module):\n",
    "    \"\"\"\n",
    "    A standard Encoder-Decoder architecture. Base for this and many \n",
    "    other models.\n",
    "    \"\"\"\n",
    "    def __init__(self, encoder, decoder, src_embed, tgt_embed, generator):\n",
    "        super(EncoderDecoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.src_embed = src_embed\n",
    "        self.tgt_embed = tgt_embed\n",
    "        self.generator = generator\n",
    "        \n",
    "    def forward(self, src, tgt):\n",
    "        \"Take in and process masked src and target sequences.\"\n",
    "        tgt_mask = get_subsequent_mask(tgt)\n",
    "        return self.decode(self.encode(src),\n",
    "                            tgt, tgt_mask)\n",
    "    \n",
    "    def encode(self, src):\n",
    "        return self.encoder(self.src_embed(src))\n",
    "    \n",
    "    def decode(self, memory, tgt, tgt_mask):\n",
    "        return self.decoder(self.tgt_embed(tgt), memory, tgt_mask)\n",
    "    \n",
    "class Generator(nn.Module):\n",
    "    \"Define standard linear + softmax generation step.\"\n",
    "    def __init__(self, d_model, vocab):\n",
    "        super(Generator, self).__init__()\n",
    "        self.proj = nn.Linear(in_features=d_model,out_features=vocab)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.log_softmax(self.proj(x), dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \"Core encoder is a stack of N layers\"\n",
    "    def __init__(self, layer, N):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.layers = clones(layer, N)\n",
    "        self.norm = LayerNorm(layer.size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"Pass the input (and mask) through each layer in turn.\"\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return self.norm(x)\n",
    "    \n",
    "class EncoderLayer(nn.Module):\n",
    "    \"Encoder is made up of self-attn and feed forward (defined below)\"\n",
    "    def __init__(self, size, self_attn, feed_forward, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.self_attn = self_attn\n",
    "        self.feed_forward = feed_forward\n",
    "        self.sublayer = clones(SublayerConnection(size, dropout), 2)\n",
    "        self.size = size\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"Follow Figure 1 (left) for connections.\"\n",
    "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x))\n",
    "        return self.sublayer[1](x, self.feed_forward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    \"Generic N layer decoder with masking.\"\n",
    "    def __init__(self, layer, N):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.layers = clones(layer, N)\n",
    "        self.norm = LayerNorm(layer.size)\n",
    "        \n",
    "    def forward(self, x, memory, tgt_mask):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, memory, tgt_mask)\n",
    "        return self.norm(x)\n",
    "\n",
    "\n",
    "class DecoderLayer(nn.Module):\n",
    "    \"Decoder is made of self-attn, src-attn, and feed forward (defined below)\"\n",
    "    def __init__(self, size, self_attn, src_attn, feed_forward, dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.size = size\n",
    "        self.self_attn = self_attn\n",
    "        self.src_attn = src_attn\n",
    "        self.feed_forward = feed_forward\n",
    "        self.sublayer = clones(SublayerConnection(size, dropout), 3)\n",
    " \n",
    "    def forward(self, x, memory, tgt_mask):\n",
    "        \"Follow Figure 1 (right) for connections.\"\n",
    "        m = memory\n",
    "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, tgt_mask))\n",
    "        x = self.sublayer[1](x, lambda x: self.src_attn(x, m, m))\n",
    "        return self.sublayer[2](x, self.feed_forward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import StepLR, LambdaLR\n",
    "import pickle\n",
    "\n",
    "def trainIters(model, n_iters, folder,lr_decrease = False,print_every=1, plot_every=100, evaluate_every = 50,read_in_model = False,learning_rate=0.001,early_stop_tol = 10e-7):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    plot_val = []\n",
    "    \n",
    "    loss_history = []\n",
    "    \n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "    \n",
    "    patience = 0\n",
    "    \n",
    "    early_stopped = False\n",
    "    current_best_bleu = 0\n",
    "    \n",
    "    best_model = model.state_dict()\n",
    "    \n",
    "    #--------------------------------------------\t\n",
    "    #\t\n",
    "    #    LOAD MODELS\t\n",
    "    #\t\n",
    "    #--------------------------------------------\t\n",
    "    if not os.path.exists(folder):\t\n",
    "        os.makedirs(folder)\t\n",
    "\n",
    "    if os.path.exists(folder+'/Self_attent_b'):\t\n",
    "        print('---------------------------------------------------------------------')\t\n",
    "        print('----------------Readind trained model---------------------------------')\t\n",
    "        print('---------------------------------------------------------------------')\t\n",
    "        \t\n",
    "        #read trained models\t\n",
    "        model.load_state_dict(torch.load(folder+\"/Self_attent_b\"))\n",
    "    \n",
    "    model_optimizer = optim.Adam(model.parameters(), lr=learning_rate,betas=(0.9, 0.98), eps=1e-9)\n",
    "    \n",
    "    if lr_decrease == True:\n",
    "        model_scheduler = StepLR(model_optimizer, step_size=1, gamma=0.4)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    last_val = 0\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        print_loss_total = 0\n",
    "        if lr_decrease == True:\n",
    "            model_scheduler.step()\n",
    "        for i, (data_s1, data_s2, lengths_s1, lengths_s2) in enumerate(train_loader):\n",
    "            input_tensor = data_s1\n",
    "            target_tensor = data_s2\n",
    "            prob = model.generator(model.forward(input_tensor, target_tensor))\n",
    "            \n",
    "            model_optimizer.zero_grad()            \n",
    "            loss=0\n",
    "            for di in range(target_tensor.size(1)):\n",
    "                loss += criterion(prob[:,di], target_tensor[:,di])\n",
    "                        \n",
    "            print_loss_total += loss.item() / target_tensor.size(1)\n",
    "            \n",
    "            loss.backward()\n",
    "\n",
    "            model_optimizer.step()\n",
    "    \n",
    "            if i % print_every == 0:\n",
    "                if i != 0:\n",
    "                    print_loss_avg = print_loss_total / print_every\n",
    "                    print_loss_total = 0\n",
    "                    print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                                 iter, iter / n_iters * 100, print_loss_avg))\n",
    "                    loss_history.append(print_loss_avg)\n",
    "                else:\n",
    "                    print_loss_total = 0\n",
    "                \n",
    "            if i % plot_every == 0:\n",
    "                if i != 0:\n",
    "                    plot_loss_avg = plot_loss_total / plot_every\n",
    "                    plot_losses.append(plot_loss_avg)\n",
    "                    plot_loss_total = 0\n",
    "                    \n",
    "                    \n",
    "                else:\n",
    "                    plot_loss_total = 0\n",
    "                    \n",
    "        \n",
    "                        \n",
    "        # Save the model for every epoch\n",
    "        if early_stopped == False:\n",
    "        \n",
    "            # Save the model for every epoch\n",
    "            print('---------------------------------------------------------------------')\t\n",
    "            print('----------------Saving trained model---------------------------------')\t\n",
    "            print('---------------------------------------------------------------------')\t\n",
    "\n",
    "            torch.save(model.state_dict(),folder +\"/Self_attent_b\")\n",
    "            \n",
    "    with open(folder+\"/loss_hist\", 'wb') as f:\n",
    "         pickle.dump(loss_history, f)\n",
    "    with open(folder+\"/bleu_hist\", 'wb') as f:\n",
    "         pickle.dump(plot_val, f)\n",
    "    showPlot(plot_losses,title = \"Train Loss\",name = folder+\"/loss.jpeg\")\n",
    "    showPlot(plot_val, title = \"BLEU Score on Validation Set\",name = folder+\"/bleu.jpeg\")\n",
    "    return plot_losses\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(loader, model, after_train_mode = False,beam = False, beam_k = 1):\n",
    "    bleu_score_list = []\n",
    "    big_pred_list = []\n",
    "    big_ref_list = []\n",
    "    for i, (data_s1, data_s2, lengths_s1, lengths_s2) in enumerate(loader):\n",
    "        input_tensor = data_s1\n",
    "        target_tensor = data_s2\n",
    "        prob = model.generator(model.forward(input_tensor, target_tensor))\n",
    "        batch_size = prob.shape[0]\n",
    "        listed_prediction = []\n",
    "        for batch_i in range(batch_size):\n",
    "            _, topi = prob[batch_i].data.topk(1)\n",
    "            sent = index2token_sentence(topi)\n",
    "            listed_prediction.append(sent)\n",
    "        ref_num = 0\n",
    "        listed_reference = []\n",
    "        for ele in data_s2:\n",
    "            sent = index2token_sentence(ele)\n",
    "            #print (tokens)\n",
    "            #sent = ' '.join(tokens)\n",
    "            #print (sent)\n",
    "            listed_reference.append(sent)\n",
    "            ref_num += 1\n",
    "        bleu_score = corpus_bleu(listed_prediction,[listed_reference])\n",
    "        #for i in range(3):\n",
    "        #    print(listed_prediction[i])\n",
    "        #    print(listed_reference[i])\n",
    "        #    print('\\n')\n",
    "            \n",
    "        print('BLEU Score is %s' % (str(bleu_score.score)))\n",
    "        bleu_score_list.append(bleu_score)\n",
    "    return bleu_score_list\n",
    "\n",
    "def index2token_sentence(sentence_batch):\n",
    "    return ' '.join(idx2words_ft_en[sent.item()] for sent in sentence_batch if sent.item()!=PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)\n",
    "    \n",
    "import time\n",
    "import math\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(src_vocab, tgt_vocab, N=6, \n",
    "               d_model=300, d_ff=2048, h=10, dropout=0.1):\n",
    "    \"Helper: Construct a model from hyperparameters.\"\n",
    "    \"d_model has to be 300 because of our embedding choices\"\n",
    "    c = copy.deepcopy\n",
    "    attn = MultiHeadedAttention(h, d_model)\n",
    "    ff = PositionwiseFeedForward(d_model, d_ff, dropout)\n",
    "    position = PositionalEncoding(d_model, dropout)\n",
    "    model = EncoderDecoder(\n",
    "        Encoder(EncoderLayer(d_model, c(attn), c(ff), dropout), N),\n",
    "        Decoder(DecoderLayer(d_model, c(attn), c(attn), \n",
    "                             c(ff), dropout), N),\n",
    "        nn.Sequential(nn.Embedding.from_pretrained(torch.from_numpy(loaded_embeddings_ft).float(), freeze=False), c(position)),\n",
    "        nn.Sequential(nn.Embedding.from_pretrained(torch.from_numpy(loaded_embeddings_ft_en).float(), freeze=False), c(position)),\n",
    "        Generator(d_model, tgt_vocab))\n",
    "    \n",
    "    # This was important from their code. \n",
    "    # Initialize parameters with Glorot / fan_avg.\n",
    "    for p in model.parameters():\n",
    "        if p.dim() > 1:\n",
    "            nn.init.xavier_uniform_(p)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1m 58s (- 37m 23s) (1 5%) 3.2977\n",
      "3m 54s (- 74m 7s) (1 5%) 2.2464\n",
      "5m 50s (- 110m 55s) (1 5%) 1.9693\n",
      "7m 46s (- 147m 46s) (1 5%) 1.7688\n",
      "9m 42s (- 184m 34s) (1 5%) 1.6394\n",
      "11m 39s (- 221m 22s) (1 5%) 1.5306\n",
      "13m 35s (- 258m 11s) (1 5%) 1.4211\n",
      "15m 31s (- 295m 0s) (1 5%) 1.4057\n",
      "17m 27s (- 331m 45s) (1 5%) 1.2841\n",
      "19m 23s (- 368m 20s) (1 5%) 1.3054\n",
      "21m 18s (- 404m 54s) (1 5%) 1.2483\n",
      "23m 14s (- 441m 28s) (1 5%) 1.1669\n",
      "25m 10s (- 478m 13s) (1 5%) 1.1103\n",
      "27m 6s (- 515m 3s) (1 5%) 1.0886\n",
      "29m 2s (- 551m 53s) (1 5%) 1.0326\n",
      "30m 59s (- 588m 44s) (1 5%) 0.9665\n",
      "32m 55s (- 625m 36s) (1 5%) 0.9142\n",
      "34m 52s (- 662m 28s) (1 5%) 0.9057\n",
      "36m 48s (- 699m 21s) (1 5%) 0.8529\n",
      "38m 45s (- 736m 15s) (1 5%) 0.8456\n",
      "40m 41s (- 773m 9s) (1 5%) 0.8298\n",
      "42m 38s (- 810m 4s) (1 5%) 0.7980\n",
      "44m 34s (- 846m 59s) (1 5%) 0.7796\n",
      "46m 31s (- 883m 53s) (1 5%) 0.7603\n",
      "48m 27s (- 920m 48s) (1 5%) 0.7349\n",
      "50m 24s (- 957m 36s) (1 5%) 0.7350\n",
      "52m 20s (- 994m 22s) (1 5%) 0.6922\n",
      "54m 16s (- 1031m 7s) (1 5%) 0.6915\n",
      "56m 12s (- 1067m 54s) (1 5%) 0.6717\n",
      "58m 8s (- 1104m 43s) (1 5%) 0.6598\n",
      "60m 4s (- 1141m 33s) (1 5%) 0.6526\n",
      "62m 1s (- 1178m 21s) (1 5%) 0.6172\n",
      "63m 57s (- 1215m 3s) (1 5%) 0.5972\n",
      "65m 52s (- 1251m 39s) (1 5%) 0.6246\n",
      "67m 48s (- 1288m 20s) (1 5%) 0.5886\n",
      "69m 44s (- 1325m 1s) (1 5%) 0.5636\n",
      "71m 40s (- 1361m 43s) (1 5%) 0.5862\n",
      "73m 35s (- 1398m 19s) (1 5%) 0.5595\n",
      "75m 31s (- 1434m 57s) (1 5%) 0.5463\n",
      "77m 27s (- 1471m 41s) (1 5%) 0.5688\n",
      "79m 23s (- 1508m 25s) (1 5%) 0.5461\n",
      "81m 19s (- 1545m 3s) (1 5%) 0.5608\n",
      "83m 14s (- 1581m 44s) (1 5%) 0.5437\n",
      "85m 10s (- 1618m 27s) (1 5%) 0.5802\n",
      "87m 6s (- 1655m 10s) (1 5%) 0.5449\n",
      "89m 2s (- 1691m 50s) (1 5%) 0.5166\n",
      "90m 58s (- 1728m 32s) (1 5%) 0.5509\n",
      "92m 54s (- 1765m 18s) (1 5%) 0.5245\n",
      "94m 50s (- 1802m 4s) (1 5%) 0.5355\n",
      "96m 46s (- 1838m 41s) (1 5%) 0.5190\n",
      "98m 42s (- 1875m 20s) (1 5%) 0.5190\n",
      "100m 38s (- 1912m 4s) (1 5%) 0.5001\n",
      "102m 34s (- 1948m 49s) (1 5%) 0.5143\n",
      "104m 30s (- 1985m 35s) (1 5%) 0.4981\n",
      "106m 26s (- 2022m 18s) (1 5%) 0.5020\n",
      "108m 22s (- 2059m 1s) (1 5%) 0.5095\n",
      "110m 18s (- 2095m 48s) (1 5%) 0.5206\n",
      "112m 14s (- 2132m 31s) (1 5%) 0.4891\n",
      "114m 9s (- 2169m 9s) (1 5%) 0.4793\n",
      "116m 5s (- 2205m 46s) (1 5%) 0.5049\n",
      "118m 1s (- 2242m 20s) (1 5%) 0.5038\n",
      "119m 56s (- 2279m 0s) (1 5%) 0.5026\n",
      "121m 52s (- 2315m 39s) (1 5%) 0.4973\n",
      "123m 48s (- 2352m 19s) (1 5%) 0.4976\n",
      "125m 44s (- 2388m 58s) (1 5%) 0.4890\n",
      "127m 40s (- 2425m 40s) (1 5%) 0.5072\n",
      "129m 35s (- 2462m 20s) (1 5%) 0.5032\n",
      "131m 31s (- 2498m 59s) (1 5%) 0.4885\n",
      "133m 27s (- 2535m 34s) (1 5%) 0.4844\n",
      "135m 22s (- 2572m 14s) (1 5%) 0.4990\n",
      "137m 18s (- 2608m 54s) (1 5%) 0.4794\n",
      "139m 14s (- 2645m 33s) (1 5%) 0.4521\n",
      "141m 10s (- 2682m 23s) (1 5%) 0.4824\n",
      "143m 7s (- 2719m 18s) (1 5%) 0.4676\n",
      "145m 3s (- 2756m 15s) (1 5%) 0.4881\n",
      "147m 0s (- 2793m 10s) (1 5%) 0.4747\n",
      "148m 56s (- 2830m 1s) (1 5%) 0.4668\n",
      "150m 53s (- 2866m 57s) (1 5%) 0.4605\n",
      "152m 49s (- 2903m 44s) (1 5%) 0.4614\n",
      "154m 45s (- 2940m 22s) (1 5%) 0.4561\n",
      "156m 41s (- 2977m 5s) (1 5%) 0.4632\n",
      "158m 36s (- 3013m 39s) (1 5%) 0.4742\n",
      "160m 32s (- 3050m 17s) (1 5%) 0.4632\n",
      "162m 28s (- 3087m 4s) (1 5%) 0.4462\n",
      "164m 24s (- 3123m 52s) (1 5%) 0.4587\n",
      "166m 20s (- 3160m 32s) (1 5%) 0.4437\n",
      "168m 16s (- 3197m 10s) (1 5%) 0.4380\n",
      "170m 12s (- 3233m 52s) (1 5%) 0.4489\n",
      "172m 8s (- 3270m 34s) (1 5%) 0.4265\n",
      "174m 3s (- 3307m 15s) (1 5%) 0.4605\n",
      "175m 59s (- 3343m 55s) (1 5%) 0.4481\n",
      "177m 55s (- 3380m 40s) (1 5%) 0.4735\n",
      "179m 52s (- 3417m 28s) (1 5%) 0.4517\n",
      "181m 47s (- 3454m 9s) (1 5%) 0.4549\n",
      "183m 43s (- 3490m 43s) (1 5%) 0.4442\n",
      "185m 39s (- 3527m 22s) (1 5%) 0.4628\n",
      "187m 34s (- 3564m 4s) (1 5%) 0.4771\n",
      "189m 30s (- 3600m 42s) (1 5%) 0.4464\n",
      "191m 26s (- 3637m 21s) (1 5%) 0.4474\n",
      "193m 22s (- 3674m 1s) (1 5%) 0.4477\n",
      "195m 18s (- 3710m 42s) (1 5%) 0.4471\n",
      "197m 13s (- 3747m 25s) (1 5%) 0.4434\n",
      "199m 9s (- 3784m 4s) (1 5%) 0.4423\n",
      "201m 5s (- 3820m 40s) (1 5%) 0.4382\n",
      "203m 0s (- 3857m 16s) (1 5%) 0.4463\n",
      "204m 56s (- 3893m 57s) (1 5%) 0.4577\n",
      "206m 52s (- 3930m 40s) (1 5%) 0.4392\n",
      "208m 48s (- 3967m 19s) (1 5%) 0.4335\n",
      "210m 44s (- 4004m 2s) (1 5%) 0.4514\n",
      "212m 40s (- 4040m 49s) (1 5%) 0.4441\n",
      "214m 36s (- 4077m 33s) (1 5%) 0.4499\n",
      "216m 32s (- 4114m 16s) (1 5%) 0.4549\n",
      "218m 28s (- 4150m 56s) (1 5%) 0.4418\n",
      "220m 24s (- 4187m 38s) (1 5%) 0.4360\n",
      "222m 20s (- 4224m 23s) (1 5%) 0.4241\n",
      "224m 16s (- 4261m 9s) (1 5%) 0.4384\n",
      "226m 12s (- 4297m 49s) (1 5%) 0.4293\n",
      "228m 7s (- 4334m 28s) (1 5%) 0.4232\n",
      "230m 3s (- 4371m 10s) (1 5%) 0.4573\n",
      "231m 59s (- 4407m 48s) (1 5%) 0.4166\n",
      "233m 54s (- 4444m 23s) (1 5%) 0.4111\n",
      "235m 50s (- 4481m 6s) (1 5%) 0.4405\n",
      "237m 46s (- 4517m 52s) (1 5%) 0.4206\n",
      "239m 42s (- 4554m 36s) (1 5%) 0.4297\n",
      "241m 38s (- 4591m 19s) (1 5%) 0.4100\n",
      "243m 34s (- 4628m 2s) (1 5%) 0.4113\n",
      "245m 30s (- 4664m 47s) (1 5%) 0.4036\n",
      "247m 26s (- 4701m 32s) (1 5%) 0.4330\n",
      "249m 22s (- 4738m 15s) (1 5%) 0.4300\n",
      "251m 18s (- 4774m 57s) (1 5%) 0.4287\n",
      "253m 14s (- 4811m 39s) (1 5%) 0.4410\n",
      "255m 10s (- 4848m 22s) (1 5%) 0.4241\n",
      "257m 6s (- 4885m 8s) (1 5%) 0.4232\n",
      "259m 2s (- 4921m 46s) (1 5%) 0.3971\n",
      "260m 58s (- 4958m 26s) (1 5%) 0.4040\n",
      "262m 54s (- 4995m 10s) (1 5%) 0.4151\n",
      "264m 50s (- 5031m 52s) (1 5%) 0.4339\n",
      "266m 46s (- 5068m 37s) (1 5%) 0.4270\n",
      "268m 42s (- 5105m 19s) (1 5%) 0.4171\n",
      "270m 38s (- 5142m 2s) (1 5%) 0.4051\n",
      "272m 34s (- 5178m 46s) (1 5%) 0.4089\n",
      "274m 30s (- 5215m 30s) (1 5%) 0.4121\n",
      "---------------------------------------------------------------------\n",
      "----------------Saving trained model---------------------------------\n",
      "---------------------------------------------------------------------\n",
      "276m 56s (- 2492m 29s) (2 10%) 0.3956\n",
      "278m 52s (- 2509m 54s) (2 10%) 0.3531\n",
      "280m 48s (- 2527m 18s) (2 10%) 0.3493\n",
      "282m 44s (- 2544m 42s) (2 10%) 0.3670\n",
      "284m 40s (- 2562m 6s) (2 10%) 0.3685\n",
      "286m 36s (- 2579m 28s) (2 10%) 0.3462\n",
      "288m 32s (- 2596m 53s) (2 10%) 0.3496\n",
      "290m 28s (- 2614m 19s) (2 10%) 0.3416\n",
      "292m 24s (- 2631m 44s) (2 10%) 0.3438\n",
      "294m 20s (- 2649m 6s) (2 10%) 0.3586\n",
      "296m 16s (- 2666m 28s) (2 10%) 0.3531\n",
      "298m 12s (- 2683m 51s) (2 10%) 0.3523\n",
      "300m 8s (- 2701m 14s) (2 10%) 0.3624\n",
      "302m 4s (- 2718m 39s) (2 10%) 0.3510\n",
      "304m 0s (- 2736m 3s) (2 10%) 0.3455\n",
      "305m 56s (- 2753m 27s) (2 10%) 0.3517\n",
      "307m 52s (- 2770m 51s) (2 10%) 0.3434\n",
      "309m 48s (- 2788m 15s) (2 10%) 0.3473\n",
      "311m 44s (- 2805m 39s) (2 10%) 0.3510\n",
      "313m 40s (- 2823m 3s) (2 10%) 0.3750\n",
      "315m 36s (- 2840m 27s) (2 10%) 0.3417\n"
     ]
    }
   ],
   "source": [
    "model = make_model(src_vocab=len(ordered_words_ft), tgt_vocab=len(ordered_words_ft_en), N=10).to(device)\n",
    "\n",
    "##UNCOMMENT TO TRAIN THE MODEL\n",
    "\n",
    "trainIters(model, 20,'attentation_test', \n",
    "           lr_decrease = True,print_every=50,plot_every = 100, evaluate_every = 250,\n",
    "           read_in_model = False,learning_rate=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
