{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note:\n",
    "\n",
    "Add code to save graphs in showPlot function\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re  \n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import collections\n",
    "from itertools import dropwhile\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"data/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install sacrebleu\n",
    "from sacrebleu import corpus_bleu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in chinese-english pairs\n",
    "#read in chinese-english pairs\n",
    "lines_zh = open(PATH+'iwslt-zh-en/train.tok.zh',encoding = 'utf-8').read().strip().split('\\n')\n",
    "lines_en = open(PATH+'iwslt-zh-en/train.tok.en',encoding = 'utf-8').read().strip().split('\\n')\n",
    "lines_zh_test = open(PATH+'iwslt-zh-en/test.tok.zh',encoding = 'utf-8').read().strip().split('\\n')\n",
    "lines_en_test = open(PATH+'iwslt-zh-en/test.tok.en',encoding = 'utf-8').read().strip().split('\\n')\n",
    "lines_zh_val = open(PATH+'iwslt-zh-en/dev.tok.zh',encoding = 'utf-8').read().strip().split('\\n')\n",
    "lines_en_val = open(PATH+'iwslt-zh-en/dev.tok.en',encoding = 'utf-8').read().strip().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delect_least_common_words(list_sent, threshold = 5):\n",
    "    ret_list =[]\n",
    "    for x in list_sent:\n",
    "        ret_list += x.split()\n",
    "    ret_dic = collections.Counter(ret_list)\n",
    "    \n",
    "    #print (ret_dic[\"&amp;\"])\n",
    "    #print (ret_dic[\"&apos;\"])\n",
    "    #print (ret_dic[\"&quot;\"])\n",
    "    #print (ret_dic[\"&#91\"])\n",
    "    for key, count in dropwhile(lambda key_count: key_count[1] >= threshold, ret_dic.most_common()):\n",
    "        \n",
    "        del ret_dic[key]\n",
    "        \n",
    "        \n",
    "    return list(ret_dic.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "771\n",
      "2014\n",
      "29656\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "zh_words = delect_least_common_words(lines_zh)\n",
    "en_words = delect_least_common_words(lines_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_to_load = 100000\n",
    "PAD_IDX = 0\n",
    "UNK_IDX = 1\n",
    "SOS_IDX = 2\n",
    "EOS_IDX = 3\n",
    "\n",
    "with open(PATH+'cc.zh.300.vec') as f:\n",
    "    loaded_embeddings_ft = np.zeros((words_to_load+3, 300))\n",
    "    words_ft = {}\n",
    "    idx2words_ft = {}\n",
    "    ordered_words_ft = []\n",
    "    ordered_words_ft.extend(['<pad>', '<unk>', '<s>'])\n",
    "    loaded_embeddings_ft[0,:] = np.zeros(300)\n",
    "    loaded_embeddings_ft[1,:] = np.random.normal(size = 300)\n",
    "    loaded_embeddings_ft[2,:] = np.random.normal(size = 300)\n",
    "    for i, line in enumerate(f):\n",
    "        if i >= words_to_load: \n",
    "            break\n",
    "        s = line.split()\n",
    "        loaded_embeddings_ft[i+3, :] = np.asarray(s[1:])\n",
    "        words_ft[s[0]] = i+3\n",
    "        idx2words_ft[i+3] = s[0]\n",
    "        ordered_words_ft.append(s[0])\n",
    "    words_ft['<pad>'] = PAD_IDX\n",
    "    words_ft['<unk>'] = UNK_IDX\n",
    "    words_ft['<s>'] = SOS_IDX\n",
    "    idx2words_ft[PAD_IDX] = '<pad>'\n",
    "    idx2words_ft[UNK_IDX] = '<unk>'\n",
    "    idx2words_ft[SOS_IDX] = '<s>'\n",
    "\n",
    "#English embedding\n",
    "with open(PATH+'wiki-news-300d-1M.vec') as f:\n",
    "    loaded_embeddings_ft_en = np.zeros((words_to_load+4, 300))\n",
    "    words_ft_en = {}\n",
    "    idx2words_ft_en = {}\n",
    "    ordered_words_ft_en = []\n",
    "    ordered_words_ft_en.extend(['<pad>', '<unk>', '<s>', '</s>'])\n",
    "    loaded_embeddings_ft_en[0,:] = np.zeros(300)\n",
    "    loaded_embeddings_ft_en[1,:] = np.random.normal(size = 300)\n",
    "    loaded_embeddings_ft_en[2,:] = np.random.normal(size = 300)\n",
    "    loaded_embeddings_ft_en[3,:] = np.random.normal(size = 300)\n",
    "    for i, line in enumerate(f):\n",
    "        if i >= words_to_load: \n",
    "            break\n",
    "        s = line.split()\n",
    "        loaded_embeddings_ft_en[i+4, :] = np.asarray(s[1:])\n",
    "        words_ft_en[s[0]] = i+4\n",
    "        idx2words_ft_en[i+4] = s[0]\n",
    "        ordered_words_ft_en.append(s[0])\n",
    "    words_ft_en['<pad>'] = PAD_IDX\n",
    "    words_ft_en['<unk>'] = UNK_IDX\n",
    "    words_ft_en['<s>'] = SOS_IDX\n",
    "    words_ft_en['</s>'] = EOS_IDX\n",
    "    idx2words_ft_en[PAD_IDX] = '<pad>'\n",
    "    idx2words_ft_en[UNK_IDX] = '<unk>'\n",
    "    idx2words_ft_en[SOS_IDX] = '<s>'\n",
    "    idx2words_ft_en[EOS_IDX] = '</s>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "&#91;\n",
      "&#93;\n",
      "&amp;\n",
      "&apos;\n",
      "&apos;Ivoire\n",
      "&apos;Neill\n",
      "&apos;all\n",
      "&apos;am\n",
      "&apos;clock\n",
      "&apos;d\n",
      "&apos;ll\n",
      "&apos;m\n",
      "&apos;mon\n",
      "&apos;n\n",
      "&apos;re\n",
      "&apos;s\n",
      "&apos;s-eye\n",
      "&apos;t\n",
      "&apos;ve\n",
      "&quot;\n",
      "15-hour\n",
      "18-minute\n",
      "200-year\n",
      "2041\n",
      "23andMe\n",
      "3-minute\n",
      "3D-printed\n",
      "442nd\n",
      "4Shbab\n",
      "50x15\n",
      "90-degree\n",
      "A-rhythm\n",
      "A-rhythm-etic\n",
      "ARES\n",
      "Aah\n",
      "Abani\n",
      "Abegg\n",
      "Achill\n",
      "Acumen\n",
      "Adrianne\n",
      "Aicha\n",
      "Airstream\n",
      "Alisch\n",
      "AlloSphere\n",
      "Amitabha\n",
      "Angeline\n",
      "Anthropocene\n",
      "Apophis\n",
      "ApproTEC\n",
      "Aral\n",
      "Ariely\n",
      "Armantrout\n",
      "Asanga\n",
      "Ashaninka\n",
      "Atala\n",
      "Avaz\n",
      "Avelile\n",
      "Aveling\n",
      "Aylward\n",
      "B-rex\n",
      "BOMB\n",
      "BRCK\n",
      "Bageye\n",
      "Band-Aid\n",
      "Bandura\n",
      "Barricelli\n",
      "Basit\n",
      "Batiuk\n",
      "Beijerinck\n",
      "Belshazzar\n",
      "Benefield\n",
      "Benki\n",
      "Benyus\n",
      "Berlow\n",
      "Bia\n",
      "Biafran\n",
      "Biochemist\n",
      "Bioenergy\n",
      "Biomimicry\n",
      "Bionics\n",
      "Blackawton\n",
      "Blakley\n",
      "Bolte\n",
      "Bonobo\n",
      "Bonobos\n",
      "Boonlua\n",
      "Botton\n",
      "Brené\n",
      "Buba\n",
      "Buckminster\n",
      "Budrus\n",
      "Bueller\n",
      "Buzzcar\n",
      "C.O.s\n",
      "CAO\n",
      "CAPTCHA\n",
      "CAPTCHAs\n",
      "Cahana\n",
      "Caitria\n",
      "CalTech\n",
      "Capgras\n",
      "Carroça\n",
      "Centella\n",
      "Chambal\n",
      "Cheetos\n",
      "Cheval\n",
      "Chimborazo\n",
      "Chopsticks\n",
      "Christakis\n",
      "Claron\n",
      "Clonie\n",
      "Cloudburst\n",
      "Collaborator\n",
      "Collusion\n",
      "Connexions\n",
      "Copernican\n",
      "Corbusier\n",
      "Crimer\n",
      "DARwIn\n",
      "DIYbio\n",
      "DemocracyOS\n",
      "Denisovans\n",
      "Derartu\n",
      "Dereck\n",
      "Detroiters\n",
      "Dishman\n",
      "Divergence\n",
      "Doerr\n",
      "Dracorex\n",
      "Drori\n",
      "DryBath\n",
      "Duolingo\n",
      "E.O.\n",
      "ECX\n",
      "ELAM\n",
      "ESG\n",
      "Earth-like\n",
      "Earthlings\n",
      "Ecologist\n",
      "Ecosia\n",
      "Eighty-five\n",
      "Electrons\n",
      "Ellsey\n",
      "Elyn\n",
      "Emeka\n",
      "Engelbart\n",
      "Ensler\n",
      "FILMCLUB\n",
      "FOXO\n",
      "Faiza\n",
      "Fast-forward\n",
      "Faunal\n",
      "Feiler\n",
      "Feki\n",
      "Fide\n",
      "Figuring\n",
      "Fildes\n",
      "Fingertips\n",
      "Fluctus\n",
      "Forer\n",
      "Frates\n",
      "FreeSpeech\n",
      "Frigoris\n",
      "Frugal\n",
      "Furby\n",
      "GNH\n",
      "GPHIN\n",
      "Galvani\n",
      "Galvao\n",
      "Gando\n",
      "Gapminder\n",
      "Garífuna\n",
      "Gayla\n",
      "Gell-Mann\n",
      "Genspace\n",
      "Gershenfeld\n",
      "Gever\n",
      "Gezi\n",
      "Ghonim\n",
      "Glenny\n",
      "Gombe\n",
      "Googlers\n",
      "Gossamer\n",
      "Gourley\n",
      "Gowanus\n",
      "GreenLab\n",
      "Gyre\n",
      "HIV-negative\n",
      "Hadron\n",
      "Haidt\n",
      "Handspring\n",
      "Handwashing\n",
      "Hany\n",
      "Hatzalah\n",
      "Hawken\n",
      "Hawn\n",
      "Headwaters\n",
      "Hedy\n",
      "Himba\n",
      "Hippocratic\n",
      "Hirshhorn\n",
      "Hockenberry\n",
      "Hodgman\n",
      "Honeybees\n",
      "Housman\n",
      "Huaorani\n",
      "Hurtigruten\n",
      "HyperCard\n",
      "Hyperscore\n",
      "Hyun-Sook\n",
      "I.M.\n",
      "IDEO\n",
      "ImageNet\n",
      "Inconvenient\n",
      "Interviewer\n",
      "Iranian-American\n",
      "Itay\n",
      "Ituri\n",
      "JU\n",
      "JY\n",
      "Jansky\n",
      "Japanese-Americans\n",
      "Jeanny\n",
      "Jehane\n",
      "Jetman\n",
      "Jordans\n",
      "Jovita\n",
      "Jugaad\n",
      "Juliano\n",
      "Jurvetson\n",
      "K-T\n",
      "KIPP\n",
      "Kaaba\n",
      "Kaluza\n",
      "Kamkwamba\n",
      "Kanzi\n",
      "Karajan\n",
      "Kary\n",
      "Kibera\n",
      "Kismet\n",
      "Kiteflyer\n",
      "Kitra\n",
      "Kleiber\n",
      "Koolhaas\n",
      "Krosoczka\n",
      "Kuznets\n",
      "Kwabena\n",
      "LOLcats\n",
      "LSST\n",
      "LXD\n",
      "Ladenism\n",
      "Lamanites\n",
      "Lanting\n",
      "Layma\n",
      "Leadbeater\n",
      "Ledgett\n",
      "Legadema\n",
      "Legos\n",
      "Lesterland\n",
      "Lesters\n",
      "Leymah\n",
      "Libeskind\n",
      "Licklider\n",
      "Lifesaver\n",
      "Limor\n",
      "Lofa\n",
      "Lovins\n",
      "Lowline\n",
      "M-Pesa\n",
      "MBI\n",
      "MOOCs\n",
      "MaKey\n",
      "Maathai\n",
      "MacCready\n",
      "MacMaster\n",
      "Machover\n",
      "Majora\n",
      "Makoko\n",
      "Malé\n",
      "Manal\n",
      "Mankoff\n",
      "Manya\n",
      "Mapendo\n",
      "Mathare\n",
      "Maz\n",
      "McGonigal\n",
      "McNuggets\n",
      "Meegeren\n",
      "Meggendorfer\n",
      "Mellody\n",
      "Merckx\n",
      "Meyerowitz\n",
      "Mid-East\n",
      "Midol\n",
      "Miklos\n",
      "Mizzone\n",
      "Mola\n",
      "Molas\n",
      "Moleeds\n",
      "Monologues\n",
      "Moschen\n",
      "Motts\n",
      "Mulgan\n",
      "Mullis\n",
      "Muslim-majority\n",
      "Muti\n",
      "Mycoplasma\n",
      "Myesha\n",
      "Myhrvold\n",
      "Mídia\n",
      "NINJA\n",
      "Nachtwey\n",
      "Naghma\n",
      "Najmuddin\n",
      "Nalini\n",
      "Nanopatch\n",
      "Naná\n",
      "Narration\n",
      "Netizens\n",
      "Netra\n",
      "Neuroscientist\n",
      "Neuwirth\n",
      "Ngozi\n",
      "Nicolelis\n",
      "Nikolayevich\n",
      "Ninos\n",
      "Nollywood\n",
      "Noujaim\n",
      "Novocure\n",
      "Novogratz\n",
      "Nyota\n",
      "OMEGA\n",
      "Okapi\n",
      "Okolloh\n",
      "Ommm\n",
      "One-two-three-four\n",
      "Onstage\n",
      "Ornish\n",
      "Oshea\n",
      "Overflow\n",
      "Ow\n",
      "Oxytocin\n",
      "PIPA\n",
      "PMTCT\n",
      "PRIZE\n",
      "Panbanisha\n",
      "Paradoxically\n",
      "Paravicini\n",
      "Parikrma\n",
      "Perasa\n",
      "Picchu\n",
      "Play-Doh\n",
      "Pleo\n",
      "Pollan\n",
      "Porco\n",
      "Post-it\n",
      "PostSecret\n",
      "Poupon\n",
      "Pranav\n",
      "Prego\n",
      "Preity\n",
      "Prickly\n",
      "Prince-Ramus\n",
      "Prospera\n",
      "Protei\n",
      "ProtonMail\n",
      "R-I-A-A\n",
      "RHex\n",
      "RISD\n",
      "RNG\n",
      "ROD\n",
      "ROVs\n",
      "RSW\n",
      "Raghava\n",
      "Ragu\n",
      "Redwoods\n",
      "Remen\n",
      "Remittances\n",
      "Renny\n",
      "Reuther\n",
      "Rezero\n",
      "Rikers\n",
      "Rives\n",
      "Robicsek\n",
      "Rockett\n",
      "Rosling\n",
      "Rossy\n",
      "S-H\n",
      "SAMS\n",
      "SANCCOB\n",
      "SING\n",
      "STriDER\n",
      "Safdie\n",
      "Sagmeister\n",
      "Sakena\n",
      "Salicornia\n",
      "Sandel\n",
      "Sanghamitra\n",
      "Sargasso\n",
      "Savage-Rumbaugh\n",
      "Schlaug\n",
      "Schocken\n",
      "Sculpey\n",
      "Selam\n",
      "Sendhil\n",
      "Shephelah\n",
      "Shereen\n",
      "Shirky\n",
      "Shreddies\n",
      "Siq\n",
      "Sirena\n",
      "Sitopia\n",
      "Sivers\n",
      "SixthSense\n",
      "Sixty-five\n",
      "Skerry\n",
      "Skoll\n",
      "Skycar\n",
      "Sobule\n",
      "SolarCity\n",
      "Solly\n",
      "SpaceShipOne\n",
      "Spinosaurus\n",
      "Splashy\n",
      "Starck\n",
      "StoryCorps\n",
      "Studs\n",
      "Stygimoloch\n",
      "Subtitles\n",
      "Sugata\n",
      "Sunitha\n",
      "Swaptree\n",
      "Sys\n",
      "Szymborska\n",
      "T.B.\n",
      "TACARE\n",
      "TBP\n",
      "TED2006\n",
      "TED2008\n",
      "TED2010\n",
      "TED2011\n",
      "TED2012\n",
      "TEDGlobal\n",
      "TEDIndia\n",
      "TEDMED\n",
      "TEDTalk\n",
      "TEDTalks\n",
      "TEDWomen\n",
      "TEDs\n",
      "TEDster\n",
      "TEDsters\n",
      "TEDx\n",
      "TEDxSummit\n",
      "TV-industrial\n",
      "Tahltan\n",
      "Taji\n",
      "Talgam\n",
      "Tarahumara\n",
      "Tarter\n",
      "TaskRabbit\n",
      "Technorati\n",
      "Tele-Actor\n",
      "Tembererana\n",
      "Teszler\n",
      "Tewksbury\n",
      "Texting\n",
      "Thrun\n",
      "Thula\n",
      "Tibbits\n",
      "Tidying\n",
      "Tinkering\n",
      "Tipper\n",
      "Tombo\n",
      "Toonchi-too\n",
      "Toraja\n",
      "Torajans\n",
      "Torosaurus\n",
      "Toxo\n",
      "Tso\n",
      "Tulley\n",
      "U.C.\n",
      "Upwake\n",
      "Ushahidi\n",
      "V-Day\n",
      "Vannevar\n",
      "Vashem\n",
      "Vending\n",
      "Vibrio\n",
      "Vineet\n",
      "Vint\n",
      "WITNESS\n",
      "WMAP\n",
      "Wangari\n",
      "Whewell\n",
      "Whitesides\n",
      "Widder\n",
      "WikiHouse\n",
      "Winky\n",
      "Wislawa\n",
      "WorldWide\n",
      "Worldchanging\n",
      "Worldchanging.com\n",
      "Wujec\n",
      "Wurman\n",
      "Wyly\n",
      "X-axis\n",
      "XDR-TB\n",
      "Y-axis\n",
      "YB\n",
      "YR\n",
      "Yochai\n",
      "Yuck\n",
      "ZK\n",
      "Zabbaleen\n",
      "Zappos\n",
      "Zig\n",
      "Zimbardo\n",
      "Zullinger\n",
      "a-rhythm\n",
      "aah\n",
      "ack\n",
      "acoustician\n",
      "acromegaly\n",
      "al-Sharif\n",
      "all-terrain\n",
      "altruist\n",
      "always-on\n",
      "amyloid-beta\n",
      "anesthetize\n",
      "anthropomorphize\n",
      "antiangiogenic\n",
      "antianxiety\n",
      "arguer\n",
      "aromatase\n",
      "astrolabe\n",
      "atomized\n",
      "atrophied\n",
      "aunties\n",
      "aurochs\n",
      "bam\n",
      "band-tailed\n",
      "baobab\n",
      "barbaria\n",
      "billionth\n",
      "biodegrade\n",
      "biofabrication\n",
      "bioluminescent\n",
      "biomaterial\n",
      "biomimicry\n",
      "bionics\n",
      "black-eyed\n",
      "bleep\n",
      "bloop\n",
      "boca\n",
      "bombsight\n",
      "bonobo\n",
      "brain-machine\n",
      "brainstorms\n",
      "brainwaves\n",
      "breadwinners\n",
      "briquettes\n",
      "bummer\n",
      "capuchin\n",
      "car-sharing\n",
      "carbon-free\n",
      "carbon-neutral\n",
      "carroças\n",
      "catadores\n",
      "centigrade\n",
      "channelrhodopsin\n",
      "chemistries\n",
      "chirps\n",
      "chk\n",
      "cingulate\n",
      "civilization-state\n",
      "civilizational\n",
      "clarion\n",
      "clicker\n",
      "cobras\n",
      "coltan\n",
      "compassionately\n",
      "connectome\n",
      "connectomes\n",
      "convulsion\n",
      "cosmologist\n",
      "coumarin\n",
      "crowd-sourced\n",
      "crowdsource\n",
      "cybercriminal\n",
      "cybercriminals\n",
      "cyberwar\n",
      "cymatics\n",
      "d.school\n",
      "daf-2\n",
      "de-extinction\n",
      "decompiculture\n",
      "deconstructive\n",
      "deep-diving\n",
      "deforested\n",
      "democratize\n",
      "democratized\n",
      "diarrheal\n",
      "dirigible\n",
      "dirtiest\n",
      "dispersants\n",
      "dollars-worth\n",
      "doodling\n",
      "dragline\n",
      "dragon-king\n",
      "e-Patient\n",
      "eardrum\n",
      "eavesdrop\n",
      "edX\n",
      "electroencephalogram\n",
      "electrogram\n",
      "electromagnet\n",
      "electroshock\n",
      "empathizing\n",
      "enigmas\n",
      "enormity\n",
      "epiphytes\n",
      "ethicist\n",
      "eureka\n",
      "evolvable\n",
      "exoskeletons\n",
      "extra-chunky\n",
      "extrasolar\n",
      "extroverts\n",
      "fallibility\n",
      "fascinates\n",
      "female-pattern\n",
      "ferrofluid\n",
      "firefly\n",
      "fischeri\n",
      "fluidly\n",
      "forager\n",
      "four-foot\n",
      "four-year-olds\n",
      "free-style\n",
      "frickin\n",
      "fusiform\n",
      "futureless\n",
      "gaga\n",
      "gavage\n",
      "genitalium\n",
      "geo-engineering\n",
      "gharial\n",
      "gigatons\n",
      "gigawatt\n",
      "globalizing\n",
      "gnarly\n",
      "goliath\n",
      "goosebumps\n",
      "goro\n",
      "granddad\n",
      "gratefulness\n",
      "greenest\n",
      "groupers\n",
      "grownup\n",
      "guga\n",
      "gymnosophist\n",
      "gyre\n",
      "head-tail-head\n",
      "head-tail-tail\n",
      "headrest\n",
      "hells\n",
      "hotdog\n",
      "human-computer\n",
      "human-powered\n",
      "human-to-human\n",
      "humanize\n",
      "hundred-dollar\n",
      "hurdy-gurdy\n",
      "hustles\n",
      "hyper-consumption\n",
      "icefall\n",
      "ikigai\n",
      "iliac\n",
      "image-making\n",
      "improbability\n",
      "incentivize\n",
      "insula\n",
      "interspecies\n",
      "introversion\n",
      "introvert\n",
      "introverts\n",
      "intuit\n",
      "jeweled\n",
      "jirga\n",
      "justness\n",
      "lap-and-shoulder\n",
      "leatherback\n",
      "lecture-based\n",
      "letter-writing\n",
      "lettuces\n",
      "levitate\n",
      "levitated\n",
      "lifesaver\n",
      "light-activated\n",
      "light-sensitive\n",
      "limbic\n",
      "location-aware\n",
      "locomotor\n",
      "malarial\n",
      "male-pattern\n",
      "maneuverable\n",
      "manta\n",
      "medicalized\n",
      "medina\n",
      "meditators\n",
      "megacities\n",
      "meme-ome\n",
      "memetics\n",
      "metabolizing\n",
      "metronome\n",
      "micro-controllers\n",
      "micro-finance\n",
      "micro-machines\n",
      "microRNAs\n",
      "microalgae\n",
      "microbloggers\n",
      "microblogging\n",
      "microfluidic\n",
      "micrometeorites\n",
      "mid-ocean\n",
      "mildness\n",
      "mind-wandering\n",
      "mismatcher\n",
      "mockingbird\n",
      "mola\n",
      "moment-to-moment\n",
      "moratoriums\n",
      "multi-touch\n",
      "must-do\n",
      "mustaches\n",
      "mycorrhiza\n",
      "napot\n",
      "narcosis\n",
      "necrophilia\n",
      "neocortex\n",
      "neocortical\n",
      "neurologically\n",
      "neuromodulators\n",
      "neuropsychologist\n",
      "nine-year-olds\n",
      "no-take\n",
      "noes\n",
      "noisier\n",
      "non-living\n",
      "non-visual\n",
      "non-zero-sum\n",
      "non-zero-sumness\n",
      "nonverbals\n",
      "obsessional\n",
      "ocean-basin-wide\n",
      "oculus\n",
      "oncogene\n",
      "one-two-three\n",
      "one-two-three-four\n",
      "ontogeny\n",
      "open-heart\n",
      "opportunity-makers\n",
      "opposable\n",
      "out-of-body\n",
      "oven-like\n",
      "overdo\n",
      "pan-African\n",
      "papercutting\n",
      "parabolas\n",
      "partons\n",
      "percolate\n",
      "petri\n",
      "photo-real\n",
      "phototherapy\n",
      "pinwheel\n",
      "play-dough\n",
      "pluripotent\n",
      "pointillist\n",
      "pollinate\n",
      "pollinated\n",
      "pollinating\n",
      "pooping\n",
      "post-docs\n",
      "pre-frontal\n",
      "pressure-sensitive\n",
      "private-public\n",
      "pro-social\n",
      "progeria\n",
      "proscenium\n",
      "protocell\n",
      "protocells\n",
      "prototyped\n",
      "psyched\n",
      "psycho-social\n",
      "pushcart\n",
      "quadrillion\n",
      "queerer\n",
      "quot\n",
      "re-engage\n",
      "re-grow\n",
      "read-write\n",
      "reasoner\n",
      "reboxetine\n",
      "rebreather\n",
      "recapitulate\n",
      "recombine\n",
      "regrow\n",
      "rehydration\n",
      "reimagine\n",
      "reimagining\n",
      "reinnervation\n",
      "repairability\n",
      "replicator\n",
      "replicators\n",
      "reprogram\n",
      "rete\n",
      "retinas\n",
      "retool\n",
      "rewilding\n",
      "rewire\n",
      "rhinovirus\n",
      "rhinoviruses\n",
      "roadrunner\n",
      "romanticize\n",
      "résumés\n",
      "sacredness\n",
      "saddle-shaped\n",
      "sargassum\n",
      "secreting\n",
      "self-assemble\n",
      "self-assembling\n",
      "self-cleaning\n",
      "self-exploration\n",
      "self-organized\n",
      "self-replication\n",
      "self-transcendence\n",
      "sequestering\n",
      "seven-year-olds\n",
      "shoulder-to-shoulder\n",
      "sigmoidal\n",
      "six-and-a-half\n",
      "six-year-olds\n",
      "sixth-graders\n",
      "sledges\n",
      "slingers\n",
      "solar-electrified\n",
      "space-faring\n",
      "spectrogram\n",
      "spoofer\n",
      "squish\n",
      "staph\n",
      "starshade\n",
      "stimulators\n",
      "stomatopod\n",
      "stupidest\n",
      "sub-orbital\n",
      "submersibles\n",
      "suey\n",
      "sun-like\n",
      "super-exponential\n",
      "supermassive\n",
      "supernormal\n",
      "superorganism\n",
      "superstring\n",
      "swum\n",
      "synecdochically\n",
      "synesthetic\n",
      "telepresence\n",
      "tembererana\n",
      "teme\n",
      "temes\n",
      "terawatt\n",
      "terroir\n",
      "theremin\n",
      "thermo-bimetal\n",
      "thought-controlled\n",
      "thousandth\n",
      "three-digit\n",
      "three-inch\n",
      "three-pound\n",
      "throes\n",
      "thumb-wrestling\n",
      "thylacine\n",
      "thylacines\n",
      "tinier\n",
      "tone-deaf\n",
      "trachoma\n",
      "treaty-based\n",
      "trocar\n",
      "trucked\n",
      "tunas\n",
      "two-by-two\n",
      "two-digit\n",
      "two-wheeler\n",
      "ubuntu\n",
      "uh-huh\n",
      "ultra-dense\n",
      "un-retouched\n",
      "unbeknownst\n",
      "uncontacted\n",
      "underly\n",
      "untie\n",
      "upright-walking\n",
      "urbanizing\n",
      "utero\n",
      "valentines\n",
      "varroa\n",
      "vastness\n",
      "venereal\n",
      "ventilate\n",
      "vertical-takeoff\n",
      "virally\n",
      "virtuality\n",
      "voila\n",
      "volantor\n",
      "walkability\n",
      "watt-hours\n",
      "wetsuit\n",
      "whaleship\n",
      "whole-hearted\n",
      "wiggles\n",
      "wingsuit\n",
      "wiper\n",
      "wisps\n",
      "world-changing\n",
      "x-axis\n",
      "y-axis\n",
      "yellowfin\n",
      "yuck\n",
      "zero-g\n"
     ]
    }
   ],
   "source": [
    "for idx, word in enumerate(np.setdiff1d(en_words, ordered_words_ft_en)):\n",
    "    print (word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_to_load = 100000\n",
    "PAD_IDX = 0\n",
    "UNK_IDX = 1\n",
    "SOS_IDX = 2\n",
    "EOS_IDX = 3\n",
    "\n",
    "with open(PATH+'cc.zh.300.vec') as f:\n",
    "    loaded_embeddings_ft = np.zeros((words_to_load+3, 300))\n",
    "    words_ft = {}\n",
    "    idx2words_ft = {}\n",
    "    ordered_words_ft = []\n",
    "    ordered_words_ft.extend(['<pad>', '<unk>', '<s>'])\n",
    "    loaded_embeddings_ft[0,:] = np.zeros(300)\n",
    "    loaded_embeddings_ft[1,:] = np.random.normal(size = 300)\n",
    "    loaded_embeddings_ft[2,:] = np.random.normal(size = 300)\n",
    "    for i, line in enumerate(f):\n",
    "        if i >= words_to_load: \n",
    "            break\n",
    "        s = line.split()\n",
    "        loaded_embeddings_ft[i+3, :] = np.asarray(s[1:])\n",
    "        words_ft[s[0]] = i+3\n",
    "        idx2words_ft[i+3] = s[0]\n",
    "        ordered_words_ft.append(s[0])\n",
    "    length = len(np.setdiff1d(zh_words, ordered_words_ft))\n",
    "    tmp_embeddings = np.zeros((length, 300))\n",
    "    for idx, word in enumerate(np.setdiff1d(zh_words, ordered_words_ft)):\n",
    "        words_ft[word] = idx+words_to_load+3\n",
    "        idx2words_ft[idx+words_to_load+3] = word\n",
    "        tmp_embeddings[idx, :] = np.random.normal(size = 300)\n",
    "    loaded_embeddings_ft = np.concatenate((loaded_embeddings_ft, tmp_embeddings), axis = 0)\n",
    "    words_ft['<pad>'] = PAD_IDX\n",
    "    words_ft['<unk>'] = UNK_IDX\n",
    "    words_ft['<s>'] = SOS_IDX\n",
    "    idx2words_ft[PAD_IDX] = '<pad>'\n",
    "    idx2words_ft[UNK_IDX] = '<unk>'\n",
    "    idx2words_ft[SOS_IDX] = '<s>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#English embedding\n",
    "with open(PATH+'wiki-news-300d-1M.vec') as f:\n",
    "    loaded_embeddings_ft_en = np.zeros((words_to_load+4, 300))\n",
    "    words_ft_en = {}\n",
    "    idx2words_ft_en = {}\n",
    "    ordered_words_ft_en = []\n",
    "    ordered_words_ft_en.extend(['<pad>', '<unk>', '<s>', '</s>'])\n",
    "    loaded_embeddings_ft_en[0,:] = np.zeros(300)\n",
    "    loaded_embeddings_ft_en[1,:] = np.random.normal(size = 300)\n",
    "    loaded_embeddings_ft_en[2,:] = np.random.normal(size = 300)\n",
    "    loaded_embeddings_ft_en[3,:] = np.random.normal(size = 300)\n",
    "    for i, line in enumerate(f):\n",
    "        if i >= words_to_load: \n",
    "            break\n",
    "        s = line.split()\n",
    "        loaded_embeddings_ft_en[i+4, :] = np.asarray(s[1:])\n",
    "        words_ft_en[s[0]] = i+4\n",
    "        idx2words_ft_en[i+4] = s[0]\n",
    "        ordered_words_ft_en.append(s[0])\n",
    "    length = len(np.setdiff1d(en_words, ordered_words_ft_en))\n",
    "    tmp_embeddings = np.zeros((length, 300))\n",
    "    for idx, word in enumerate(np.setdiff1d(en_words, ordered_words_ft_en)):\n",
    "        words_ft_en[word] = idx+words_to_load+4\n",
    "        idx2words_ft_en[idx+words_to_load+4] = word\n",
    "        tmp_embeddings[idx, :] = np.random.normal(size = 300)\n",
    "    loaded_embeddings_ft_en = np.concatenate((loaded_embeddings_ft_en, tmp_embeddings), axis = 0)\n",
    "    words_ft_en['<pad>'] = PAD_IDX\n",
    "    words_ft_en['<unk>'] = UNK_IDX\n",
    "    words_ft_en['<s>'] = SOS_IDX\n",
    "    words_ft_en['</s>'] = EOS_IDX\n",
    "    idx2words_ft_en[PAD_IDX] = '<pad>'\n",
    "    idx2words_ft_en[UNK_IDX] = '<unk>'\n",
    "    idx2words_ft_en[SOS_IDX] = '<s>'\n",
    "    idx2words_ft_en[EOS_IDX] = '</s>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.79869912,  1.46128091,  0.11428397, ..., -1.52910412,\n",
       "         0.48773032,  0.32303459],\n",
       "       [ 0.94128651,  0.56052646, -0.1102972 , ...,  0.03731587,\n",
       "        -0.11548435,  1.61760977],\n",
       "       ...,\n",
       "       [ 1.35850218, -0.50144133,  0.74495701, ..., -0.71505851,\n",
       "        -0.07255102,  1.32304673],\n",
       "       [ 1.48546289, -0.70037252,  0.07368666, ...,  0.40099942,\n",
       "        -0.24083316,  1.85793499],\n",
       "       [ 1.16017146, -0.01182964,  1.04587374, ..., -1.05127933,\n",
       "        -0.47294914,  0.53223868]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assert len(idx2words_ft) == len(words_ft)\n",
    "assert len(loaded_embeddings_ft) == len(words_ft)\n",
    "assert len(idx2words_ft_en) == len(words_ft_en)\n",
    "assert len(loaded_embeddings_ft_en) == len(words_ft_en)\n",
    "loaded_embeddings_ft_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add sos and eos in each sentence\n",
    "def add_sos_eos(lines):\n",
    "    \n",
    "    train = []\n",
    "    for l in lines:\n",
    "        l = '<s> ' + l + '</s>'\n",
    "        train.append(l)\n",
    "    return train\n",
    "zh_train = add_sos_eos(lines_zh)    \n",
    "en_train = add_sos_eos(lines_en)\n",
    "zh_test = add_sos_eos(lines_zh_test)\n",
    "en_test = add_sos_eos(lines_en_test)\n",
    "zh_val = add_sos_eos(lines_zh_val)\n",
    "en_val = add_sos_eos(lines_en_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert token to id in the dataset\n",
    "def token2index_dataset(tokens_data,eng = False):\n",
    "    indices_data = []\n",
    "    for tokens in tokens_data:\n",
    "        index_list = []\n",
    "        for token in tokens.split():\n",
    "            if eng == False:\n",
    "                try:\n",
    "                    index_list.append(words_ft[token])\n",
    "                except KeyError:\n",
    "                    index_list.append(UNK_IDX)\n",
    "            else:\n",
    "                try:\n",
    "                    index_list.append(words_ft_en[token])\n",
    "                except KeyError:\n",
    "                    index_list.append(UNK_IDX)\n",
    "        indices_data.append(index_list)\n",
    "    return indices_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "zh_train_indices = token2index_dataset(zh_train)\n",
    "en_train_indices = token2index_dataset(en_train,eng = True)\n",
    "zh_test_indices = token2index_dataset(zh_test)\n",
    "en_test_indices = token2index_dataset(en_test,eng = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#max_sentence_length\n",
    "length_of_en = [len(x.split()) for x in en_train]\n",
    "max_sentence_length_en = sorted(length_of_en)[-int(len(length_of_en)*0.01)]\n",
    "length_of_zh = [len(x.split()) for x in zh_train]\n",
    "max_sentence_length_zh = sorted(length_of_zh)[-int(len(length_of_zh)*0.01)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_sentence_length_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Data Loader\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class load_dataset(Dataset):\n",
    "    \"\"\"\n",
    "    Class that represents a train/validation/test dataset that's readable for PyTorch\n",
    "    Note that this class inherits torch.utils.data.Dataset\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data_list_s1,data_list_s2):\n",
    "        \"\"\"\n",
    "        @param data_list_zh: list of Chinese tokens \n",
    "        @param data_list_en: list of English tokens as TARGETS\n",
    "        \"\"\"\n",
    "        self.data_list_s1 = data_list_s1\n",
    "        self.data_list_s2 = data_list_s2\n",
    "        \n",
    "        assert (len(self.data_list_s1) == len(self.data_list_s2))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_list_s1)\n",
    "        \n",
    "    def __getitem__(self, key):\n",
    "        \"\"\"\n",
    "        Triggered when you call dataset[i]\n",
    "        \"\"\"\n",
    "        \n",
    "        token_idx_s1 = self.data_list_s1[key][:max_sentence_length_zh]\n",
    "        token_idx_s2 = self.data_list_s2[key][:max_sentence_length_en]\n",
    "        return [token_idx_s1, token_idx_s2, len(token_idx_s1), len(token_idx_s2)]\n",
    "\n",
    "def collate_func(batch):\n",
    "    \"\"\"\n",
    "    Customized function for DataLoader that dynamically pads the batch so that all \n",
    "    data have the same length\n",
    "    \"\"\"\n",
    "    data_list_s1 = []\n",
    "    data_list_s2 = []\n",
    "    length_list_s1 = []\n",
    "    length_list_s2 = []\n",
    "    for datum in batch:\n",
    "        length_list_s1.append(datum[2])\n",
    "        length_list_s2.append(datum[3])\n",
    "        padded_vec_zh = np.pad(np.array(datum[0]), \n",
    "                                pad_width=((0,max_sentence_length_zh-datum[2])), \n",
    "                                mode=\"constant\", constant_values=0)\n",
    "        padded_vec_en = np.pad(np.array(datum[1]), \n",
    "                                pad_width=((0,max_sentence_length_en-datum[3])), \n",
    "                                mode=\"constant\", constant_values=0)\n",
    "        data_list_s1.append(padded_vec_zh[:max_sentence_length_zh])\n",
    "        data_list_s2.append(padded_vec_en[:max_sentence_length_en])\n",
    "    #print(type(data_list_s1[0]))\n",
    "    if torch.cuda.is_available and torch.has_cudnn:\n",
    "        return [torch.from_numpy(np.array(data_list_s1)).cuda(), torch.from_numpy(np.array(data_list_s2)).cuda(),\n",
    "                torch.LongTensor(length_list_s1).cuda(), torch.LongTensor(length_list_s2).cuda()]\n",
    "    else:    \n",
    "        return [torch.from_numpy(np.array(data_list_s1)), torch.from_numpy(np.array(data_list_s2)),\n",
    "                torch.LongTensor(length_list_s1), torch.LongTensor(length_list_s2)]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 100\n",
    "EMBEDDING_SIZE = 300 # fixed as from the input embedding data\n",
    "\n",
    "train_dataset = load_dataset(zh_train_indices, en_train_indices)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=collate_func,\n",
    "                                           shuffle=True)\n",
    "\n",
    "val_dataset = load_dataset(zh_test_indices, en_test_indices)\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_dataset,\n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=collate_func,\n",
    "                                           shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, emb_dim, hidden_size, embed= torch.from_numpy(loaded_embeddings_ft).float(),num_layers=1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.emb_dim = emb_dim\n",
    "        self.num_layers = num_layers \n",
    "\n",
    "        self.embedding = nn.Embedding.from_pretrained(embed, freeze=False)\n",
    "        #self.gru = nn.GRU(emb_dim, hidden_size,num_layers=num_layers,batch_first=True,bidirectional = True)\n",
    "        self.rnn = nn.LSTM(self.emb_dim, self.hidden_size, batch_first=True,\n",
    "                           num_layers=self.num_layers, bidirectional=True)\n",
    "\n",
    "    def forward(self, data, hidden):\n",
    "        #hidden is a tuple (h,c)\n",
    "        #dimension of h: num_layers * num_directions, batch, hidden_size \n",
    "        \n",
    "        batch_size, seq_len = data.size()\n",
    "        \n",
    "        embed = self.embedding(data)\n",
    "        \n",
    "        \n",
    "        #output, hidden = self.gru(embed,hidden)\n",
    "        \n",
    "        #hidden is a tuple (h,c). Dim of h: num_layers * num_directions, batch, hidden_size\n",
    "        output, (h,c) = self.rnn(embed,hidden)\n",
    "        \n",
    "        h = torch.sum(h, dim=0).unsqueeze(0)\n",
    "        c = torch.sum(c, dim=0).unsqueeze(0)\n",
    "        \n",
    "        hidden = (h,c)\n",
    "        \n",
    "        \n",
    "        output = (output[:, :, :self.hidden_size] +\n",
    "                output[:, :, self.hidden_size:])\n",
    "        \n",
    "        ## potentially there are other ways \n",
    "        \n",
    "        \n",
    "        #hidden = [n layers * n directions =1 , batch_size, hidden_size ]\n",
    "        #print (\"encoder hidden\",hidden)\n",
    "        #print (\"encoder output\", output.shape)\n",
    "\n",
    "        return output, hidden\n",
    "\n",
    "    # initialize the hidden with random numbers\n",
    "    def initHidden(self,batch_size):\n",
    "        return (torch.randn(2*self.num_layers, batch_size, self.hidden_size,device=device),\n",
    "                torch.randn(2*self.num_layers, batch_size, self.hidden_size,device=device))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self,emb_dim,hidden_size, output_size, embed= torch.from_numpy(loaded_embeddings_ft_en).float(),num_layers=1,\n",
    "                 dropout_p=0.1, max_length=max_sentence_length_zh):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers \n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding.from_pretrained(embed, freeze=False)\n",
    "        self.attn = nn.Linear(self.hidden_size + emb_dim, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size + emb_dim, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "\n",
    "        #self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.rnn = nn.LSTM(hidden_size, hidden_size, bidirectional = False)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, data, hidden,encoder_outputs):\n",
    "        \n",
    "        ### embed: [1 * batch size * emb_dim = 300 ] ###\n",
    "        ### hidden: [1 * batch size * hidden_size = 300 ] ###\n",
    "        ### FOR LSTM, HIDDEN: tuple (h,c). h:(2, batch size, hidden_size)\n",
    "        ### encoder_outputs: [batch size * max_sentence_length_zh * hidden_size = 300 ] ###\n",
    "        ### 因为这里concat之后，attn layer 他给的是 hidden size *2 \n",
    "        ### 所以我这儿的hidden size就只能写300了 \n",
    "        \n",
    "        embed = self.embedding(data)\n",
    "        embed = self.dropout(embed)    \n",
    "        ### torch.cat((embed, hidden), 2)  \n",
    "        ### [1 * batch size * (emb_dim + hidden_size) ]\n",
    "        \n",
    "        ### attn_weights: [1 * batch size * max_sentence_length_zh ]###\n",
    "        ### attn_weights[0].unsqueeze(1): [batch size * 1 * max_sentence_length_zh ]###\n",
    "        \n",
    "        ### softmax dim=2 因为最后一个dimension是 词组什么的，不能是1，1的话就是\n",
    "        ### 不同batch间这样比较了？\n",
    "        \n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embed, hidden[0]), 2)), dim=2)\n",
    "        \n",
    "\n",
    "        ### torch.bmm(attn_weights[0].unsqueeze(1),encoder_outputs).squeeze(1) :\n",
    "        ### [batch size * 1 * hidden_size ]###\n",
    "\n",
    "        ### attn_applied: [batch size * hidden_size (= 300) ] ###\n",
    "     \n",
    "        attn_applied = torch.bmm(attn_weights[0].unsqueeze(1),\n",
    "                                 encoder_outputs).squeeze(1)\n",
    "        \n",
    "        ### output: [batch size * hidden_size (= 300) ] ###\n",
    "        ### embed[0]: [batch size * hidden_size (= 300) ] ###\n",
    "\n",
    "        output = torch.cat((embed[0], attn_applied), 1)\n",
    " \n",
    "        ### output: [1 * batch size * hidden_size (= 300) ] ###\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "        \n",
    "        ### output: [1 * batch size * hidden_size (= 300) ] ###\n",
    "        output = F.relu(output)\n",
    "        \n",
    "        \n",
    "        \n",
    "        #output, hidden = self.gru(output, hidden)\n",
    "        output, hidden = self.rnn(output, hidden)\n",
    "        \n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        \n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self,batch_size):\n",
    "        return torch.randn(self.num_layers, batch_size, self.hidden_size,device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 1\n",
    "#input_tensor: list of sentence tensor\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer,\n",
    "          criterion, eee):\n",
    "    \n",
    "    ### target_tensor [batch size, max_sentence_length_en = 377] ###\n",
    "    ### target_tensor [batch size, max_sentence_length_zh = 220] ###\n",
    "    batch_size_1, input_length = input_tensor.size()\n",
    "    batch_size_2, target_length = target_tensor.size()\n",
    "    \n",
    "    \n",
    "    encoder_hidden = encoder.initHidden(batch_size_1)\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    loss = 0\n",
    "    ### encoder_hidden: 1 * batch * hidden size ### \n",
    "    ### encoder_output: batch size * max_sentence_length_zh * hidden size ### \n",
    "    encoder_output, encoder_hidden = encoder(input_tensor, encoder_hidden)\n",
    "\n",
    "    decoder_input = torch.tensor(np.array([[SOS_IDX]]*batch_size_1).reshape(1,batch_size_1),device=device)\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "    #print(use_teacher_forcing)\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            \n",
    "            ### decoder_output: [batchsize,5000] ###\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden,encoder_output)\n",
    "            \n",
    "            #print (\"decoder output, \",decoder_output)\n",
    "            #print (\"target_tensor, \",target_tensor[:,di])\n",
    "            loss += criterion(decoder_output, target_tensor[:,di])\n",
    "            decoder_input = target_tensor[:,di].unsqueeze(0)  # Teacher forcing\n",
    "            \n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden,encoder_output)\n",
    "                        \n",
    "            ### decoder_output [batch size, 50003]  ###\n",
    "            \n",
    "            ### topi is a [batch size, 1] tensor first we remove the size 1\n",
    "            ### demension then we add it at the beginning using squeeze\n",
    "            ### 有点脑残诶，做个转置不就好了？\n",
    "            \n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "            \n",
    "            ### decoder_input [1, batch size]  ###\n",
    "            decoder_input = decoder_input.unsqueeze(0)\n",
    " \n",
    "            loss += criterion(decoder_output, target_tensor[:,di])\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, n_iters, folder,print_every=1, plot_every=100, evaluate_every = 50,read_in_model = False,learning_rate=0.001,early_stop_tol = 10e-7):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    plot_val = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "    patience = 0\n",
    "    \n",
    "    early_stopped = False\n",
    "    current_best_bleu = 0\n",
    "    \n",
    "    best_encoder = encoder.state_dict()\n",
    "    best_decoder = decoder.state_dict()\n",
    "    \n",
    "    \n",
    "    #--------------------------------------------\t\n",
    "    #\t\n",
    "    #    LOAD MODELS\t\n",
    "    #\t\n",
    "    #--------------------------------------------\t\n",
    "    \t\n",
    "        \n",
    "    \n",
    "    if not os.path.exists(folder):\t\n",
    "        os.makedirs(folder)\t\n",
    "\n",
    "    if read_in_model == True:\n",
    "        if os.path.exists(folder+'/Encoder'):\t\n",
    "            print('---------------------------------------------------------------------')\t\n",
    "            print('----------------Readind trained model---------------------------------')\t\n",
    "            print('---------------------------------------------------------------------')\t\n",
    "\n",
    "            #read trained models\t\n",
    "            encoder.load_state_dict(torch.load(folder+\"/Encoder\"))\n",
    "            decoder.load_state_dict(torch.load(folder+\"/Decoder\"))\t\n",
    "\n",
    "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    #criterion_val = nn.CrossEntropyLoss()\n",
    "    \n",
    "    last_val = 0\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        \n",
    "        for i, (data_s1, data_s2, lengths_s1, lengths_s2) in enumerate(train_loader):\n",
    "            input_tensor = data_s1\n",
    "            target_tensor = data_s2\n",
    "            #print(\"train\",target_tensor.size())\n",
    "            loss = train(input_tensor, target_tensor, encoder,\n",
    "                         decoder, encoder_optimizer, decoder_optimizer, criterion,i)\n",
    "            print_loss_total += loss\n",
    "            plot_loss_total += loss\n",
    "\n",
    "            if i % print_every == 0:\n",
    "                if i != 0:\n",
    "                    print_loss_avg = print_loss_total / print_every\n",
    "                    print_loss_total = 0\n",
    "                    print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                                 iter, iter / n_iters * 100, print_loss_avg))\n",
    "                \n",
    "            if i % plot_every == 0:\n",
    "                if i != 0:\n",
    "                    plot_loss_avg = plot_loss_total / plot_every\n",
    "                    plot_losses.append(plot_loss_avg)\n",
    "                    plot_loss_total = 0\n",
    "                \n",
    "            if i % evaluate_every == 0:\n",
    "                if i != 0:\n",
    "                    bleu_score,output_words,attentions = evaluate(val_loader, encoder, decoder)\n",
    "                    if bleu_score > current_best_bleu:\n",
    "                        current_best_bleu = bleu_score\n",
    "                        \n",
    "                        best_encoder = encoder.state_dict()\n",
    "                        best_decoder = decoder.state_dict()\n",
    "                        \n",
    "                    plot_val.append(bleu_score)\n",
    "                    #print (\"BLEU: \",bleu_score)\n",
    "                    \n",
    "                    if bleu_score <= current_best_bleu:\n",
    "                        patience += 1\n",
    "                        \n",
    "                    elif bleu_score > current_best_bleu and np.abs(bleu_score - current_best_bleu)/float(current_best_bleu) < early_stop_tol:\n",
    "                        patience += 1\n",
    "                    \n",
    "                    else:\n",
    "                        patience = 0\n",
    "                        \n",
    "                        \n",
    "                    \n",
    "                    \n",
    "                    \"\"\"\n",
    "                    #If new bleu score is lower than last time\n",
    "                    if bleu_score <= last_val:\n",
    "                        patience += 1\n",
    "                    #or does not improve by enough percentage\n",
    "                    elif bleu_score > last_val and np.abs(bleu_score - last_val)/float(last_val) < early_stop_tol:\n",
    "                        \n",
    "                        patience += 1\n",
    "                    #bleu score increased since last time\n",
    "                    else:\n",
    "                        #reset patience\n",
    "                        patience = 0\n",
    "                            \n",
    "                    \"\"\"    \n",
    "                    if patience == 10:\n",
    "                       \n",
    "                        torch.save(best_encoder,folder +\"/Encoder\")\n",
    "                        torch.save(best_decoder,folder +\"/Decoder\")\n",
    "                        early_stopped = True\n",
    "                        patience = 0\n",
    "            \n",
    "                        \n",
    "                    last_val = bleu_score\n",
    "                 \n",
    "        if early_stopped == False:\n",
    "        \n",
    "            # Save the model for every epoch\n",
    "            print('---------------------------------------------------------------------')\t\n",
    "            print('----------------Saving trained model---------------------------------')\t\n",
    "            print('---------------------------------------------------------------------')\t\n",
    "\n",
    "            torch.save(encoder.state_dict(),folder +\"/Encoder\")\n",
    "            torch.save(decoder.state_dict(),folder +\"/Decoder\")\n",
    "\n",
    "    showPlot(plot_losses)\n",
    "    showPlot(plot_val)\n",
    "    return plot_losses\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)\n",
    "    \n",
    "import time\n",
    "import math\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "#loader can be test_loader or val_loader\n",
    "def evaluate(loader, encoder, decoder):\n",
    "    bleu_score_list = []\n",
    "    predictions = ''\n",
    "    references = ''\n",
    "    with torch.no_grad():\n",
    "        for i, (data_s1, data_s2, lengths_s1, lengths_s2) in enumerate(loader):\n",
    "            \n",
    "            input_tensor = data_s1\n",
    "            input_length = input_tensor.size()[0]\n",
    "            #sentence_length to the output length\n",
    "            sentence_length = data_s2.size()[1]\n",
    "            encoder_hidden = encoder.initHidden(input_length)\n",
    "\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor, encoder_hidden)\n",
    "            \n",
    "            #decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "            decoder_input = torch.tensor(np.array([[SOS_IDX]]*input_length).reshape(1,input_length),device=device)\n",
    "\n",
    "            decoder_hidden = encoder_hidden\n",
    "\n",
    "            decoder_attentions = torch.zeros(sentence_length, sentence_length)\n",
    "            decoded_words_eval = []\n",
    "            # EOS_IDX tensor matrix\n",
    "            test_matrix = torch.ones(input_length, beam_k)*EOS_IDX\n",
    "            out_sequences = []\n",
    "            for di in range(sentence_length):\n",
    "                decoded_words_sub = []\n",
    "                \n",
    "                decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                    decoder_input, decoder_hidden, encoder_output)\n",
    "                # topk(1) - softmax probability maximum\n",
    "                topv, topi = decoder_output.data.topk(1) \n",
    "                #print(topi)\n",
    "                #batch loop\n",
    "                \n",
    "                for ind in topi:\n",
    "                    if ind.item() == EOS_IDX:\n",
    "                        decoded_words_sub.append('</s>')\n",
    "                        break\n",
    "                    else:\n",
    "                        decoded_words_sub.append(idx2words_ft_en[ind.item()])\n",
    "                        \n",
    "                decoded_words_eval.append(decoded_words_sub)\n",
    "\n",
    "                #change the dimension\n",
    "                decoder_input = topi.squeeze().detach()\n",
    "                decoder_input = decoder_input.unsqueeze(0)\n",
    "\n",
    "            pred_num = 0\n",
    "            listed_predictions = []\n",
    "            #swap dimensions of decoded_words to [batch_size * 377]\n",
    "            decoded_words_new = [[i for i in ele] for ele in list(zip(*decoded_words_eval))]\n",
    "           # print(decoded_words_new)\n",
    "            for token_list in decoded_words_new:\n",
    "                sent = ' '.join(token for token in token_list if token!=\"<pad>\")\n",
    "                #print(len(token_list))\n",
    "                #print (sent)\n",
    "                listed_predictions.append(sent)\n",
    "                pred_num += 1\n",
    "                \n",
    "            ref_num = 0\n",
    "            listed_reference = []\n",
    "            for ele in data_s2:\n",
    "                sent = index2token_sentence(ele)\n",
    "                #print (tokens)\n",
    "                #sent = ' '.join(tokens)\n",
    "                #print (sent)\n",
    "                listed_reference.append(sent)\n",
    "                ref_num += 1\n",
    "            #print(listed_reference)\n",
    "            predictions+= ''.join(listed_predictions)\n",
    "            references += ''.join(listed_reference)\n",
    "            #bleu_score = corpus_bleu(listed_predictions,[listed_reference])\n",
    "            #print('BLEU Score is %s' % (str(bleu_score.score)))\n",
    "        #bleu_score_list.append(bleu_score)\n",
    "        bleu_score = corpus_bleu(predictions,references)\n",
    "        print('BLEU Score is %s' % (str(bleu_score.score)))\n",
    "        return bleu_score, decoded_words_new, decoder_attentions[:di + 1]\n",
    "def index2token_batch(list_of_list):\n",
    "    return ' '.join(idx2words_ft_en[r.item()] for v in list_of_list for r in v if r.item()!=PAD_IDX)\n",
    "def index2token_sentence(sentence_batch):\n",
    "    return ' '.join(idx2words_ft_en[sent.item()] for sent in sentence_batch if sent.item()!=PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 46s (- 0m 0s) (1 100%) 3.7410\n",
      "1m 32s (- 0m 0s) (1 100%) 1.9894\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'beam_k' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-bb243b36be61>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m##UNCOMMENT TO TRAIN THE MODEL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtrainIters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'./attention_model_bilstm'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mplot_every\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_every\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-19-2a13c377a871>\u001b[0m in \u001b[0;36mtrainIters\u001b[0;34m(encoder, decoder, n_iters, folder, print_every, plot_every, evaluate_every, read_in_model, learning_rate, early_stop_tol)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mevaluate_every\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m                     \u001b[0mbleu_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput_words\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mattentions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mbleu_score\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mcurrent_best_bleu\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m                         \u001b[0mcurrent_best_bleu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbleu_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-21-bad522e7471b>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(loader, encoder, decoder)\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mdecoded_words_eval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;31m# EOS_IDX tensor matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0mtest_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeam_k\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mEOS_IDX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m             \u001b[0mout_sequences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'beam_k' is not defined"
     ]
    }
   ],
   "source": [
    "hidden_size = 300\n",
    "encoder1 = EncoderRNN(EMBEDDING_SIZE,hidden_size).to(device)\n",
    "decoder1 = AttnDecoderRNN(EMBEDDING_SIZE,hidden_size, len(ordered_words_ft_en)).to(device)\n",
    "\n",
    "##UNCOMMENT TO TRAIN THE MODEL\n",
    "trainIters(encoder1, decoder1, 1,'./attention_model_bilstm', print_every=50,plot_every = 100, evaluate_every = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# beam search + bleu score\n",
    "def beam_search_decoder(data, k):\n",
    "    sequences = [[list(), 1.0]]\n",
    "    # walk over each step in sequence\n",
    "    for row in data:\n",
    "        all_candidates = list()\n",
    "        # expand each current candidate\n",
    "        for i in range(len(sequences)):\n",
    "            seq, score = sequences[i]\n",
    "            for j in range(len(row)):\n",
    "                candidate = [seq + [j], score * -log(row[j])]\n",
    "                all_candidates.append(candidate)\n",
    "        # order all candidates by score\n",
    "        ordered = sorted(all_candidates, key=lambda tup:tup[1])\n",
    "        # select top best\n",
    "        sequences = ordered[:1]\n",
    "    return sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class decoder_output_node:\n",
    "    def __init__(self,parent, word_idx, prob_sum, isroot=False):\n",
    "        self.parent = parent\n",
    "        self.isroot = isroot\n",
    "        self.children = []\n",
    "        self.word_idx = word_idx\n",
    "        self.prob_sum = prob_sum\n",
    "    \n",
    "    def get_children(self):\n",
    "        '''\n",
    "        return children\n",
    "        '''\n",
    "        return self.children\n",
    "    \n",
    "    def add_children(self, child):\n",
    "        '''\n",
    "        child: node\n",
    "        '''\n",
    "        self.children.append(child)\n",
    "        return\n",
    "    \n",
    "    def get_parent(self):\n",
    "        '''\n",
    "        get parent of children\n",
    "        '''\n",
    "        return self.parent\n",
    "    \n",
    "    def get_word_idx(self):\n",
    "        \n",
    "        return self.word_idx\n",
    "    \n",
    "    def get_prob_sum(self):\n",
    "        \n",
    "        return self.prob_sum\n",
    "    \n",
    "    def is_root(self):\n",
    "        return self.isroot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_sentence_sequence(child_node):\n",
    "    if child_node.is_root():\n",
    "        return [child_node.get_word_idx()]\n",
    "    \n",
    "    return return_sentence_sequence(child_node.get_parent())+[child_node.get_word_idx()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beam_search(beam_k, decoder_output, prob_sum = None, parent_node_list=None, vocab_size = len(idx2words_ft_en)):\n",
    "    '''\n",
    "    params:\n",
    "    beam_k\n",
    "    decoder_output: previous round decoder output\n",
    "    parent_node_list: previous candidate word list (for only one candidate)\n",
    "    \n",
    "    return:\n",
    "    list_of_best_k_nodes: best k nodes found in this iteration, list of list, first dim batch, second dim best k\n",
    "    prob_with_sum: probabilistic matrix after sum+sortee \n",
    "    '''\n",
    "    # if first word\n",
    "    if parent_node_list is None:\n",
    "        # initialize result\n",
    "        prob_with_sum_sorted, word_idx_sorted = decoder_output.data.topk(beam_k)\n",
    "        #print(\"ps\",prob_with_sum_sorted)\n",
    "        # add initialize tree list\n",
    "        list_of_best_k_nodes = []\n",
    "        batchsize = prob_with_sum_sorted.shape[0]\n",
    "        for batch_i in range(batchsize):\n",
    "            batch_i_tree_list = []\n",
    "            for beam_i in range(beam_k):\n",
    "                # add tree root node to list\n",
    "                batch_i_tree_list.append(decoder_output_node(parent=None, word_idx=word_idx_sorted[batch_i, beam_i].item(), \n",
    "                                                            prob_sum= prob_with_sum_sorted[batch_i, beam_i].item(), isroot=True))\n",
    "                \n",
    "            list_of_best_k_nodes.append(batch_i_tree_list)\n",
    "   \n",
    "    # if not first word\n",
    "    else:\n",
    "        # get sorted results for all outputs\n",
    "        prob = decoder_output.data\n",
    "        #print(decoder_output.data.shape)\n",
    "        #print(word_idx)\n",
    "        \n",
    "        \n",
    "        # find top beam k words options\n",
    "        #print(\"sum:\",prob_sum)\n",
    "        #print(\"curr prob:\",prob)\n",
    "        #print(\"sum:\",prob+prob_sum)\n",
    "        prob_with_sum = prob+prob_sum\n",
    "        prob_with_sum_sorted, word_idx_sorted = torch.sort(prob_with_sum, dim=1, descending=True)\n",
    "        #print(\"sum sorted:\", prob_with_sum_sorted)\n",
    "        # add top beam k words options into tree\n",
    "        batchsize = prob_with_sum_sorted.shape[0]\n",
    "        \n",
    "        list_of_best_k_nodes = []\n",
    "        for batch_i in range(batchsize):\n",
    "            batch_i_tree_list = []\n",
    "            for beam_i in range(beam_k):\n",
    "                #print(word_idx_sorted[batch_i, beam_i])\n",
    "                #print(parent_node_list[batch_i].get_word_idx())\n",
    "                child_node = decoder_output_node(parent=parent_node_list[batch_i], word_idx= word_idx_sorted[batch_i,beam_i].item(), prob_sum=prob_with_sum_sorted[batch_i,beam_i].item())\n",
    "                \n",
    "                # update parent node's child\n",
    "                parent_node_list[batch_i].add_children(child_node)\n",
    "                #save child to new list\n",
    "                batch_i_tree_list.append(child_node)\n",
    "            # add batch tree list to best k\n",
    "            list_of_best_k_nodes.append(batch_i_tree_list)\n",
    "                \n",
    "    return list_of_best_k_nodes, prob_with_sum_sorted[:,:beam_k], word_idx_sorted[:,:beam_k]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_with_beam_search(val_loader,encoder1,decoder1,beam_k):\n",
    "    \n",
    "    beam_k = 5\n",
    "    with torch.no_grad():\n",
    "        predictions = ''\n",
    "        references = ''\n",
    "        for i, (data_s1, data_s2, lengths_s1, lengths_s2) in enumerate(val_loader):\n",
    "            #print(i)\n",
    "            input_tensor = data_s1\n",
    "            input_length = input_tensor.size()[0]\n",
    "            #sentence_length to the output length\n",
    "            sentence_length = data_s2.size()[1]\n",
    "            encoder_hidden = encoder1.initHidden(input_length)\n",
    "\n",
    "            encoder_output, encoder_hidden = encoder1(input_tensor, encoder_hidden)\n",
    "\n",
    "            #decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "            decoder_input = torch.tensor(np.array([[SOS_IDX]]*input_length).reshape(1,input_length),device=device)\n",
    "\n",
    "            decoder_hidden = encoder_hidden\n",
    "\n",
    "            decoder_attentions = torch.zeros(sentence_length, sentence_length)\n",
    "            decoded_words_eval = []\n",
    "            list_of_best_k_nodes = []\n",
    "\n",
    "            prob_with_sum_sorted = []\n",
    "            #print(\"outside\",prob_with_sum_sorted)\n",
    "\n",
    "            decoder_hidden_list = []\n",
    "            for di in range(sentence_length):\n",
    "\n",
    "                ############################################beam search###################################################\n",
    "                #print(di)\n",
    "                if di == 0:\n",
    "                    decoded_words_sub = []\n",
    "\n",
    "\n",
    "                    decoder_output, decoder_hidden, decoder_attention = decoder1(\n",
    "                                    decoder_input, decoder_hidden, encoder_output)\n",
    "\n",
    "                    # find top k candidates\n",
    "                    list_of_best_k_nodes,prob_with_sum_sorted ,word_idx_sorted = beam_search(beam_k, decoder_output, parent_node_list=None)\n",
    "                    decoder_hidden_list = [decoder_hidden]*beam_k\n",
    "\n",
    "                    #print(\"sum1\",prob_with_sum_sorted)\n",
    "                    #print(\"idx\",word_idx_sorted)\n",
    "                    #print(list_of_best_k_nodes[0][0].get_word_idx())\n",
    "                    #print(list_of_best_k_nodes[0][1].get_word_idx())\n",
    "\n",
    "                else:\n",
    "                    # keep track of all new nodes\n",
    "                    new_nodes = []\n",
    "                    nodes_prob = None\n",
    "                    #nodes_word_idx = None\n",
    "\n",
    "                    # store index in previous candidate to locate position in new nodes, repeats=beam_size*beam_size\n",
    "                    prev_candidate_idx = np.repeat(range(beam_k), repeats=beam_k)\n",
    "\n",
    "                    # iterate through each node candidate from last iterations to find new candidates\n",
    "                    new_decoder_hidden_list = []\n",
    "\n",
    "                    for beam_i in range(beam_k):\n",
    "                        #print(word_idx_sorted.shape)\n",
    "                        topi = word_idx_sorted[:,beam_i].data\n",
    "                        #print(\"idx i\",topi)\n",
    "\n",
    "                        prob_sum = prob_with_sum_sorted[:,beam_i].view((input_length,1))\n",
    "                        #print(\"prob sum:\", prob_sum)\n",
    "                        #change the dimension\n",
    "                        decoder_input = topi.squeeze().detach()\n",
    "                        decoder_input = decoder_input.unsqueeze(0)\n",
    "\n",
    "                        # get decoder output\n",
    "                        decoder_output, decoder_hidden_i, decoder_attention = decoder1(\n",
    "                                    decoder_input, decoder_hidden_list[beam_i], encoder_output)\n",
    "\n",
    "                        new_decoder_hidden_list.append(decoder_hidden_i)\n",
    "\n",
    "                        # get beam search output\n",
    "                        best_k_curr_node, prob_sum_curr_node, _ = beam_search(beam_k, decoder_output, prob_sum=prob_sum, parent_node_list=[ls[beam_i] for ls in list_of_best_k_nodes])\n",
    "                        #print(word_idx_curr_node)\n",
    "\n",
    "                        # keep track of beam search output\n",
    "                        new_nodes.append(best_k_curr_node)\n",
    "\n",
    "                        if beam_i == 0:\n",
    "                            nodes_prob = prob_sum_curr_node.data\n",
    "\n",
    "                            #nodes_word_idx = word_idx_curr_node\n",
    "                        else:\n",
    "                            nodes_prob = torch.cat((nodes_prob, prob_sum_curr_node.data),dim=1)\n",
    "                            #nodes_word_idx = torch.cat((nodes_word_idx, word_idx_curr_node),dim=1)\n",
    "\n",
    "                    #print(\"nodes prob\", nodes_prob)\n",
    "                    _, sorted_idx = torch.sort(nodes_prob, dim=1, descending=True)\n",
    "                    #print(\"length\",nodes_prob.shape)\n",
    "                    #print(nodes_prob)\n",
    "                    #print(sorted_idx)\n",
    "\n",
    "                    #print(prev_candidate_idx)\n",
    "                    #print(\"new nodes len:\", len(new_nodes[0][0]))\n",
    "                    #print(\"new_nodes 0\",new_nodes[0])\n",
    "                    #print(\"new_nodes 1\",new_nodes[1])\n",
    "                    # update \n",
    "                    #print(sorted_idx.shape)\n",
    "                    for batch_i in range(input_length):\n",
    "                        for beam_i in range(beam_k):\n",
    "                            # find the index of which candidate it descended from\n",
    "                            st_idx = sorted_idx[batch_i][beam_i].item()\n",
    "                            # find the corresponding node, st_idx gives parent node id, batch_i gives which example, st_idx%beam_k gives which node in the existing node list\n",
    "                            #if batch_i == 0:\n",
    "                            #print(\"st_idx\",st_idx)\n",
    "                            update_node = new_nodes[prev_candidate_idx[st_idx]][batch_i][st_idx%beam_k]\n",
    "\n",
    "                            list_of_best_k_nodes[batch_i][beam_i] = update_node\n",
    "                            #print(batch_i)\n",
    "                            #print(beam_i)\n",
    "                            #print(list_of_best_k_nodes[0][0].parent.get_word_idx())\n",
    "\n",
    "                            # update word idex, prob sum correspondingly for next iteration\n",
    "                            #word_idx_sorted[batch_i][beam_i] = nodes_word_idx[batch_i][st_idx] \n",
    "                            word_idx_sorted[batch_i][beam_i] = update_node.get_word_idx()\n",
    "                            prob_with_sum_sorted[batch_i][beam_i] = update_node.get_prob_sum()\n",
    "\n",
    "\n",
    "                            decoder_hidden_list[beam_i][0,batch_i,:] = new_decoder_hidden_list[prev_candidate_idx[st_idx]][0,batch_i,:]\n",
    "\n",
    "                    #print(\"best k\",list_of_best_k_nodes[0])\n",
    "                    #print(\"final\", prob_with_sum_sorted)\n",
    "                    #print(\"idx final\", word_idx_sorted)\n",
    "\n",
    "            # find the best and get index\n",
    "            listed_predictions = []\n",
    "            for batch_i in range(input_length):\n",
    "                best_sequence_last_node = list_of_best_k_nodes[batch_i][0]\n",
    "                batch_i_word_idx = return_sentence_sequence(best_sequence_last_node)\n",
    "\n",
    "                listed_predictions.append(' '.join(idx2words_ft_en[token_idx] for token_idx in batch_i_word_idx if token_idx!=PAD_IDX))\n",
    "                #print(' '.join(idx2words_ft_en[token_idx] for token_idx in batch_i_word_idx ))\n",
    "                #print(batch_i_word_idx)\n",
    "            listed_reference = []\n",
    "            for ele in data_s2:\n",
    "                sent = index2token_sentence(ele)\n",
    "\n",
    "                listed_reference.append(sent)\n",
    "\n",
    "            #print(listed_predictions)\n",
    "            #bleu_score = corpus_bleu(listed_predictions,[listed_reference])\n",
    "            #print('BLEU Score is %s' % (str(bleu_score.score)))\n",
    "\n",
    "            predictions+= ''.join(listed_predictions)\n",
    "            references += ''.join(listed_reference)\n",
    "    bleu_score = corpus_bleu(predictions,references)\n",
    "    print('BLEU Score is %s' % (str(bleu_score.score)))\n",
    "            ############################################beam search###################################################\n",
    "    return bleu_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'encoder1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-7a2b97a7b952>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscore_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattentions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_with_beam_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeam_k\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'encoder1' is not defined"
     ]
    }
   ],
   "source": [
    "score_list, output_words, attentions = evaluate_with_beam_search(val_loader, encoder1, decoder1, beam_k = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 46s (- 0m 0s) (1 100%) 3.7975\n",
      "Avg BLEU is:  0.6975785329578511\n",
      "1m 41s (- 0m 0s) (1 100%) 2.0326\n",
      "Avg BLEU is:  8.917369824347876\n",
      "2m 35s (- 0m 0s) (1 100%) 1.8935\n",
      "Avg BLEU is:  5.885121761471209\n",
      "3m 30s (- 0m 0s) (1 100%) 1.8582\n",
      "Avg BLEU is:  9.655997002533569\n",
      "4m 26s (- 0m 0s) (1 100%) 1.8445\n",
      "Avg BLEU is:  9.286253428485088\n",
      "5m 21s (- 0m 0s) (1 100%) 1.7844\n",
      "Avg BLEU is:  8.737495492763994\n",
      "6m 16s (- 0m 0s) (1 100%) 1.7879\n",
      "Avg BLEU is:  10.086246632807185\n",
      "7m 10s (- 0m 0s) (1 100%) 1.7728\n",
      "Avg BLEU is:  10.605542863057291\n",
      "8m 4s (- 0m 0s) (1 100%) 1.7176\n",
      "Avg BLEU is:  10.841422001703762\n",
      "8m 59s (- 0m 0s) (1 100%) 1.7410\n",
      "Avg BLEU is:  7.885705444672648\n",
      "---------------------------------------------------------------------\n",
      "----------------Saving ealy stopped model----------------------------\n",
      "---------------------------------------------------------------------\n",
      "9m 54s (- 0m 0s) (1 100%) 1.7157\n",
      "Avg BLEU is:  6.731576111534779\n",
      "10m 48s (- 0m 0s) (1 100%) 1.7109\n",
      "Avg BLEU is:  8.815850547111527\n",
      "11m 43s (- 0m 0s) (1 100%) 1.7197\n",
      "Avg BLEU is:  8.390650132957962\n",
      "12m 37s (- 0m 0s) (1 100%) 1.6740\n",
      "Avg BLEU is:  10.757291833107255\n",
      "13m 31s (- 0m 0s) (1 100%) 1.6953\n",
      "Avg BLEU is:  11.179615786729112\n",
      "14m 26s (- 0m 0s) (1 100%) 1.6643\n",
      "Avg BLEU is:  11.039060021495702\n",
      "15m 20s (- 0m 0s) (1 100%) 1.6281\n",
      "Avg BLEU is:  11.463399326929103\n",
      "16m 14s (- 0m 0s) (1 100%) 1.6025\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for EncoderRNN:\n\tMissing key(s) in state_dict: \"rnn.weight_ih_l0\", \"rnn.weight_hh_l0\", \"rnn.bias_ih_l0\", \"rnn.bias_hh_l0\", \"rnn.weight_ih_l0_reverse\", \"rnn.weight_hh_l0_reverse\", \"rnn.bias_ih_l0_reverse\", \"rnn.bias_hh_l0_reverse\". \n\tUnexpected key(s) in state_dict: \"gru.weight_ih_l0\", \"gru.weight_hh_l0\", \"gru.bias_ih_l0\", \"gru.bias_hh_l0\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-816b47833e5c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mdecoder2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAttnDecoderRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEMBEDDING_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mordered_words_ft\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mencoder2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"encoder.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mdecoder2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"decoder.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/nlp/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m    717\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m--> 719\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m    720\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for EncoderRNN:\n\tMissing key(s) in state_dict: \"rnn.weight_ih_l0\", \"rnn.weight_hh_l0\", \"rnn.bias_ih_l0\", \"rnn.bias_hh_l0\", \"rnn.weight_ih_l0_reverse\", \"rnn.weight_hh_l0_reverse\", \"rnn.bias_ih_l0_reverse\", \"rnn.bias_hh_l0_reverse\". \n\tUnexpected key(s) in state_dict: \"gru.weight_ih_l0\", \"gru.weight_hh_l0\", \"gru.bias_ih_l0\", \"gru.bias_hh_l0\". "
     ]
    }
   ],
   "source": [
    "### Load the best models\n",
    "hidden_size=300\n",
    "\n",
    "\n",
    "folder = './attentation_model'\t\n",
    "\n",
    "encoder2 = EncoderRNN(EMBEDDING_SIZE,hidden_size).to(device)\n",
    "decoder2 = AttnDecoderRNN(EMBEDDING_SIZE,hidden_size, len(ordered_words_ft)).to(device)\n",
    "\n",
    "#encoder2.load_state_dict(torch.load(\"encoder.pt\"))\n",
    "#decoder2.load_state_dict(torch.load(\"decoder.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2038973810226181\n",
      "Avg BLEU is:  0.8098061679109313\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "blue, output_words, attentions = evaluate(val_loader,\n",
    "    encoder1, decoder1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
