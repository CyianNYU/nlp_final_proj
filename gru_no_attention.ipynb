{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note:\n",
    "\n",
    "Add code to save graphs in showPlot function\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re  \n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import collections\n",
    "from itertools import dropwhile\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"./\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install sacrebleu\n",
    "from sacrebleu import corpus_bleu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in chinese-english pairs\n",
    "#read in chinese-english pairs\n",
    "lines_zh = open(PATH+'iwslt-zh-en/train.tok.zh',encoding = 'utf-8').read().strip().split('\\n')\n",
    "lines_en = open(PATH+'iwslt-zh-en/train.tok.en',encoding = 'utf-8').read().strip().split('\\n')\n",
    "lines_zh_test = open(PATH+'iwslt-zh-en/test.tok.zh',encoding = 'utf-8').read().strip().split('\\n')\n",
    "lines_en_test = open(PATH+'iwslt-zh-en/test.tok.en',encoding = 'utf-8').read().strip().split('\\n')\n",
    "lines_zh_val = open(PATH+'iwslt-zh-en/dev.tok.zh',encoding = 'utf-8').read().strip().split('\\n')\n",
    "lines_en_val = open(PATH+'iwslt-zh-en/dev.tok.en',encoding = 'utf-8').read().strip().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delect_least_common_words(list_sent, threshold = 5):\n",
    "    ret_list =[]\n",
    "    for x in list_sent:\n",
    "        ret_list += x.split()\n",
    "    ret_dic = collections.Counter(ret_list)\n",
    "    \n",
    "    #print (ret_dic[\"&amp;\"])\n",
    "    #print (ret_dic[\"&apos;\"])\n",
    "    #print (ret_dic[\"&quot;\"])\n",
    "    #print (ret_dic[\"&#91\"])\n",
    "    for key, count in dropwhile(lambda key_count: key_count[1] >= threshold, ret_dic.most_common()):\n",
    "        \n",
    "        del ret_dic[key]\n",
    "        \n",
    "        \n",
    "    return list(ret_dic.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "zh_words = delect_least_common_words(lines_zh)\n",
    "en_words = delect_least_common_words(lines_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34443"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(zh_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_to_load = 100000\n",
    "PAD_IDX = 0\n",
    "UNK_IDX = 1\n",
    "SOS_IDX = 2\n",
    "EOS_IDX = 3\n",
    "\n",
    "with open('../cc.zh.300.vec') as f:\n",
    "    loaded_embeddings_ft = np.zeros((words_to_load+3, 300))\n",
    "    words_ft = {}\n",
    "    idx2words_ft = {}\n",
    "    ordered_words_ft = []\n",
    "    ordered_words_ft.extend(['<pad>', '<unk>', '<s>'])\n",
    "    loaded_embeddings_ft[0,:] = np.zeros(300)\n",
    "    loaded_embeddings_ft[1,:] = np.random.normal(size = 300)\n",
    "    loaded_embeddings_ft[2,:] = np.random.normal(size = 300)\n",
    "    for i, line in enumerate(f):\n",
    "        if i >= words_to_load: \n",
    "            break\n",
    "        s = line.split()\n",
    "        loaded_embeddings_ft[i+3, :] = np.asarray(s[1:])\n",
    "        words_ft[s[0]] = i+3\n",
    "        idx2words_ft[i+3] = s[0]\n",
    "        ordered_words_ft.append(s[0])\n",
    "    length = len(np.setdiff1d(zh_words, ordered_words_ft))\n",
    "    tmp_embeddings = np.zeros((length, 300))\n",
    "    for idx, word in enumerate(np.setdiff1d(zh_words, ordered_words_ft)):\n",
    "        words_ft[word] = idx+words_to_load+3\n",
    "        idx2words_ft[idx+words_to_load+3] = word\n",
    "        tmp_embeddings[idx, :] = np.random.normal(size = 300)\n",
    "    loaded_embeddings_ft = np.concatenate((loaded_embeddings_ft, tmp_embeddings), axis = 0)\n",
    "    words_ft['<pad>'] = PAD_IDX\n",
    "    words_ft['<unk>'] = UNK_IDX\n",
    "    words_ft['<s>'] = SOS_IDX\n",
    "    idx2words_ft[PAD_IDX] = '<pad>'\n",
    "    idx2words_ft[UNK_IDX] = '<unk>'\n",
    "    idx2words_ft[SOS_IDX] = '<s>'\n",
    "    \n",
    "ordered_words_ft = list(words_ft.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#English embedding\n",
    "with open(PATH+'wiki-news-300d-1M.vec') as f:\n",
    "    loaded_embeddings_ft_en = np.zeros((words_to_load+4, 300))\n",
    "    words_ft_en = {}\n",
    "    idx2words_ft_en = {}\n",
    "    ordered_words_ft_en = []\n",
    "    ordered_words_ft_en.extend(['<pad>', '<unk>', '<s>', '</s>'])\n",
    "    loaded_embeddings_ft_en[0,:] = np.zeros(300)\n",
    "    loaded_embeddings_ft_en[1,:] = np.random.normal(size = 300)\n",
    "    loaded_embeddings_ft_en[2,:] = np.random.normal(size = 300)\n",
    "    loaded_embeddings_ft_en[3,:] = np.random.normal(size = 300)\n",
    "    for i, line in enumerate(f):\n",
    "        if i >= words_to_load: \n",
    "            break\n",
    "        s = line.split()\n",
    "        loaded_embeddings_ft_en[i+4, :] = np.asarray(s[1:])\n",
    "        words_ft_en[s[0]] = i+4\n",
    "        idx2words_ft_en[i+4] = s[0]\n",
    "        ordered_words_ft_en.append(s[0])\n",
    "    length = len(np.setdiff1d(en_words, ordered_words_ft_en))\n",
    "    tmp_embeddings = np.zeros((length, 300))\n",
    "    for idx, word in enumerate(np.setdiff1d(en_words, ordered_words_ft_en)):\n",
    "        words_ft_en[word] = idx+words_to_load+4\n",
    "        idx2words_ft_en[idx+words_to_load+4] = word\n",
    "        tmp_embeddings[idx, :] = np.random.normal(size = 300)\n",
    "    loaded_embeddings_ft_en = np.concatenate((loaded_embeddings_ft_en, tmp_embeddings), axis = 0)\n",
    "    words_ft_en['<pad>'] = PAD_IDX\n",
    "    words_ft_en['<unk>'] = UNK_IDX\n",
    "    words_ft_en['<s>'] = SOS_IDX\n",
    "    words_ft_en['</s>'] = EOS_IDX\n",
    "    idx2words_ft_en[PAD_IDX] = '<pad>'\n",
    "    idx2words_ft_en[UNK_IDX] = '<unk>'\n",
    "    idx2words_ft_en[SOS_IDX] = '<s>'\n",
    "    idx2words_ft_en[EOS_IDX] = '</s>'\n",
    "    \n",
    "ordered_words_ft_en = list(words_ft_en.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(idx2words_ft) == len(words_ft)\n",
    "assert len(loaded_embeddings_ft) == len(words_ft)\n",
    "assert len(idx2words_ft_en) == len(words_ft_en)\n",
    "assert len(loaded_embeddings_ft_en) == len(words_ft_en)\n",
    "assert len(ordered_words_ft_en) == len(loaded_embeddings_ft_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add sos and eos in each sentence\n",
    "def add_sos_eos(lines):\n",
    "    \n",
    "    train = []\n",
    "    for l in lines:\n",
    "        l = '<s> ' + l + ' </s>'\n",
    "        train.append(l)\n",
    "    return train\n",
    "zh_train = add_sos_eos(lines_zh)    \n",
    "en_train = add_sos_eos(lines_en)\n",
    "zh_test = add_sos_eos(lines_zh_test)\n",
    "en_test = add_sos_eos(lines_en_test)\n",
    "zh_val = add_sos_eos(lines_zh_val)\n",
    "en_val = add_sos_eos(lines_en_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s> And the problem , I think , is that we take the ocean for granted . </s>'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_train[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert token to id in the dataset\n",
    "def token2index_dataset(tokens_data,eng = False):\n",
    "    indices_data = []\n",
    "    for tokens in tokens_data:\n",
    "        index_list = []\n",
    "        for token in tokens.split():\n",
    "            if eng == False:\n",
    "                try:\n",
    "                    index_list.append(words_ft[token])\n",
    "                except KeyError:\n",
    "                    index_list.append(UNK_IDX)\n",
    "            else:\n",
    "                try:\n",
    "                    index_list.append(words_ft_en[token])\n",
    "                except KeyError:\n",
    "                    index_list.append(UNK_IDX)\n",
    "        indices_data.append(index_list)\n",
    "    return indices_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "zh_train_indices = token2index_dataset(zh_train)\n",
    "en_train_indices = token2index_dataset(en_train,eng = True)\n",
    "zh_val_indices = token2index_dataset(zh_val)\n",
    "en_val_indices = token2index_dataset(en_val,eng = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#max_sentence_length\n",
    "length_of_en = [len(x.split()) for x in en_train]\n",
    "max_sentence_length_en = sorted(length_of_en)[-int(len(length_of_en)*0.01)]\n",
    "length_of_zh = [len(x.split()) for x in zh_train]\n",
    "max_sentence_length_zh = sorted(length_of_zh)[-int(len(length_of_zh)*0.01)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_sentence_length_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Data Loader\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class load_dataset(Dataset):\n",
    "    \"\"\"\n",
    "    Class that represents a train/validation/test dataset that's readable for PyTorch\n",
    "    Note that this class inherits torch.utils.data.Dataset\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data_list_s1,data_list_s2):\n",
    "        \"\"\"\n",
    "        @param data_list_zh: list of Chinese tokens \n",
    "        @param data_list_en: list of English tokens as TARGETS\n",
    "        \"\"\"\n",
    "        self.data_list_s1 = data_list_s1\n",
    "        self.data_list_s2 = data_list_s2\n",
    "        \n",
    "        assert (len(self.data_list_s1) == len(self.data_list_s2))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_list_s1)\n",
    "        \n",
    "    def __getitem__(self, key):\n",
    "        \"\"\"\n",
    "        Triggered when you call dataset[i]\n",
    "        \"\"\"\n",
    "        \n",
    "        token_idx_s1 = self.data_list_s1[key][:max_sentence_length_zh]\n",
    "        token_idx_s2 = self.data_list_s2[key][:max_sentence_length_en]\n",
    "        return [token_idx_s1, token_idx_s2, len(token_idx_s1), len(token_idx_s2)]\n",
    "\n",
    "def collate_func(batch):\n",
    "    \"\"\"\n",
    "    Customized function for DataLoader that dynamically pads the batch so that all \n",
    "    data have the same length\n",
    "    \"\"\"\n",
    "    data_list_s1 = []\n",
    "    data_list_s2 = []\n",
    "    length_list_s1 = []\n",
    "    length_list_s2 = []\n",
    "    for datum in batch:\n",
    "        length_list_s1.append(datum[2])\n",
    "        length_list_s2.append(datum[3])\n",
    "        padded_vec_zh = np.pad(np.array(datum[0]), \n",
    "                                pad_width=((0,max_sentence_length_zh-datum[2])), \n",
    "                                mode=\"constant\", constant_values=0)\n",
    "        padded_vec_en = np.pad(np.array(datum[1]), \n",
    "                                pad_width=((0,max_sentence_length_en-datum[3])), \n",
    "                                mode=\"constant\", constant_values=0)\n",
    "        data_list_s1.append(padded_vec_zh[:max_sentence_length_zh])\n",
    "        data_list_s2.append(padded_vec_en[:max_sentence_length_en])\n",
    "    #print(type(data_list_s1[0]))\n",
    "    \n",
    "    return [torch.from_numpy(np.array(data_list_s1)).to(device), torch.from_numpy(np.array(data_list_s2)).to(device),\n",
    "            torch.LongTensor(length_list_s1).to(device), torch.LongTensor(length_list_s2).to(device)]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 100\n",
    "EMBEDDING_SIZE = 300 # fixed as from the input embedding data\n",
    "\n",
    "train_dataset = load_dataset(zh_train_indices, en_train_indices)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=collate_func,\n",
    "                                           shuffle=True)\n",
    "\n",
    "val_dataset = load_dataset(zh_val_indices, en_val_indices)\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_dataset,\n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=collate_func,\n",
    "                                           shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, emb_dim, hidden_size, embed= torch.from_numpy(loaded_embeddings_ft).float(),num_layers=1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.emb_dim = emb_dim\n",
    "        self.num_layers = num_layers \n",
    "\n",
    "        self.embedding = nn.Embedding.from_pretrained(embed, freeze=False)\n",
    "        self.gru = nn.GRU(emb_dim, hidden_size,num_layers=num_layers,batch_first=True)\n",
    "\n",
    "    def forward(self, data, hidden):\n",
    "        \n",
    "        batch_size, seq_len = data.size()\n",
    "        \n",
    "        embed = self.embedding(data)\n",
    "        \n",
    "        output, hidden = self.gru(embed,hidden)\n",
    "        #hidden = [n layers * n directions =1 , batch_size, hidden_size ]\n",
    "        \n",
    "        return output, hidden\n",
    "\n",
    "    # initialize the hidden with random numbers\n",
    "    def initHidden(self,batch_size):\n",
    "        return torch.randn(self.num_layers, batch_size, self.hidden_size,device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self,emb_dim,hidden_size, output_size, embed= torch.from_numpy(loaded_embeddings_ft_en).float(),num_layers=1):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers \n",
    "        self.output_size = output_size\n",
    "\n",
    "        #self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.embedding = nn.Embedding.from_pretrained(embed, freeze=False)\n",
    "        self.gru = nn.GRU(emb_dim, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, data, hidden):\n",
    "        embed = self.embedding(data)\n",
    "\n",
    "        #print(\"decoder\",embed.size())\n",
    "        \n",
    "        output = F.relu(embed)\n",
    "        #print(\"decoder\",output.size())\n",
    "        \n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        \n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self,batch_size):\n",
    "        return torch.randn(self.num_layers, batch_size, self.hidden_size,device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 1\n",
    "#input_tensor: list of sentence tensor\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer,\n",
    "          criterion, eee):\n",
    "    \n",
    "    ### target_tensor [batch size, max_sentence_length_en = 377] ###\n",
    "    ### target_tensor [batch size, max_sentence_length_zh = 220] ###\n",
    "    batch_size_1, input_length = input_tensor.size()\n",
    "    batch_size_2, target_length = target_tensor.size()\n",
    "    #print (\"target length \", target_length)\n",
    "    \n",
    "    \n",
    "    encoder_hidden = encoder.initHidden(batch_size_1)\n",
    "    #print (\"encoder hidden init, \",h.shape)\n",
    "    \n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    loss = 0\n",
    "    ### encoder_hidden: 1 * batch * hidden size ### \n",
    "    ### encoder_output: batch size * max_sentence_length_zh * hidden size ### \n",
    "    _, encoder_hidden = encoder(input_tensor, encoder_hidden)\n",
    "    #print (\"encoder output, \", encoder_output.shape)\n",
    "\n",
    "    decoder_input = torch.tensor(np.array([[SOS_IDX]]*batch_size_1).reshape(1,batch_size_1),device=device)\n",
    "    decoder_hidden = encoder_hidden\n",
    "    #h1,c1 = encoder_hidden\n",
    "    #print (\"encoder hidden,\", h1.shape)\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "    #print(use_teacher_forcing)\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            \n",
    "            ### decoder_output: [batchsize,5000] ###\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden)\n",
    "            \n",
    "            #print (\"decoder output, \",decoder_output.shape)\n",
    "            #print (\"target_tensor, \",len(target_tensor[:,di]))\n",
    "            loss += criterion(decoder_output, target_tensor[:,di])\n",
    "            decoder_input = target_tensor[:,di].unsqueeze(0)  # Teacher forcing\n",
    "            \n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden)\n",
    "                        \n",
    "            ### decoder_output [batch size, 50003]  ###\n",
    "            \n",
    "            ### topi is a [batch size, 1] tensor first we remove the size 1\n",
    "            ### demension then we add it at the beginning using squeeze\n",
    "            \n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "            \n",
    "            ### decoder_input [1, batch size]  ###\n",
    "            decoder_input = decoder_input.unsqueeze(0)\n",
    " \n",
    "            loss += criterion(decoder_output, target_tensor[:,di])\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import StepLR, LambdaLR\n",
    "import pickle\n",
    "def trainIters(encoder, decoder, n_iters, folder,lr_decrease = False,print_every=1, plot_every=100, evaluate_every = 50,read_in_model = False,learning_rate=0.001,early_stop_tol = 10e-7):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    plot_val = []\n",
    "    \n",
    "    loss_history = []\n",
    "   \n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "    patience = 0\n",
    "    \n",
    "    early_stopped = False\n",
    "    current_best_bleu = 0\n",
    "    \n",
    "    best_encoder = encoder.state_dict()\n",
    "    best_decoder = decoder.state_dict()\n",
    "    \n",
    "    \n",
    "    #--------------------------------------------\t\n",
    "    #\t\n",
    "    #    LOAD MODELS\t\n",
    "    #\t\n",
    "    #--------------------------------------------\t\n",
    "    \t\n",
    "        \n",
    "    \n",
    "    if not os.path.exists(folder):\t\n",
    "        os.makedirs(folder)\t\n",
    "\n",
    "    if read_in_model == True:\n",
    "        if os.path.exists(folder+'/Encoder'):\t\n",
    "            print('---------------------------------------------------------------------')\t\n",
    "            print('----------------Readind trained model---------------------------------')\t\n",
    "            print('---------------------------------------------------------------------')\t\n",
    "\n",
    "            #read trained models\t\n",
    "            encoder.load_state_dict(torch.load(folder+\"/Encoder\"))\n",
    "            decoder.load_state_dict(torch.load(folder+\"/Decoder\"))\t\n",
    "\n",
    "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "    \n",
    "    if lr_decrease == True:\n",
    "        encoder_scheduler = StepLR(encoder_optimizer, step_size=3, gamma=0.8)\n",
    "        decoder_scheduler = StepLR(decoder_optimizer, step_size=3, gamma=0.8)\n",
    "    \n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    #criterion_val = nn.CrossEntropyLoss()\n",
    "    \n",
    "    last_val = 0\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        if lr_decrease == True:\n",
    "            encoder_scheduler.step()\n",
    "            decoder_scheduler.step()\n",
    "        for i, (data_s1, data_s2, lengths_s1, lengths_s2) in enumerate(train_loader):\n",
    "            input_tensor = data_s1\n",
    "            target_tensor = data_s2\n",
    "            #print(\"train\",target_tensor.size())\n",
    "            loss = train(input_tensor, target_tensor, encoder,\n",
    "                         decoder, encoder_optimizer, decoder_optimizer, criterion,i)\n",
    "            print_loss_total += loss\n",
    "            plot_loss_total += loss\n",
    "\n",
    "            if i % print_every == 0:\n",
    "                if i != 0:\n",
    "                    print_loss_avg = print_loss_total / print_every\n",
    "                    print_loss_total = 0\n",
    "                    print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                                 iter, iter / n_iters * 100, print_loss_avg))\n",
    "                    loss_history.append(print_loss_avg)\n",
    "                else:\n",
    "                    print_loss_total = 0\n",
    "                \n",
    "            if i % plot_every == 0:\n",
    "                if i != 0:\n",
    "                    plot_loss_avg = plot_loss_total / plot_every\n",
    "                    plot_losses.append(plot_loss_avg)\n",
    "                    plot_loss_total = 0\n",
    "                    \n",
    "                    \n",
    "                else:\n",
    "                    plot_loss_total = 0\n",
    "                \n",
    "            if i % evaluate_every == 0:\n",
    "                if i != 0:\n",
    "                    bleu_score,output_words = evaluate(val_loader, encoder, decoder)\n",
    "                    if bleu_score > current_best_bleu:\n",
    "                        current_best_bleu = bleu_score\n",
    "                        \n",
    "                        best_encoder = encoder.state_dict()\n",
    "                        best_decoder = decoder.state_dict()\n",
    "                        \n",
    "                    plot_val.append(bleu_score)\n",
    "                    #print (\"BLEU: \",bleu_score)\n",
    "                    \n",
    "                    if bleu_score <= current_best_bleu:\n",
    "                        patience += 1\n",
    "                        \n",
    "                    elif bleu_score > current_best_bleu and np.abs(bleu_score - current_best_bleu)/float(current_best_bleu) < early_stop_tol:\n",
    "                        patience += 1\n",
    "                    \n",
    "                    else:\n",
    "                        patience = 0\n",
    "                        \n",
    "                        \n",
    "                    \n",
    "                    \n",
    "                    \"\"\"\n",
    "                    #If new bleu score is lower than last time\n",
    "                    if bleu_score <= last_val:\n",
    "                        patience += 1\n",
    "                    #or does not improve by enough percentage\n",
    "                    elif bleu_score > last_val and np.abs(bleu_score - last_val)/float(last_val) < early_stop_tol:\n",
    "                        \n",
    "                        patience += 1\n",
    "                    #bleu score increased since last time\n",
    "                    else:\n",
    "                        #reset patience\n",
    "                        patience = 0\n",
    "                            \n",
    "                    \"\"\"    \n",
    "                    if patience == 10:\n",
    "                       \n",
    "                        torch.save(best_encoder,folder +\"/Encoder\")\n",
    "                        torch.save(best_decoder,folder +\"/Decoder\")\n",
    "                        early_stopped = True\n",
    "                        patience = 0\n",
    "            \n",
    "                        \n",
    "                    last_val = bleu_score\n",
    "                 \n",
    "        if early_stopped == False:\n",
    "        \n",
    "            # Save the model for every epoch\n",
    "            print('---------------------------------------------------------------------')\t\n",
    "            print('----------------Saving trained model---------------------------------')\t\n",
    "            print('---------------------------------------------------------------------')\t\n",
    "\n",
    "            torch.save(encoder.state_dict(),folder +\"/Encoder\")\n",
    "            torch.save(decoder.state_dict(),folder +\"/Decoder\")\n",
    "            \n",
    "    with open(folder+\"/loss_hist\", 'wb') as f:\n",
    "         pickle.dump(loss_history, f)\n",
    "    with open(folder+\"/bleu_hist\", 'wb') as f:\n",
    "         pickle.dump(plot_val, f)\n",
    "    showPlot(plot_losses,title = \"Train Loss\",name = folder+\"/loss.jpeg\")\n",
    "    showPlot(plot_val, title = \"BLEU Score on Validation Set\",name = folder+\"/bleu.jpeg\")\n",
    "    return plot_losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "def showPlot(points,title,name):\n",
    "    plt.figure()\n",
    "    \n",
    "    plt.plot(points)\n",
    "    plt.title(title)\n",
    "    plt.savefig(name)\n",
    "    \n",
    "import time\n",
    "import math\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loader can be test_loader or val_loader\n",
    "def evaluate(loader, encoder, decoder, after_train_mode = False,beam = False, beam_k = 1):\n",
    "    bleu_score_list = []\n",
    "    big_pred_list = []\n",
    "    big_ref_list = []\n",
    "    with torch.no_grad():\n",
    "        for i, (data_s1, data_s2, lengths_s1, lengths_s2) in enumerate(loader):\n",
    "            input_tensor = data_s1\n",
    "            input_length = input_tensor.size()[0]\n",
    "            #sentence_length to the output length\n",
    "            sentence_length = data_s2.size()[1]\n",
    "            encoder_hidden = encoder.initHidden(input_length)\n",
    "\n",
    "            _, encoder_hidden = encoder(input_tensor, encoder_hidden)\n",
    "            \n",
    "            #decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "            decoder_input = torch.tensor(np.array([[SOS_IDX]]*input_length).reshape(1,input_length),device=device)\n",
    "\n",
    "            decoder_hidden = encoder_hidden\n",
    "\n",
    "            #decoder_attentions = torch.zeros(sentence_length, sentence_length)\n",
    "            decoded_words_eval = []\n",
    "            sequences = [[list(), 1.0]]*input_length\n",
    "            for di in range(sentence_length):\n",
    "                decoded_words_sub = []\n",
    "                decoder_output, decoder_hidden = decoder(\n",
    "                    decoder_input, decoder_hidden)\n",
    "                # decoder_attentions[di] = decoder_attention.data\n",
    "                # topk(1) - softmax probability maximum\n",
    "                if beam == True:\n",
    "                    pass\n",
    "#                     topv, topi = decoder_output.data.topk(beam_k)\n",
    "#                     #batch loop\n",
    "#                     C = []\n",
    "#                     for idx, ind in enumerate(topi):\n",
    "#                         H, _ = sequences[idx]\n",
    "#                         for ele in ind:\n",
    "#                             if ele.item() == EOS_IDX:\n",
    "#                                 H.append('<EOS>')\n",
    "#                             else:\n",
    "#                                 H.append(idx2words_ft_en[ele.item()])\n",
    "                         \n",
    "                else:\n",
    "                    topv, topi = decoder_output.data.topk(1) \n",
    "                    \n",
    "                #batch loop\n",
    "                \n",
    "                \n",
    "                for ind in topi:\n",
    "                    \n",
    "                    if ind.item() == EOS_IDX:\n",
    "                        \n",
    "                        decoded_words_sub.append(idx2words_ft_en[EOS_IDX])\n",
    "                        \n",
    "                    else:\n",
    "                        decoded_words_sub.append(idx2words_ft_en[ind.item()])\n",
    "                    \n",
    "                \n",
    "                decoded_words_eval.append(decoded_words_sub)\n",
    "                \n",
    "                #swap dimensions of decoded_words to [batch_size * 377]\n",
    "                \n",
    "                #decoded_words_new = [[i for i in ele] for ele in list(zip(*decoded_words_eval))]\n",
    "\n",
    "                #change the dimension\n",
    "                decoder_input = topi.squeeze().detach()\n",
    "                decoder_input = decoder_input.unsqueeze(0)\n",
    "            \n",
    "            \n",
    "            pred_num = 0\n",
    "            listed_predictions = []\n",
    "            \n",
    "            \n",
    "            decoded_words_new = [[i for i in ele] for ele in list(zip(*decoded_words_eval))]\n",
    "            \n",
    "            for token_list in decoded_words_new:\n",
    "                sent = ' '.join(str(token) for token in token_list if token!=\"<pad>\" and token!=\"<s>\" and token!=\"</s>\")\n",
    "                #print (sent)\n",
    "                listed_predictions.append(sent)\n",
    "                #print (sent)\n",
    "                pred_num += 1\n",
    "                \n",
    "            ref_num = 0\n",
    "            listed_reference = []\n",
    "            for ele in data_s2:\n",
    "                sent = index2token_sentence(ele)\n",
    "                #print (tokens)\n",
    "                #sent = ' '.join(tokens)\n",
    "                #print (sent)\n",
    "                listed_reference.append(sent)\n",
    "                ref_num += 1\n",
    "            \n",
    "            big_pred_list += listed_predictions\n",
    "            big_ref_list += listed_reference\n",
    "            \n",
    "            assert len(big_pred_list) == len(big_ref_list)\n",
    "            \n",
    "            \n",
    "            #uncommon to print prediction and reference\n",
    "            #print (listed_predictions)\n",
    "            #print (listed_reference)\n",
    "        bleu_score = corpus_bleu(big_pred_list,[big_ref_list]).score\n",
    "        \n",
    "        if after_train_mode == True:\n",
    "            for idx,ele in enumerate(big_pred_list):\n",
    "                print (ele)\n",
    "                print (big_ref_list[idx])\n",
    "                print (\"\\n\")\n",
    "                \n",
    "                \n",
    "    print('BLEU Score is %s' % (str(bleu_score)))\n",
    "        \n",
    "\n",
    "    return bleu_score, decoded_words_new\n",
    "    \n",
    "def index2token_batch(list_of_list):\n",
    "    return ' '.join(idx2words_ft_en[r.item()] for v in list_of_list for r in v if r.item()!=PAD_IDX)\n",
    "def index2token_sentence(sentence_batch):\n",
    "    return ' '.join(idx2words_ft_en[sent.item()] for sent in sentence_batch if sent.item()!=PAD_IDX and sent.item()!=SOS_IDX and sent.item()!=EOS_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'encoder1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-14766dec781a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscore_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattentions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mafter_train_mode\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'encoder1' is not defined"
     ]
    }
   ],
   "source": [
    "score_list, output_words, attentions = evaluate(val_loader, encoder1, decoder1,after_train_mode =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 41s (- 13m 11s) (1 5%) 2.3992\n",
      "1m 22s (- 26m 5s) (1 5%) 1.7279\n",
      "2m 3s (- 39m 0s) (1 5%) 1.6682\n",
      "2m 43s (- 51m 55s) (1 5%) 1.6775\n",
      "3m 24s (- 64m 50s) (1 5%) 1.6379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:That's 100 lines that end in a tokenized period ('.')\n",
      "WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score is 0.8386282924722102\n",
      "4m 14s (- 80m 42s) (1 5%) 1.6074\n",
      "4m 55s (- 93m 37s) (1 5%) 1.5858\n",
      "5m 36s (- 106m 32s) (1 5%) 1.5758\n",
      "6m 17s (- 119m 27s) (1 5%) 1.5280\n",
      "6m 58s (- 132m 22s) (1 5%) 1.5175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:That's 100 lines that end in a tokenized period ('.')\n",
      "WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score is 0.9180780323941934\n",
      "7m 48s (- 148m 18s) (1 5%) 1.5127\n",
      "8m 29s (- 161m 13s) (1 5%) 1.5197\n",
      "9m 9s (- 174m 8s) (1 5%) 1.5500\n",
      "9m 50s (- 187m 3s) (1 5%) 1.4814\n",
      "10m 31s (- 199m 58s) (1 5%) 1.4584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:That's 100 lines that end in a tokenized period ('.')\n",
      "WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score is 2.2424401687117235\n",
      "11m 21s (- 215m 49s) (1 5%) 1.4592\n",
      "12m 2s (- 228m 45s) (1 5%) 1.4479\n",
      "12m 43s (- 241m 40s) (1 5%) 1.4281\n",
      "13m 23s (- 254m 35s) (1 5%) 1.4177\n",
      "14m 4s (- 267m 30s) (1 5%) 1.3911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:That's 100 lines that end in a tokenized period ('.')\n",
      "WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score is 2.9742970762127943\n",
      "14m 54s (- 283m 22s) (1 5%) 1.3904\n",
      "15m 35s (- 296m 17s) (1 5%) 1.3642\n",
      "16m 16s (- 309m 12s) (1 5%) 1.3644\n",
      "16m 57s (- 322m 7s) (1 5%) 1.3554\n",
      "17m 38s (- 335m 2s) (1 5%) 1.3603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:That's 100 lines that end in a tokenized period ('.')\n",
      "WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score is 2.6076231061204624\n",
      "18m 28s (- 350m 53s) (1 5%) 1.3708\n",
      "19m 8s (- 363m 48s) (1 5%) 1.3424\n",
      "19m 49s (- 376m 43s) (1 5%) 1.3090\n",
      "20m 30s (- 389m 38s) (1 5%) 1.3217\n",
      "21m 11s (- 402m 33s) (1 5%) 1.3205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:That's 100 lines that end in a tokenized period ('.')\n",
      "WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score is 3.2472183904051173\n",
      "22m 1s (- 418m 24s) (1 5%) 1.3137\n",
      "22m 42s (- 431m 19s) (1 5%) 1.3219\n",
      "23m 22s (- 444m 14s) (1 5%) 1.3459\n",
      "24m 3s (- 457m 9s) (1 5%) 1.3153\n",
      "24m 44s (- 470m 4s) (1 5%) 1.3197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:That's 100 lines that end in a tokenized period ('.')\n",
      "WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score is 2.383652660707996\n",
      "25m 34s (- 485m 56s) (1 5%) 1.3090\n",
      "26m 15s (- 498m 51s) (1 5%) 1.3131\n",
      "26m 56s (- 511m 46s) (1 5%) 1.3050\n",
      "27m 36s (- 524m 41s) (1 5%) 1.2930\n",
      "28m 17s (- 537m 36s) (1 5%) 1.3004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:That's 100 lines that end in a tokenized period ('.')\n",
      "WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score is 1.7858422065188535\n",
      "29m 7s (- 553m 28s) (1 5%) 1.3012\n",
      "29m 48s (- 566m 23s) (1 5%) 1.2980\n",
      "---------------------------------------------------------------------\n",
      "----------------Saving trained model---------------------------------\n",
      "---------------------------------------------------------------------\n",
      "30m 57s (- 278m 38s) (2 10%) 1.2439\n",
      "31m 38s (- 284m 46s) (2 10%) 1.2584\n",
      "32m 19s (- 290m 53s) (2 10%) 1.2334\n",
      "33m 0s (- 297m 0s) (2 10%) 1.2299\n",
      "33m 40s (- 303m 7s) (2 10%) 1.2401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:That's 100 lines that end in a tokenized period ('.')\n",
      "WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score is 3.155850855445472\n",
      "34m 30s (- 310m 38s) (2 10%) 1.2133\n",
      "35m 11s (- 316m 45s) (2 10%) 1.2598\n",
      "35m 52s (- 322m 52s) (2 10%) 1.2486\n",
      "36m 33s (- 328m 59s) (2 10%) 1.2279\n",
      "37m 14s (- 335m 6s) (2 10%) 1.2340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:That's 100 lines that end in a tokenized period ('.')\n",
      "WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score is 2.3309117531521006\n",
      "38m 4s (- 342m 44s) (2 10%) 1.2497\n",
      "38m 45s (- 348m 51s) (2 10%) 1.2500\n",
      "39m 26s (- 354m 58s) (2 10%) 1.2411\n",
      "40m 7s (- 361m 4s) (2 10%) 1.2044\n",
      "40m 47s (- 367m 11s) (2 10%) 1.2494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:That's 100 lines that end in a tokenized period ('.')\n",
      "WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score is 2.9107943848545155\n",
      "41m 37s (- 374m 41s) (2 10%) 1.2588\n",
      "42m 18s (- 380m 48s) (2 10%) 1.2413\n",
      "42m 59s (- 386m 55s) (2 10%) 1.2584\n",
      "43m 40s (- 393m 2s) (2 10%) 1.2558\n",
      "44m 21s (- 399m 9s) (2 10%) 1.2440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:That's 100 lines that end in a tokenized period ('.')\n",
      "WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score is 3.416279043646922\n",
      "45m 11s (- 406m 39s) (2 10%) 1.2420\n",
      "45m 51s (- 412m 46s) (2 10%) 1.2292\n",
      "46m 32s (- 418m 53s) (2 10%) 1.2152\n",
      "47m 13s (- 425m 0s) (2 10%) 1.2280\n",
      "47m 54s (- 431m 7s) (2 10%) 1.2483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:That's 100 lines that end in a tokenized period ('.')\n",
      "WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score is 3.1435516664597447\n",
      "48m 44s (- 438m 37s) (2 10%) 1.2608\n",
      "49m 24s (- 444m 44s) (2 10%) 1.2217\n",
      "50m 5s (- 450m 51s) (2 10%) 1.2273\n",
      "50m 46s (- 456m 58s) (2 10%) 1.2380\n",
      "51m 27s (- 463m 5s) (2 10%) 1.2493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:That's 100 lines that end in a tokenized period ('.')\n",
      "WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score is 2.998027916621079\n",
      "52m 17s (- 470m 36s) (2 10%) 1.2255\n",
      "52m 58s (- 476m 43s) (2 10%) 1.2265\n",
      "53m 38s (- 482m 50s) (2 10%) 1.2437\n",
      "54m 19s (- 488m 57s) (2 10%) 1.2305\n",
      "55m 0s (- 495m 4s) (2 10%) 1.2517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:That's 100 lines that end in a tokenized period ('.')\n",
      "WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score is 3.180163371510281\n",
      "55m 50s (- 502m 30s) (2 10%) 1.2345\n",
      "56m 30s (- 508m 36s) (2 10%) 1.2487\n",
      "57m 11s (- 514m 42s) (2 10%) 1.2292\n",
      "57m 52s (- 520m 49s) (2 10%) 1.2190\n",
      "58m 32s (- 526m 55s) (2 10%) 1.2466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:That's 100 lines that end in a tokenized period ('.')\n",
      "WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score is 3.75924812161804\n",
      "59m 22s (- 534m 21s) (2 10%) 1.2486\n",
      "60m 3s (- 540m 27s) (2 10%) 1.2496\n",
      "61m 11s (- 346m 44s) (3 15%) 1.1489\n",
      "61m 52s (- 350m 35s) (3 15%) 1.1498\n",
      "62m 32s (- 354m 25s) (3 15%) 1.1604\n",
      "63m 13s (- 358m 16s) (3 15%) 1.1567\n",
      "63m 54s (- 362m 6s) (3 15%) 1.1557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:That's 100 lines that end in a tokenized period ('.')\n",
      "WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score is 3.2865937039025876\n",
      "64m 43s (- 366m 48s) (3 15%) 1.1546\n",
      "65m 24s (- 370m 38s) (3 15%) 1.1787\n",
      "66m 5s (- 374m 29s) (3 15%) 1.1821\n",
      "66m 45s (- 378m 20s) (3 15%) 1.1666\n",
      "67m 26s (- 382m 10s) (3 15%) 1.1668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:That's 100 lines that end in a tokenized period ('.')\n",
      "WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score is 2.8618604806668415\n",
      "68m 16s (- 386m 52s) (3 15%) 1.1751\n",
      "68m 56s (- 390m 42s) (3 15%) 1.1751\n",
      "69m 37s (- 394m 33s) (3 15%) 1.1682\n",
      "70m 18s (- 398m 24s) (3 15%) 1.1789\n",
      "70m 59s (- 402m 14s) (3 15%) 1.1930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:That's 100 lines that end in a tokenized period ('.')\n",
      "WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score is 2.933153069508772\n",
      "71m 48s (- 406m 55s) (3 15%) 1.1770\n",
      "72m 29s (- 410m 46s) (3 15%) 1.1905\n",
      "73m 10s (- 414m 36s) (3 15%) 1.1847\n",
      "73m 50s (- 418m 27s) (3 15%) 1.2032\n",
      "74m 31s (- 422m 18s) (3 15%) 1.1663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:That's 100 lines that end in a tokenized period ('.')\n",
      "WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score is 4.218618931225955\n",
      "75m 21s (- 427m 3s) (3 15%) 1.1938\n",
      "76m 2s (- 430m 54s) (3 15%) 1.1726\n",
      "76m 43s (- 434m 45s) (3 15%) 1.2057\n",
      "77m 23s (- 438m 35s) (3 15%) 1.1847\n",
      "78m 4s (- 442m 26s) (3 15%) 1.1804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:That's 100 lines that end in a tokenized period ('.')\n",
      "WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score is 3.7544183866610346\n",
      "78m 54s (- 447m 7s) (3 15%) 1.1868\n",
      "79m 34s (- 450m 57s) (3 15%) 1.1928\n",
      "80m 15s (- 454m 48s) (3 15%) 1.1841\n",
      "80m 56s (- 458m 38s) (3 15%) 1.1809\n",
      "81m 36s (- 462m 29s) (3 15%) 1.1647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:That's 100 lines that end in a tokenized period ('.')\n",
      "WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score is 3.0256819771283645\n",
      "82m 26s (- 467m 10s) (3 15%) 1.1804\n",
      "83m 7s (- 471m 1s) (3 15%) 1.1937\n",
      "83m 47s (- 474m 51s) (3 15%) 1.1913\n",
      "84m 28s (- 478m 42s) (3 15%) 1.1970\n",
      "85m 9s (- 482m 33s) (3 15%) 1.2005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:That's 100 lines that end in a tokenized period ('.')\n",
      "WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score is 3.755313932514754\n",
      "85m 58s (- 487m 13s) (3 15%) 1.2068\n",
      "86m 39s (- 491m 4s) (3 15%) 1.1898\n",
      "87m 20s (- 494m 55s) (3 15%) 1.1954\n",
      "88m 0s (- 498m 45s) (3 15%) 1.1937\n",
      "88m 41s (- 502m 36s) (3 15%) 1.1836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:That's 100 lines that end in a tokenized period ('.')\n",
      "WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score is 2.1378402259826914\n",
      "89m 31s (- 507m 17s) (3 15%) 1.1767\n",
      "90m 12s (- 511m 8s) (3 15%) 1.1876\n",
      "91m 20s (- 365m 21s) (4 20%) 1.1143\n",
      "92m 1s (- 368m 4s) (4 20%) 1.0975\n",
      "92m 41s (- 370m 46s) (4 20%) 1.1060\n",
      "93m 22s (- 373m 29s) (4 20%) 1.1058\n",
      "94m 3s (- 376m 12s) (4 20%) 1.0969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:That's 100 lines that end in a tokenized period ('.')\n",
      "WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score is 3.860655343288881\n",
      "94m 52s (- 379m 30s) (4 20%) 1.1056\n",
      "95m 33s (- 382m 13s) (4 20%) 1.1150\n",
      "96m 13s (- 384m 55s) (4 20%) 1.0999\n",
      "96m 54s (- 387m 38s) (4 20%) 1.1107\n",
      "97m 35s (- 390m 21s) (4 20%) 1.1199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:That's 100 lines that end in a tokenized period ('.')\n",
      "WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score is 3.1487395750472778\n",
      "98m 24s (- 393m 39s) (4 20%) 1.1173\n",
      "99m 5s (- 396m 22s) (4 20%) 1.1052\n",
      "99m 46s (- 399m 5s) (4 20%) 1.1113\n",
      "100m 26s (- 401m 47s) (4 20%) 1.1278\n",
      "101m 7s (- 404m 30s) (4 20%) 1.1357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:That's 100 lines that end in a tokenized period ('.')\n",
      "WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score is 3.2210957053533185\n",
      "101m 57s (- 407m 49s) (4 20%) 1.1029\n",
      "102m 37s (- 410m 31s) (4 20%) 1.1048\n",
      "103m 18s (- 413m 14s) (4 20%) 1.1157\n",
      "103m 59s (- 415m 57s) (4 20%) 1.1217\n",
      "104m 40s (- 418m 40s) (4 20%) 1.1334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:That's 100 lines that end in a tokenized period ('.')\n",
      "WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score is 3.7371739239253494\n",
      "105m 29s (- 421m 58s) (4 20%) 1.1200\n",
      "106m 10s (- 424m 41s) (4 20%) 1.1275\n",
      "106m 51s (- 427m 24s) (4 20%) 1.1269\n",
      "107m 31s (- 430m 6s) (4 20%) 1.1319\n",
      "108m 12s (- 432m 49s) (4 20%) 1.1470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:That's 100 lines that end in a tokenized period ('.')\n",
      "WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score is 3.2810927815835966\n",
      "109m 1s (- 436m 7s) (4 20%) 1.1252\n",
      "109m 42s (- 438m 50s) (4 20%) 1.1108\n",
      "110m 23s (- 441m 33s) (4 20%) 1.1327\n",
      "111m 4s (- 444m 16s) (4 20%) 1.1524\n",
      "111m 44s (- 446m 59s) (4 20%) 1.1537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:That's 100 lines that end in a tokenized period ('.')\n",
      "WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score is 4.13847506997027\n",
      "112m 34s (- 450m 19s) (4 20%) 1.1416\n",
      "113m 15s (- 453m 2s) (4 20%) 1.1296\n",
      "113m 56s (- 455m 45s) (4 20%) 1.1439\n",
      "114m 37s (- 458m 28s) (4 20%) 1.1419\n",
      "115m 17s (- 461m 11s) (4 20%) 1.1288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:That's 100 lines that end in a tokenized period ('.')\n",
      "WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score is 3.1731638392738586\n",
      "116m 7s (- 464m 29s) (4 20%) 1.1378\n",
      "116m 48s (- 467m 12s) (4 20%) 1.1330\n",
      "117m 28s (- 469m 55s) (4 20%) 1.1244\n",
      "118m 9s (- 472m 37s) (4 20%) 1.1525\n",
      "118m 50s (- 475m 20s) (4 20%) 1.1528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:That's 100 lines that end in a tokenized period ('.')\n",
      "WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score is 4.061337059647854\n",
      "119m 39s (- 478m 38s) (4 20%) 1.1349\n",
      "120m 20s (- 481m 21s) (4 20%) 1.1502\n",
      "121m 28s (- 364m 26s) (5 25%) 1.0787\n",
      "122m 9s (- 366m 28s) (5 25%) 1.0580\n",
      "122m 50s (- 368m 30s) (5 25%) 1.0584\n",
      "123m 30s (- 370m 32s) (5 25%) 1.0862\n",
      "124m 11s (- 372m 34s) (5 25%) 1.0742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:That's 100 lines that end in a tokenized period ('.')\n",
      "WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score is 4.116440127868696\n",
      "125m 0s (- 375m 2s) (5 25%) 1.0751\n",
      "125m 41s (- 377m 4s) (5 25%) 1.0773\n",
      "126m 22s (- 379m 7s) (5 25%) 1.0788\n",
      "127m 3s (- 381m 9s) (5 25%) 1.0931\n",
      "127m 43s (- 383m 11s) (5 25%) 1.0843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:That's 100 lines that end in a tokenized period ('.')\n",
      "WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score is 3.56307582851746\n",
      "128m 33s (- 385m 39s) (5 25%) 1.0896\n",
      "129m 13s (- 387m 41s) (5 25%) 1.0578\n",
      "129m 54s (- 389m 43s) (5 25%) 1.0687\n",
      "130m 35s (- 391m 46s) (5 25%) 1.1009\n",
      "131m 16s (- 393m 48s) (5 25%) 1.0963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:That's 100 lines that end in a tokenized period ('.')\n",
      "WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score is 3.144031884609802\n",
      "132m 5s (- 396m 16s) (5 25%) 1.1040\n",
      "132m 46s (- 398m 19s) (5 25%) 1.1175\n",
      "133m 27s (- 400m 21s) (5 25%) 1.1084\n",
      "134m 7s (- 402m 23s) (5 25%) 1.1067\n",
      "134m 48s (- 404m 25s) (5 25%) 1.0811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:That's 100 lines that end in a tokenized period ('.')\n",
      "WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score is 3.412594635300846\n",
      "135m 37s (- 406m 53s) (5 25%) 1.1018\n",
      "136m 18s (- 408m 55s) (5 25%) 1.0830\n",
      "136m 59s (- 410m 58s) (5 25%) 1.0979\n",
      "137m 40s (- 413m 0s) (5 25%) 1.1199\n",
      "138m 20s (- 415m 2s) (5 25%) 1.1004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:That's 100 lines that end in a tokenized period ('.')\n",
      "WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score is 3.579020951482353\n",
      "139m 10s (- 417m 31s) (5 25%) 1.1065\n",
      "139m 51s (- 419m 33s) (5 25%) 1.0846\n",
      "140m 31s (- 421m 35s) (5 25%) 1.0942\n",
      "141m 12s (- 423m 37s) (5 25%) 1.0891\n",
      "141m 53s (- 425m 39s) (5 25%) 1.0986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:That's 100 lines that end in a tokenized period ('.')\n",
      "WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score is 3.5156731943607618\n",
      "142m 42s (- 428m 8s) (5 25%) 1.1189\n",
      "143m 23s (- 430m 10s) (5 25%) 1.1085\n",
      "144m 4s (- 432m 12s) (5 25%) 1.1123\n",
      "144m 44s (- 434m 14s) (5 25%) 1.1206\n",
      "145m 25s (- 436m 16s) (5 25%) 1.1152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:That's 100 lines that end in a tokenized period ('.')\n",
      "WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score is 3.3063521191518124\n",
      "146m 15s (- 438m 45s) (5 25%) 1.1016\n",
      "146m 55s (- 440m 47s) (5 25%) 1.1105\n",
      "147m 36s (- 442m 49s) (5 25%) 1.1107\n",
      "148m 17s (- 444m 51s) (5 25%) 1.1150\n",
      "148m 57s (- 446m 53s) (5 25%) 1.1139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:That's 100 lines that end in a tokenized period ('.')\n",
      "WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score is 3.808447510385108\n",
      "149m 48s (- 449m 24s) (5 25%) 1.1208\n",
      "150m 28s (- 451m 26s) (5 25%) 1.1245\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 200\n",
    "encoder1 = EncoderRNN(EMBEDDING_SIZE,hidden_size).to(device)\n",
    "decoder1 = DecoderRNN(EMBEDDING_SIZE,hidden_size, len(ordered_words_ft)).to(device)\n",
    "\n",
    "##UNCOMMENT TO TRAIN THE MODEL\n",
    "trainIters(encoder1, decoder1, 20,'hidden_200_lr_0.01', lr_decrease = True,print_every=50,plot_every = 100, evaluate_every = 250,learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 350\n",
    "encoder1 = EncoderRNN(EMBEDDING_SIZE,hidden_size).to(device)\n",
    "decoder1 = DecoderRNN(EMBEDDING_SIZE,hidden_size, len(ordered_words_ft)).to(device)\n",
    "\n",
    "##UNCOMMENT TO TRAIN THE MODEL\n",
    "trainIters(encoder1, decoder1, 20,'hidden_350', lr_decrease = True,print_every=50,plot_every = 100, evaluate_every = 250,learning_rate=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# beam search + bleu score\n",
    "def beam_search_decoder(data, k):\n",
    "    sequences = [[list(), 1.0]]\n",
    "    # walk over each step in sequence\n",
    "    for row in data:\n",
    "        all_candidates = list()\n",
    "        # expand each current candidate\n",
    "        for i in range(len(sequences)):\n",
    "            seq, score = sequences[i]\n",
    "            for j in range(len(row)):\n",
    "                candidate = [seq + [j], score * -log(row[j])]\n",
    "                all_candidates.append(candidate)\n",
    "        # order all candidates by score\n",
    "        ordered = sorted(all_candidates, key=lambda tup:tup[1])\n",
    "        # select top best\n",
    "        sequences = ordered[:1]\n",
    "    return sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class decoder_output_node:\n",
    "    def __init__(self,parent, word_idx, prob_sum, isroot=False):\n",
    "        self.parent = parent\n",
    "        self.isroot = isroot\n",
    "        self.children = []\n",
    "        self.word_idx = word_idx\n",
    "        self.prob_sum = prob_sum\n",
    "    \n",
    "    def get_children(self):\n",
    "        '''\n",
    "        return children\n",
    "        '''\n",
    "        return self.children\n",
    "    \n",
    "    def add_children(self, child):\n",
    "        '''\n",
    "        child: node\n",
    "        '''\n",
    "        self.children.append(child)\n",
    "        return\n",
    "    \n",
    "    def get_parent(self):\n",
    "        '''\n",
    "        get parent of children\n",
    "        '''\n",
    "        return self.parent\n",
    "    \n",
    "    def get_word_idx(self):\n",
    "        \n",
    "        return self.word_idx\n",
    "    \n",
    "    def get_prob_sum(self):\n",
    "        \n",
    "        return self.prob_sum\n",
    "    \n",
    "    def is_root(self):\n",
    "        return self.isroot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_sentence_sequence(child_node):\n",
    "    if child_node.is_root():\n",
    "        return [child_node.get_word_idx()]\n",
    "    \n",
    "    return return_sentence_sequence(child_node.get_parent())+[child_node.get_word_idx()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beam_search(beam_k, decoder_output, prob_sum = None, parent_node_list=None, vocab_size = len(idx2words_ft_en)):\n",
    "    '''\n",
    "    params:\n",
    "    beam_k\n",
    "    decoder_output: previous round decoder output\n",
    "    parent_node_list: previous candidate word list (for only one candidate)\n",
    "    \n",
    "    return:\n",
    "    list_of_best_k_nodes: best k nodes found in this iteration, list of list, first dim batch, second dim best k\n",
    "    prob_with_sum: probabilistic matrix after sum+sortee \n",
    "    '''\n",
    "    # if first word\n",
    "    if parent_node_list is None:\n",
    "        # initialize result\n",
    "        prob_with_sum_sorted, word_idx_sorted = decoder_output.data.topk(beam_k)\n",
    "        #print(\"ps\",prob_with_sum_sorted)\n",
    "        # add initialize tree list\n",
    "        list_of_best_k_nodes = []\n",
    "        batchsize = prob_with_sum_sorted.shape[0]\n",
    "        for batch_i in range(batchsize):\n",
    "            batch_i_tree_list = []\n",
    "            for beam_i in range(beam_k):\n",
    "                # add tree root node to list\n",
    "                batch_i_tree_list.append(decoder_output_node(parent=None, word_idx=word_idx_sorted[batch_i, beam_i].item(), \n",
    "                                                            prob_sum= prob_with_sum_sorted[batch_i, beam_i].item(), isroot=True))\n",
    "                \n",
    "            list_of_best_k_nodes.append(batch_i_tree_list)\n",
    "   \n",
    "    # if not first word\n",
    "    else:\n",
    "        # get sorted results for all outputs\n",
    "        prob = decoder_output.data\n",
    "        #print(decoder_output.data.shape)\n",
    "        #print(word_idx)\n",
    "        \n",
    "        \n",
    "        # find top beam k words options\n",
    "        #print(\"sum:\",prob_sum)\n",
    "        #print(\"curr prob:\",prob)\n",
    "        #print(\"sum:\",prob+prob_sum)\n",
    "        prob_with_sum = prob+prob_sum\n",
    "        prob_with_sum_sorted, word_idx_sorted = torch.sort(prob_with_sum, dim=1, descending=True)\n",
    "        #print(\"sum sorted:\", prob_with_sum_sorted)\n",
    "        # add top beam k words options into tree\n",
    "        batchsize = prob_with_sum_sorted.shape[0]\n",
    "        \n",
    "        list_of_best_k_nodes = []\n",
    "        for batch_i in range(batchsize):\n",
    "            batch_i_tree_list = []\n",
    "            for beam_i in range(beam_k):\n",
    "                #print(word_idx_sorted[batch_i, beam_i])\n",
    "                #print(parent_node_list[batch_i].get_word_idx())\n",
    "                child_node = decoder_output_node(parent=parent_node_list[batch_i], word_idx= word_idx_sorted[batch_i,beam_i].item(), prob_sum=prob_with_sum_sorted[batch_i,beam_i].item())\n",
    "                \n",
    "                # update parent node's child\n",
    "                parent_node_list[batch_i].add_children(child_node)\n",
    "                #save child to new list\n",
    "                batch_i_tree_list.append(child_node)\n",
    "            # add batch tree list to best k\n",
    "            list_of_best_k_nodes.append(batch_i_tree_list)\n",
    "                \n",
    "    return list_of_best_k_nodes, prob_with_sum_sorted[:,:beam_k], word_idx_sorted[:,:beam_k]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_with_beam_search(val_loader,encoder1,decoder1,beam_k = 5):\n",
    "    big_pred_list = []\n",
    "    big_ref_list = []\n",
    "    #beam_k = 5\n",
    "    with torch.no_grad():\n",
    "        predictions = ''\n",
    "        references = ''\n",
    "        for i, (data_s1, data_s2, lengths_s1, lengths_s2) in enumerate(val_loader):\n",
    "            #print(i)\n",
    "            input_tensor = data_s1\n",
    "            input_length = input_tensor.size()[0]\n",
    "            #sentence_length to the output length\n",
    "            sentence_length = data_s2.size()[1]\n",
    "            encoder_hidden = encoder1.initHidden(input_length)\n",
    "\n",
    "            encoder_output, encoder_hidden = encoder1(input_tensor, encoder_hidden)\n",
    "\n",
    "            #decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "            decoder_input = torch.tensor(np.array([[SOS_IDX]]*input_length).reshape(1,input_length),device=device)\n",
    "\n",
    "            decoder_hidden = encoder_hidden\n",
    "\n",
    "            decoder_attentions = torch.zeros(sentence_length, sentence_length)\n",
    "            decoded_words_eval = []\n",
    "            list_of_best_k_nodes = []\n",
    "\n",
    "            prob_with_sum_sorted = []\n",
    "            #print(\"outside\",prob_with_sum_sorted)\n",
    "\n",
    "            decoder_hidden_list = []\n",
    "            for di in range(sentence_length):\n",
    "\n",
    "                ############################################beam search###################################################\n",
    "                #print(di)\n",
    "                if di == 0:\n",
    "                    decoded_words_sub = []\n",
    "\n",
    "\n",
    "                    decoder_output, decoder_hidden, decoder_attention = decoder1(\n",
    "                                    decoder_input, decoder_hidden, encoder_output)\n",
    "\n",
    "                    # find top k candidates\n",
    "                    list_of_best_k_nodes,prob_with_sum_sorted ,word_idx_sorted = beam_search(beam_k, decoder_output, parent_node_list=None)\n",
    "                    decoder_hidden_list = [decoder_hidden]*beam_k\n",
    "\n",
    "                    #print(\"sum1\",prob_with_sum_sorted)\n",
    "                    #print(\"idx\",word_idx_sorted)\n",
    "                    #print(list_of_best_k_nodes[0][0].get_word_idx())\n",
    "                    #print(list_of_best_k_nodes[0][1].get_word_idx())\n",
    "\n",
    "                else:\n",
    "                    # keep track of all new nodes\n",
    "                    new_nodes = []\n",
    "                    nodes_prob = None\n",
    "                    #nodes_word_idx = None\n",
    "\n",
    "                    # store index in previous candidate to locate position in new nodes, repeats=beam_size*beam_size\n",
    "                    prev_candidate_idx = np.repeat(range(beam_k), repeats=beam_k)\n",
    "\n",
    "                    # iterate through each node candidate from last iterations to find new candidates\n",
    "                    new_decoder_hidden_list = []\n",
    "\n",
    "                    for beam_i in range(beam_k):\n",
    "                        #print(word_idx_sorted.shape)\n",
    "                        topi = word_idx_sorted[:,beam_i].data\n",
    "                        #print(\"idx i\",topi)\n",
    "\n",
    "                        prob_sum = prob_with_sum_sorted[:,beam_i].view((input_length,1))\n",
    "                        #print(\"prob sum:\", prob_sum)\n",
    "                        #change the dimension\n",
    "                        decoder_input = topi.squeeze().detach()\n",
    "                        decoder_input = decoder_input.unsqueeze(0)\n",
    "\n",
    "                        # get decoder output\n",
    "                        decoder_output, decoder_hidden_i, decoder_attention = decoder1(\n",
    "                                    decoder_input, decoder_hidden_list[beam_i], encoder_output)\n",
    "\n",
    "                        new_decoder_hidden_list.append(decoder_hidden_i)\n",
    "\n",
    "                        # get beam search output\n",
    "                        best_k_curr_node, prob_sum_curr_node, _ = beam_search(beam_k, decoder_output, prob_sum=prob_sum, parent_node_list=[ls[beam_i] for ls in list_of_best_k_nodes])\n",
    "                        #print(word_idx_curr_node)\n",
    "\n",
    "                        # keep track of beam search output\n",
    "                        new_nodes.append(best_k_curr_node)\n",
    "\n",
    "                        if beam_i == 0:\n",
    "                            nodes_prob = prob_sum_curr_node.data\n",
    "\n",
    "                            #nodes_word_idx = word_idx_curr_node\n",
    "                        else:\n",
    "                            nodes_prob = torch.cat((nodes_prob, prob_sum_curr_node.data),dim=1)\n",
    "                            #nodes_word_idx = torch.cat((nodes_word_idx, word_idx_curr_node),dim=1)\n",
    "\n",
    "                    #print(\"nodes prob\", nodes_prob)\n",
    "                    _, sorted_idx = torch.sort(nodes_prob, dim=1, descending=True)\n",
    "                    #print(\"length\",nodes_prob.shape)\n",
    "                    #print(nodes_prob)\n",
    "                    #print(sorted_idx)\n",
    "\n",
    "                    #print(prev_candidate_idx)\n",
    "                    #print(\"new nodes len:\", len(new_nodes[0][0]))\n",
    "                    #print(\"new_nodes 0\",new_nodes[0])\n",
    "                    #print(\"new_nodes 1\",new_nodes[1])\n",
    "                    # update \n",
    "                    #print(sorted_idx.shape)\n",
    "                    for batch_i in range(input_length):\n",
    "                        for beam_i in range(beam_k):\n",
    "                            # find the index of which candidate it descended from\n",
    "                            st_idx = sorted_idx[batch_i][beam_i].item()\n",
    "                            # find the corresponding node, st_idx gives parent node id, batch_i gives which example, st_idx%beam_k gives which node in the existing node list\n",
    "                            #if batch_i == 0:\n",
    "                            #print(\"st_idx\",st_idx)\n",
    "                            update_node = new_nodes[prev_candidate_idx[st_idx]][batch_i][st_idx%beam_k]\n",
    "\n",
    "                            list_of_best_k_nodes[batch_i][beam_i] = update_node\n",
    "                            #print(batch_i)\n",
    "                            #print(beam_i)\n",
    "                            #print(list_of_best_k_nodes[0][0].parent.get_word_idx())\n",
    "\n",
    "                            # update word idex, prob sum correspondingly for next iteration\n",
    "                            #word_idx_sorted[batch_i][beam_i] = nodes_word_idx[batch_i][st_idx] \n",
    "                            word_idx_sorted[batch_i][beam_i] = update_node.get_word_idx()\n",
    "                            prob_with_sum_sorted[batch_i][beam_i] = update_node.get_prob_sum()\n",
    "\n",
    "\n",
    "                            decoder_hidden_list[beam_i][0,batch_i,:] = new_decoder_hidden_list[prev_candidate_idx[st_idx]][0,batch_i,:]\n",
    "\n",
    "                    #print(\"best k\",list_of_best_k_nodes[0])\n",
    "                    #print(\"final\", prob_with_sum_sorted)\n",
    "                    #print(\"idx final\", word_idx_sorted)\n",
    "\n",
    "            # find the best and get index\n",
    "            listed_predictions = []\n",
    "            for batch_i in range(input_length):\n",
    "                best_sequence_last_node = list_of_best_k_nodes[batch_i][0]\n",
    "                batch_i_word_idx = return_sentence_sequence(best_sequence_last_node)\n",
    "\n",
    "                listed_predictions.append(' '.join(idx2words_ft_en[token_idx] for token_idx in batch_i_word_idx if token_idx!=PAD_IDX))\n",
    "                #print(' '.join(idx2words_ft_en[token_idx] for token_idx in batch_i_word_idx ))\n",
    "                #print(batch_i_word_idx)\n",
    "                #print (listed_predictions)\n",
    "            listed_reference = []\n",
    "            for ele in data_s2:\n",
    "                sent = index2token_sentence(ele)\n",
    "\n",
    "                listed_reference.append(sent)\n",
    "                #print (\"\\n\")\n",
    "                #print (sent)\n",
    "\n",
    "            #print(listed_predictions)\n",
    "            #bleu_score = corpus_bleu(listed_predictions,[listed_reference])\n",
    "            #print('BLEU Score is %s' % (str(bleu_score.score)))\n",
    "\n",
    "            big_pred_list += listed_predictions\n",
    "            big_ref_list += listed_reference\n",
    "            \n",
    "    bleu_score = corpus_bleu(big_pred_list,[big_ref_list])\n",
    "    print('BLEU Score is %s' % (str(bleu_score.score)))\n",
    "            ############################################beam search###################################################\n",
    "    return bleu_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
